{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nthanhkhang/Vietnamese-Social-Media-Emotion-Corpus/blob/main/Task3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ndnMfSlzIVg"
   },
   "source": [
    "#**Sentiment-Analysis-with-Attention**\n",
    "\n",
    "A model to perform sentiment analysis on wikipedia comments using attention mechanism in keras.\n",
    "\n",
    "Data from Youtube comment classification challenge.\n",
    "\n",
    "The word embeddings can be downloaded from [here](https://github.com/nthanhkhang/Natural-Language-Processing/raw/main/Data/Data.zip).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeNTCKnKnN6R"
   },
   "source": [
    "# I.Import Library\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5IjtVZsKuBq"
   },
   "source": [
    "## 1.Download Packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KZVIBRDDrFk",
    "outputId": "146feaa8-15ac-4029-8aa2-d9e4f397d49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "Collecting keras==2.2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from keras==2.2.5) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.2.5\n",
      "Requirement already satisfied: pyvi in /usr/local/lib/python3.7/dist-packages (0.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.3.6)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.22.2.post1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "!pip install keras==2.2.5\n",
    "!pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AN8rgbmrdKJP",
    "outputId": "11e75dac-a95c-4645-cfa1-ed3c0d0a8950"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import os, pickle, re, keras, sklearn, string\n",
    "from keras.callbacks import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import gensim, operator, json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import *\n",
    "import keras.backend as K\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers\n",
    "from keras import optimizers\n",
    "from keras.engine.topology import Layer\n",
    "from keras import constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mydjvnoKc6l"
   },
   "source": [
    "## 2.Download Word2Vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_QyBjmaFumz",
    "outputId": "93d844dc-e98e-4985-9a13-8635f0eb77f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "word2vec already downloaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%cd /content\n",
    "if not os.path.exists(\"baomoi.model.bin\"):\n",
    "  !wget -P /content/ -c \"https://thiaisotajppub.s3-ap-northeast-1.amazonaws.com/publicfiles/baomoi.model.bin\"\n",
    "else:\n",
    "  print(\"word2vec already downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tulCPm4JKlB6"
   },
   "source": [
    "## 3.Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBL3vFXWC6HS",
    "outputId": "e1fe989a-e8ee-41c2-bf31-4e01aa48dcc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Data.zip already downloaded\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "if not os.path.exists(\"Data.zip\"):\n",
    "  !wget -P /content/ -c \"https://github.com/nthanhkhang/Natural-Language-Processing/raw/main/Data/Data.zip\"\n",
    "else:\n",
    "  print(\"Data.zip already downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqqjA5rmnXW9"
   },
   "source": [
    "# II.Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6I-G2B7CwyA",
    "outputId": "612a16db-8050-4ca1-9505-e5ac33b2514a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zipfile.ZipFile [closed]>\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"Data.zip\",\"r\") as zf:\n",
    "    zf.extractall('Data')\n",
    "print(zf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Rp1-Qa_81FEY"
   },
   "outputs": [],
   "source": [
    "path_train ='Data/link1.csv'\n",
    "path_valid ='Data/link2.csv'\n",
    "path_test ='Data/link3.csv'\n",
    "path_stopword = 'Data/stopwords.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3JUFIaAndQo"
   },
   "source": [
    "# III.Word2vec using baomoi.model.bin\n",
    "\n",
    "*   Function reading pretrain word embedding library.\n",
    "*   The word embedding pretrain has been trained in new news, 300-way news\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Skg7lUZ9LYAn",
    "outputId": "c1476036-56e7-4015-a56d-5e726f7c5064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding:  400\n",
      "[-0.78774583 -0.22327825 -0.6274532  -2.7228408  -2.2186291   0.38002455\n",
      "  3.8660462   0.9853684  -1.4683082  -1.7013292  -0.5839958  -0.14467287\n",
      "  3.600142    3.381808   -0.02930526  3.0047843  -0.2006207  -1.0937127\n",
      "  1.7360235   2.3691583  -0.71597415  3.319453    0.2824182  -3.0814204\n",
      "  2.6810844  -0.810977    1.5186927  -2.10329     1.3271075  -1.3646411\n",
      " -0.11144319 -4.6505136  -1.7251624  -2.31126     1.583203   -0.8746506\n",
      " -2.6937015  -1.7733976   0.557898   -1.7562917   1.3282276  -0.3805479\n",
      " -1.3979301  -0.1536707  -1.1909302   1.3283668   0.22275637 -2.7959821\n",
      " -5.188217   -0.6404673   0.0164395   0.67177856 -1.4948794   0.21867418\n",
      " -1.4103376   0.99262404  2.2180524  -0.4881204   3.0988753  -0.31382522\n",
      "  1.3226501   0.21269594 -1.6409203   1.7758838   2.3379912  -2.4666297\n",
      " -0.599687    0.551105   -1.3755493  -1.4293027  -2.6366289   0.40759587\n",
      " -0.77850854 -0.6169452  -0.84525913  0.02801617  2.1296268   0.13715844\n",
      " -1.1562283  -2.1226277  -0.1346792   0.88932824 -1.5711976   0.36148685\n",
      "  2.2572796  -2.0762215   1.736077   -0.3133224   0.48849696  2.1262195\n",
      " -2.3417432   0.7264937   1.3197432  -1.0578146   1.9603167  -1.957219\n",
      " -0.47556064 -3.2944543  -1.540249    1.6060241   0.02990843 -1.0645736\n",
      " -0.5550473   1.589397   -0.5811684  -1.2199221  -0.9025384  -1.2436662\n",
      "  0.50163126  0.11698119  0.8760743   0.8978141  -1.8893797  -0.1424527\n",
      " -3.0423136  -0.88489795  0.49000955 -3.4689097  -1.8564429  -0.66697997\n",
      "  5.3912683  -2.092744   -0.5973023  -0.7118058  -1.0953093   0.4417508\n",
      "  2.440871    1.1271865   1.4602836  -2.714987   -1.3927895  -0.16143057\n",
      "  0.07596377 -2.0885456  -1.0929846  -1.1670731   0.7352281  -1.0726835\n",
      "  0.4963534  -0.78458273  2.3078787  -3.5055773   0.9567256  -0.5207236\n",
      "  0.36697528  0.8511779   0.878965    1.3028007   0.04724613  0.9892602\n",
      " -0.8373782   0.27926713  2.268885   -0.11917569  0.8163163   0.3869213\n",
      "  0.20561185 -2.2969527  -1.6468542  -3.9922614  -0.96281457  3.2537632\n",
      "  0.48358652 -0.6078726   3.2632709   0.11489751 -2.6600893   0.92677915\n",
      " -0.528953    3.4760187   2.31958     2.23189     2.2253554  -1.8307585\n",
      " -1.7324418  -1.2364737  -4.273679    0.9341229   0.59669524 -0.03376843\n",
      " -2.971719    1.9712305  -0.549242    0.4829846   1.4618144  -1.3703161\n",
      " -1.1212839   0.4291749   1.4675773  -0.67144257 -0.49444234  1.7652586\n",
      "  1.7143794   0.54265493  2.1978571   3.2426474  -2.7528286  -2.2640996\n",
      "  0.09805597  1.2702079   1.156494   -1.1671641  -2.3361897   1.2424865\n",
      " -2.1413488  -0.22989413 -2.7570245  -1.2689328  -0.11422111  0.340871\n",
      " -0.72356385 -3.100242   -0.2113436   0.08352826  3.0843058   0.2549431\n",
      "  3.6576512  -0.71284246 -1.8232595  -1.0566906  -0.7372802   0.18872899\n",
      "  0.11927979  3.0378866   0.7687284   0.7458194   3.392024   -0.10601766\n",
      "  1.7550762  -3.9328496   0.5543825   2.4240685   2.4877627  -1.8583341\n",
      " -2.7361338   0.9327119   1.4136555   0.6736002  -0.56006515 -0.17299697\n",
      "  2.3964696   1.4890865   0.47563386 -1.7579868  -3.2750478  -2.711356\n",
      "  1.1631078   0.5226146  -0.77252626  2.0378802  -2.1662908   1.1695647\n",
      "  1.0302314   1.2815226   1.8774925   1.0482382  -2.829525   -1.3818443\n",
      "  1.0274167  -0.61302423  0.24060939 -2.8208141   1.2254591  -1.9544963\n",
      "  1.7342434  -0.9264713   0.39906958  1.4076114   0.68284744  2.4939642\n",
      "  2.1315014   0.20849855 -1.4851028   4.6376705   2.2327776   2.2943447\n",
      " -1.253777   -2.385657   -2.5678577  -1.7067193   2.387362   -1.3572613\n",
      " -4.5016227   0.7827232  -0.44352373  0.3998332  -0.5178318   0.6794015\n",
      "  3.7974224  -0.774167   -1.1981938   0.3985697  -1.8760519   0.1238703\n",
      "  0.05213618 -1.1321199  -2.8599005  -1.7278007   2.1998515  -2.5468414\n",
      "  0.9428754   0.992005   -2.7554674  -1.364683   -0.8704408  -1.1697435\n",
      "  1.880865    1.9564949   3.1174672   0.14133504 -2.2360458  -1.173718\n",
      "  1.3261789  -2.2110426   0.589773    3.4267988   3.2046275  -0.91721445\n",
      "  0.7951813  -2.3174386  -0.8497346   1.6120318  -0.40876418  0.7933062\n",
      " -0.8393237  -0.41007656  2.8945262   0.993892   -1.7588191  -4.925732\n",
      " -2.4419074   3.0766954  -1.9000514  -2.0604458   3.4133394  -2.0102491\n",
      "  2.046963    0.71078193  2.2965722   1.72548     1.2269657  -2.2357993\n",
      "  0.50008225  4.8475957  -1.0541344   2.308317   -1.1630418   1.1258802\n",
      " -1.2478187   1.0942221   0.92810786 -1.5838045  -2.0654778  -0.28107494\n",
      "  2.4073355   1.3492072   0.48608387 -0.4716219   2.1616933  -1.3125483\n",
      "  1.5123384  -4.5521007  -1.8622614   1.088746    1.6043898  -4.609651\n",
      " -0.4500263   1.9802842   1.9102592  -0.47483805 -4.2590923   1.1523023\n",
      "  0.9832213   1.9767743   3.2593958   0.41252086  0.37052628  0.5532108\n",
      " -0.44213554  1.3767333  -0.8914752  -4.444391   -1.9290444  -1.6292545\n",
      " -2.6812217  -1.0284953   0.0313996   4.0027394   0.6476944  -0.02785059\n",
      " -2.4854484  -0.82289666  1.3539648   3.0980484  -1.3214976  -1.5370079\n",
      "  0.96148336  0.1992502   3.5529153   2.4300497 ]\n"
     ]
    }
   ],
   "source": [
    "path_embedding= 'baomoi.model.bin'\n",
    "\n",
    "import io\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word_embedding = KeyedVectors.load_word2vec_format(path_embedding, binary=True)\n",
    "# Example of taking vector of 1 word in the word embedding pretrain\n",
    "EMBEDDING_DIM = word_embedding['yêu'].shape[0]\n",
    "print(\"Embedding: \",EMBEDDING_DIM)\n",
    "# Vector of love words in pretrained word embedding set.\n",
    "print(word_embedding['yêu'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lo7k112MoVAQ"
   },
   "source": [
    "# IV. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5Gb-4LVo1bf"
   },
   "source": [
    "## 1.Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MWTniSb1o0d9"
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    token = ViTokenizer.tokenize(text)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsAfz-Kco86j"
   },
   "source": [
    "## 2.Delete Icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VCchYWSMo9y5"
   },
   "outputs": [],
   "source": [
    "def deleteIcon(text):\n",
    "    text = text.lower()\n",
    "    s = ''\n",
    "    pattern = r\"[a-zA-ZaăâbcdđeêghiklmnoôơpqrstuưvxyàằầbcdđèềghìklmnòồờpqrstùừvxỳáắấbcdđéếghíklmnóốớpqrstúứvxýảẳẩbcdđẻểghỉklmnỏổởpqrstủửvxỷạặậbcdđẹệghịklmnọộợpqrstụựvxỵãẵẫbcdđẽễghĩklmnõỗỡpqrstũữvxỹAĂÂBCDĐEÊGHIKLMNOÔƠPQRSTUƯVXYÀẰẦBCDĐÈỀGHÌKLMNÒỒỜPQRSTÙỪVXỲÁẮẤBCDĐÉẾGHÍKLMNÓỐỚPQRSTÚỨVXÝẠẶẬBCDĐẸỆGHỊKLMNỌỘỢPQRSTỤỰVXỴẢẲẨBCDĐẺỂGHỈKLMNỎỔỞPQRSTỦỬVXỶÃẴẪBCDĐẼỄGHĨKLMNÕỖỠPQRSTŨỮVXỸ,._]\"\n",
    "    for char in text:\n",
    "        if char !=' ':\n",
    "            if len(re.findall(pattern, char)) != 0:\n",
    "                s+=char\n",
    "            elif char == '_':\n",
    "                s+=char\n",
    "        else:\n",
    "            s+=char\n",
    "    s = re.sub('\\\\s+',' ',s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5xJDr9epIEJ"
   },
   "source": [
    "## 3.Clean Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L1_TFsm9WdA0"
   },
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    doc = tokenizer(doc)\n",
    "    for punc in string.punctuation:# delete all punctuation (!,? ..) in a sentence\n",
    "        if punc != \"_\":\n",
    "            doc = doc.replace(punc,' ')\n",
    "    doc = deleteIcon(doc) \n",
    "    doc = re.sub(r\"[0-9]+\", \" num \", doc)# Delete numbers\n",
    "    doc = doc.lower()#lowercase \n",
    "    doc = re.sub('\\\\s+',' ',doc)# Remove lots of spaces\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJlgGwaxudQc"
   },
   "source": [
    "## 4.Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hPeiHFV2vRMY"
   },
   "outputs": [],
   "source": [
    "# from underthesea import word_tokenize\n",
    "def pre_process(questions):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    questions_stop = [[t for t in tokens if (t not in stop_words) and (3 < len(t.strip()) < 15)]\n",
    "                      for tokens in questions_tokens]\n",
    "    questions_stop = pd.Series(questions_stop)\n",
    "    return questions_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpylx70bxTGD"
   },
   "source": [
    "## 5.Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0AGZRQ8bOklR"
   },
   "outputs": [],
   "source": [
    "def word_tokenize(text):\n",
    "    token = word_tokenize.tokenize(text)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmCkYJpypwlS"
   },
   "source": [
    "# V.Train/Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Usy-4ygPWdA2"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(path_train,encoding='utf-16')\n",
    "valid_data = pd.read_csv(path_valid,encoding='utf-16')\n",
    "test_data = pd.read_csv(path_test,encoding='utf-16')\n",
    "\n",
    "X_train = train_data[\"Sentence\"].apply(lambda x : clean_doc(x))\n",
    "y_train = train_data[\"Emotion\"]\n",
    "\n",
    "X_val = valid_data[\"Sentence\"].apply(lambda x : clean_doc(x))\n",
    "y_val = valid_data[\"Emotion\"]\n",
    "\n",
    "X_test = test_data[\"Sentence\"].apply(lambda x : clean_doc(x))\n",
    "y_test = test_data[\"Emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnYcGTbL0jnu",
    "outputId": "1f07db0f-3edc-44a8-c8c2-d31b1a174cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "100 100\n",
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(y_train))\n",
    "print(len(X_val),len(y_val))\n",
    "print(len(X_test),len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9GOPYuaMf4W"
   },
   "source": [
    "## DataFrame link1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "A-p2WNKMJcFB",
    "outputId": "eba20f75-4303-45b1-c0f3-40099f859c0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>một giọng nói của người trải qua sự bi_đát mon...</td>\n",
       "      <td>Enjoyment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vũ_nương_à</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chào anh tuân anh thích ăn món gì nhất</td>\n",
       "      <td>Enjoyment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anh tuna ơi em thấy cj cừu xinh phết anh có_th...</td>\n",
       "      <td>Enjoyment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giọng ông đọc radio buồn được phết</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence    Emotion\n",
       "0  một giọng nói của người trải qua sự bi_đát mon...  Enjoyment\n",
       "1                                         vũ_nương_à      Other\n",
       "2             chào anh tuân anh thích ăn món gì nhất  Enjoyment\n",
       "3  anh tuna ơi em thấy cj cừu xinh phết anh có_th...  Enjoyment\n",
       "4                 giọng ông đọc radio buồn được phết    Sadness"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_train)\n",
    "df.columns = [\"Sentence\"]\n",
    "df['Emotion']=df['Sentence'].apply(len)\n",
    "df['Emotion'] = pd.DataFrame(y_train)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVy9TfvcMr1-"
   },
   "source": [
    "## DataFrame link2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "wfPFt819J_qF",
    "outputId": "98147acc-cf74-4823-f922-26921dc07d71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nếu làm ra sản_phẩm mà không có tiền để làm qu...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kênh lên phiên_bản tiếng trung nếu chủ_đề về t...</td>\n",
       "      <td>Enjoyment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>không có bình_luận của dân mạng tq về bài này ...</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>giúp gì mà giúp ở đây chưa biết ai giúp ai tq ...</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admin nên tìm_hiểu xem sau năm đó trung_quốc đ...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence    Emotion\n",
       "0  nếu làm ra sản_phẩm mà không có tiền để làm qu...      Anger\n",
       "1  kênh lên phiên_bản tiếng trung nếu chủ_đề về t...  Enjoyment\n",
       "2  không có bình_luận của dân mạng tq về bài này ...    Disgust\n",
       "3  giúp gì mà giúp ở đây chưa biết ai giúp ai tq ...    Disgust\n",
       "4  admin nên tìm_hiểu xem sau năm đó trung_quốc đ...      Other"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_val)\n",
    "df.columns = [\"Sentence\"]\n",
    "df['Emotion']=df['Sentence'].apply(len)\n",
    "df['Emotion'] = pd.DataFrame(y_val)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmaZbrbAMx2c"
   },
   "source": [
    "## DataFrame link3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "WHxbXYpKKI-n",
    "outputId": "c33ee354-efe8-45a5-f2f2-4b4420f1777b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nhân_viên y_tế vn chết sau khi tim vacien mà t...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bán hàng gì o hiểu</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cô vid không phải là vũ_khí hủy_diệt nhưng nó ...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quá vo vẫn phút quản_cáo một lần</td>\n",
       "      <td>Enjoyment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giống nói_khó nghe</td>\n",
       "      <td>Enjoyment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence    Emotion\n",
       "0  nhân_viên y_tế vn chết sau khi tim vacien mà t...      Other\n",
       "1                                 bán hàng gì o hiểu      Other\n",
       "2  cô vid không phải là vũ_khí hủy_diệt nhưng nó ...    Sadness\n",
       "3                   quá vo vẫn phút quản_cáo một lần  Enjoyment\n",
       "4                                 giống nói_khó nghe  Enjoyment"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_test)\n",
    "df.columns = [\"Sentence\"]\n",
    "df['Emotion']=df['Sentence'].apply(len)\n",
    "df['Emotion'] = pd.DataFrame(y_test)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "uOMLPBxfQlpC",
    "outputId": "67231651-8598-4619-f4fb-fe7318d5ba11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum Sentence sequence length >> 216\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Sentence_lengths = [len(s) for s in X_test]\n",
    "print(f\"maximum Sentence sequence length >> {np.max(question_lengths)}\")\n",
    "plt.subplot(2,1,1)\n",
    "plt.hist(Sentence_lengths,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyPnd4f4qDSJ"
   },
   "source": [
    "## 1.Catalog vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fyIQeZi-WdA4"
   },
   "outputs": [],
   "source": [
    "classes = ['Anger','Disgust','Enjoyment','Fear','Other','Sadness','Surprise']\n",
    "def to_category_vector(label):\n",
    "    vector = np.zeros(len(classes)).astype(np.float64)\n",
    "    index = classes.index(label)\n",
    "    vector[index] = 1.0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ppniGtjqfhg"
   },
   "source": [
    "## 2.Convert labels to numbers in train and test practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqYyTPmLWdA_",
    "outputId": "cedf47d0-fe69-426b-d464-93e503e7bc6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anger', 'Disgust', 'Enjoyment', 'Fear', 'Other', 'Sadness', 'Surprise']\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "Enjoyment\n"
     ]
    }
   ],
   "source": [
    "y_train_encode = []\n",
    "for label in y_train:\n",
    "    y_train_encode.append(to_category_vector(label))\n",
    "\n",
    "\n",
    "y_val_encode = []\n",
    "for label in y_val:\n",
    "    y_val_encode.append(to_category_vector(label))\n",
    "\n",
    "print(classes)\n",
    "print(y_train_encode[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK6nyuqOq171"
   },
   "source": [
    "## 3.LSTM\n",
    "\n",
    "\n",
    "*   All the words in the X_train set will form a dictionary\n",
    "*   Each vector of the input word, it will turn into a vector with a fixed number of dimensions and each vocabulary will be replaced by its index in the dictionary\n",
    "* Number of vector dimensions per input we will take the longest sentence which is the direction of the vector and the shorter arcs will automatically add the value 0 after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAdmN2_AUC-r"
   },
   "source": [
    "![Attention-based-LSTM-sentiment-classifier.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAogAAAFiCAMAAABCoNnxAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAJdnBBZwAABvoAAAneANJhYVIAAAMAUExURf///6fb6avd6aXb6TRKk6231and6QAacvM+AmJ0ra3f6aPZ6fmZePdyRq/f6+f596HZ5+P39+H39ent9ev5+en5+f3Nvd/39cHJ39Xb6eX39wwmeuX59xgwg+37+QgkeN319YeVwURYmyY+i7Hh61JmpXSFt5mly6/h66HX5/P18aXZ6QgKCv/z76vf6f/n35/X5/NMEvmNaP3ZzfVmNPuzm0RopfVYJPmnia3f6xo4h+n59+H396PZ5/d+Vvu/qxAsgdv19RIugSREj+/7+ev7+T5kpd/19Rg4hyBCj0BmpS5QlypNlZfL4XOfxZOZmSI7iYeMi6PR4ZaZmX6BgSJEjzBIkj5mpZPJ32+dxVhyq2WRvSxOl6Cy0DVanUpyrZC/2JGZl0JmpZqxz0xzrWiRvV+NvXurz6HP4QolelB2rWybxXipzWqSvXWhx1R/tYq714mNjVmCtRAugVtyq5evz7rIx3ajx4WLi5/P4VZxqqavr83g4IWv0Ye515PB2dnn7////S5Ikenp50Jopc7l7GKPvYW516yxsXBycsPV5ZXJ3xYwgcDKyfPz83qRvUhyrbS9vAchdyJCj/39+87X13t+fvf398/Ty53O4Z2lpYKv0MPLy5exz16Ft6GnpWqbxUtkoxYwgzpcnWuCtOLv7q3D2n6HiTlRl5rM4VJ2rcPT04yhxzRYnThandXr6d/h24Wx0XJ0dNjs6xMpesvj67i/vXaPugYccWWBs8vX1r3DvZXB2dnj4SAeJH6tz+vt5zIiXj1WmrrS4qmxr6+7u5WdmYex0ff597/T4ytGjxQsftXj5052refn55evzSpAjd3f2x00hkZanczR1anB2YefxZ+rz2ZscsXU0w4mesHT08fHxcXV5bHD20hioQ4OENXn7x47h3ktQFdqqIWfxdLh4V4qSmqVq6M0KlJEeNXW1FBko988DKuTp5Kfx5Gvv4OLlTZMlWh6sRYqcB4ybq/Fz2Zyj5EwMjI0PCY2gUAkWOWPenRsmXaHuY2bxbJW1XUAACAASURBVHgB7X0JdCVHeW57IrklRdLg0URI1tNoJI2kwRkdIc2MR2d8mBkvJx6P8TJ4AWMbPNhgwE7AhmOMbZZhMbYztmMwBhtODCeGvDx4QMgzBpIQcCAnwAFnIwskISYJWV6W90jevn5/VVfVX9XVy723772tudX26FZXV/9V9f9f/7X99VcUhStwIHAgcCBwIHAgcCBwIHAgcKCOHBheW6ljsUKZeowDewcG1nqsyqG6deTA8MDASB3LFcrUYxzoZSAu95isa13dHgbi8MCeWoumtwrXw0BcHRgY7y1h17m2PQzEgQDEGiEzALFGwujlovQwEPcEjdgY8sfX8idYlvea50n44Mjeknn0MBBHAhANSPaCG/paN/EmtLy2mj/Tt44vWyVX4ZH8V1Ry/AYgMmb0dBBIEPVfObg67GfEcAGqVgwQoyS8e6TseLB5IMpvaISvy6zgo1k9cHDlACqCMSm7hvG1DLC1xN243aPr6yHlZ0WlsUEjWuxc1zA6qAVjJYDSMk2v/SS50xRwz8PexE5k80AU2tTqAexeXVuOVoalBh+g2oyL1m9lHd8akMgwu2bdpUk5pWzLbQCixVbIKrlftqRqEh2sKxDxDfHFieVV+cHsFuUlrZgAMYoO7I4AvVWdGopbAFVX0iGl49sZCEC0uGuAaEWzm/G6AtEp+rjC1joBUnxVUiNG0cHd0TCQqFX+MECgb6iqDilW+/YFAxAt3moRSMGMQ3mMHziwjjR75Q+ENBId3LO6lnT7xg+s7hlW3a29IyPDigILjx8QyomIHTxwING0K8Nrw2uu1m2laVYZJ/XRH8yK1IyIRgrVWR0GEpVKXF7FgwBECwddv9HSXEVRDu6D5Ib3oT81HK3RD+EGAh4ewAMpur17VpbXB1Z3U8GX9+xZiQ7iiR1egfIBFvYSMU0l2r0KdAN3BhtEokIgYgByYJloRhpjFhDxPPkMhvegL6sT0RuaC3SDiq2PjBwYJmIjdKGy+Mrox3yFy3v3jK8c2DMeDe9ZGwHBxq+gES2ekW7AtT4iuoroPI0cBNsRiZ91sSw/PrAKmawAltCD46JbdkC21iNCxawLIPIwOmSklJYxbBBU6CbaJzLYp8CQFKJCIIpuoK1xLSBGIwP7ZK779uYDcfcqEL0+sA9I3I1qEyDxxRAc9Vd4EPH0b2QYqZbXRN2SKpX9CUC0OJUAcVjiBMICdGjwm/wgnDR5y/tIiYwIUAE+AOVeqVWWCYg8TFITySQx8RxUSOVGB/jYFfdVAnH5ANTtPtUWU242EHEncLoXeMzViAdExfaJZn130qAPY8xtfYX7Bvas7D4gO6bLAYjE7pYuSEe8n/ByRHaq9sgf0YyqvheZLS0PrFJbBVUAee+TaIVQ7TADokCFyCGhMjwghrO6yFUCESqcZg/Z3gMbiJjCEU0oFGI+ENdI++GbFKVfk58bAZx/hXgsUC1xymaGdNWKAtCItv4ueuHkfq6AGAkdprifCMECItpr6ATTtUIzLiRFQORh8EtrRANEaBZi5PDAusXPaoGIWUQgUcBI5OIAETVAgcapQ5GrEZeh7pcBalHXFQG1g4Cw9RUqTq0O7BOdSatWpW4ARMPMUm+c1Ik0EGUtEwT6gEg6bZy1rFrKAqAGlCDkASIaZYLgvlUImV0VA1F26nQeuogoEgl9H3UZRijkgMDhAgC9dnAkwYlQiTT051+hVpi7oYRpGNb4FYBo8YyLABjJAeJBEozq7y8LrSKbFmp6VTNDYT8Ql0dW92LQSY0euyoE4koC8XUDMheIUIm7hUIsAOKwaIgTIFIvcYW0KP8KNaeiZSzlsM+T1a0gGIBoMYgBcTeAlgPENVJ6SXsV0Uyi4r8Eouwm5QHx4PrwOORpXVUB8SBwgn/iMiYXLhAxjl9bEwU1YBWvMC5EBzH8ln3ERNFBNdJQxf4KFafAh+XmensBiIL16g+mAZPg8j6wPxuIcgUNU4QknnE0cTRdIvQbTXDwMGlEav4UMZmDsTGgR+qqCIgrKNS4GjEkuSMLF4goWGL7kA3ElfXdUu0nrCAq+4g19leoKicqOtyMSgxAVCAQvxCNHHIc3EOzbMlIeFVELotnmAhGd3x5zwhps2UMmPeNjAgErqCjDgGBwt5xHqYoMTaWk0AYyEBt4C+G25ixFCLVRWgFiPiGQJiu5T2gOq4GKRpBaSCSShRvOEC0SKHCRG51YJ1GLbhGkm1O/CtUQKTJRuSTKE+RvOSfAETGqL0wnNLXMJQKWUet7MWEHBQYWUeRHtuNRHv2JFMNhEQ1WUcd9X170PHCvDULi6Hr8IoiRlTw8rrKR+gQVYZWgIh3h8fpWt9H35CceCdFrXNAnkmxoxE5bST6F6iSA0SbFIzJhg+s7RnYl6zUjCdU+FeIT1aAT8yYDqvFQ1WtMr8BiGW45KRJNI+IheTV0+X1YXQW5cozD6vn/Hdtd7SCVw/aQmseiHvx0eiLoDc+jM9q38jqnoNJtuM0jFgVy9tk5XCAEol16BUyT1wV42iR1CWF5ZTVvZijF20AUiwrnJmvcBwEB6jiawf2jOyh1b+GrwDEhllWxQvreiLbklrzQPQXSg2d/U+bjF3XKjZiX2GTxPRrAYiaFR0MLOv2ctkyEKgaiG2p0j7eIFSWQwBiZaxsgBA6cLI/vxsGK+yqPRDXYV9DUwTVXwGI1fO0BEUgjpap98iJEP1C3YG4jq6gXqjRpa4kEIBYCRsbJrIyDBxWahjbcBGaeCGZlmrizcJX8A2avmdh6pCgvRyou0aMVmiesC1XAGJb2Nok0doDscl6lXgtALEEkzqWJACxY6wOGeVxIAAxjzvhWcc4EIDYMVaHjPI4EICYx53wrGMcCEDsGKtDRnkcCEDM4054JjjQCSdZAYgBbCU4AJgoe74SqZtJEoDYDNd67h2stLZtYUEys7eBqE3jeg5ZDVaY7ylq8NWSyXsbiO0x6ynJ+o2UrP1AxGaRXl357+FvsOFvwAWi9pIFQxruJMt4ydJOssrmtXe9zY1/2YJ0PF0AYnmWO0A0XrJsJ1nGS5Z2klU+j55NGYBYXvQOEJmXLO4kC/vnSKtJX3WJk6zyeVSccqwRehONJK46bQBieY46QFQeEMjYnznJsrxkJU6yyudRccq+SUVQoiwLaxQ/GM+pxF34hc2t2m/Yhdw3VpYOELmXLOMky/aSZXa3d6WqE/GgyrdPBORfFWd+Kb4vnjcRnQ8l2/c7n/HGy9EBIrYFGy9Z2kkWWmY28O0yEBfiqaRxXoyJ3/JvmvMifmwwS1+mXwgx3eSAC0TuJUs7yQIQldcZlLW7QJyM43hWcGw2JiDKv1HU3w94Tvb390cTswRUET/R309AlH/ZQ/F+p/8g/8XBwbk+dQ2yaxEF7+90gWqVHwci+jOqj7guCqmdZFm+6roLxMH+OJ6m0k1Mx3Ffn/wbjc3PzU4tRZPzcTw3HU+Pmad90eT0/Oz0/Bh72DkJjPX3zw4OLvT1obDF11TfwuASfVA9eDEgwt+W4yVLO8myfNV1FYhjc9FcHC+RpAaFRpR/++KxqG9KxE1MxDGUi4rvi+ZxuxSjx4io5GHbBT25BNWHr8K+pvqANOtS2hG/UyZt39zgbL8ekrW9sLXIwHKSRZ6LdnMvWcpJFvmkIyUpfNV1FYiL/RFUohifMCACezQwWRLwm4zjRQbEJcIl3hljD9vJeqjAPoMp0tp9g4Noeos7qxP9g4Ncdc734b1e0Y+Y6uL+thwvWcpJluWrLnGS1U5hZtPuQ18KuoPUBQMigtT7mpVxuFFP++I+PBNA7GcPs+m38mSyf3BOacEpoG+puW7fJLqSTJv29cJ4y3WSRYeOcC9Z2kmWQKLwVaedZLUisqbfnaWmbSGOF0CBAXFRtNIqzgYinrUfiKQGVds6PzdYRbs6CZpzUrdOzS32WEPtAmSdzdpU6CXLzab8PQEwiiBytFgMiGh5qds4yZSefAqNKLqMGEPLpjkSKBVUqvnjqMHZqse+/YNSyU4vLPVKK+0RTHucZHkyKhnVjzYXF1QiAgDX5Gzydz6eWuofJKxNR2PsKYCI1NR3FK21elgyu6JkY7MLajQ8PTe41C6tpbOZH6wa5kU1rMPz9jnJarp2E3Nz1HlfogZrMBqbi6cn1F+oDdzQ9E0/2uK5MRk/OxVPoeM4j/+gL83DpkvAXlxKVBV6oRhBtfuaWJyTTf/cYvGop92F6Sj9NjrJaks9OiqeiUXVeZttlxr0MEm10lML7Qe+J/suRbXRSVaXalRRtpOzC1I3dWM4O7Y0KDoD82L1qKIa1ZxM+5xk1bziOcVTOIjnB7s3dJicRR8jnhrsoC7OYUl41HEOTCQT1VMLnWyPvdWcwHANU+VigcmbIESepByYVGOFvpqMFcYWqYmexkRBuHqGAxOyX4b2uFaDhCUsumNqv1Zl6hlMdL6ikxKF0ws1HB5MDtKwqZcGLp2Xfz1ynFykcUE8X5P22MOUMHDxMCUjam+Tx25nkOtY9JgQMvph9R6eJgOX0EIXAWNjbrAfmxU9sOmNYPoiBy5z9f5eimDS/ucbcU/lkpgemVpo3/wI7Vsg421hvq0NuGG7OIco2I81qOD6xapnGELnwXnDAXFJrpy0A4VkLcZNX6kDmn3BoFtYdJcyjp3FdM603MyTJ40efraxgJhM1cxVM0YeTk6Fw/4tQFBZ6ijoAWdkvY2L1GM/dnotIYwNLtq0UaWc7iu27RmD4RuM3noYaQVV30BATKZqKpsPwc6L1TGyt9YQBKJmCXQFPKPHSEVNN3b9JXCE0fdsLs4mqVu7ENrnDOZuFCDqqZqqOv1j/f/nb77yeaXUYLfdtNHsBLP/7lvIMTrrB+KnsGEnXB4ObAwgChvH6qZq+s3OgRgQXMrVZB6meaJoY6DSrLQbwa/5FjHFPV1G4XpyOMmjNgAQ1cJtBXCBMLEunajB//m//ua/V0NTYWSsf3BBzLEjhylvR3aMBvxhKkcxjP3WHogTYpRcjSnL2FKyeQB2YhNwkDEwwDhRWZC6nRLrcx5DoIkwlePldM2BOEtiq8a4T9mJ6X1OGKy0BYiCzxOzcvPAfHqHX5jK8SGxzkAcExYN0xXM1UwmsIitnZ/tBCLxOpnynHfXf+RUTlWjLp9UN2BcfYHYL9ZP5lrv2qt9VCk7sXYDEXDoT6yDBu1VIJrKmWq9ZhsQb5lFrisQK7JbwfY60V3z2m13AIjg+4TcT+isSC5h/DyYKZUefFBLICpLvhbl0Z8MTbL2UXUGiKhEMgka84E0bZ/FvtpwJRyoIRBlm9yqbfOksNbH3GP2PqqWgIglP7oWyYNTxqwhB1liL4ROqgIfzeRgs3e4JAfqBsQxGlO2vttDGup7hqxc7o0BUZhEYKVZTVvLGRr9d1quTGOJMAtccAkhdrouqGEKHAwkXk15qXo0XC8gyjYZfsNauiSV4kmfkkC016M18igwD/R5kSl81nkqIQfSfck4hfyYhtVnyaY6AVGosamFLI3ikasnKrHcnrOHqZ6EUVQIRAFBocUE6sgYURhFpNtiNM9kAwFY6uR4RRhROFknKl9+a/DLEs8rBekk7LHb+gBRtsm6C9WcHOQ6zHR6FtlHLheIS82vR8OsFivPaq0vDUexcj4l95rCOgxOncMV1QWIAoYtLuTJRenyvmeygZhMRUNdtWISMZEJx0kxRyo6i/1QoXIex5337i101gKIY2Ljpe7ENyeBZHzSwDqMH4hqfAtr19Y6CUk1yEpMD3Cw71W2xLLK9OWNQXX2jUWL0ZTEY3O1b/db8Hvf8NUQ+2oAxCpgKI1mpxpTKgAineHFL6wFUnfQmvHjz5sOMxtwBUbZF8GHg+b5NRPxX8Vwd1/bS39Kgj0l/zQy6Ow6EKuAoTCNAHgaFKMLxGTeGaswaq6vQYKFyfuVbxQJRrGpCqN7msehq9EKFOZXXQJZwAb/NqLiuwxEAcOk394k1ybF7Fwz+5stIPpX4posU95r2qkngTHpLP7zN4WIu3kyYV6R8YxcnTd49TW0htlVIFYCQxJhc8swDIhCN2EevWFuNyicJLkG4/zg/3vjd1EBCURxHENzFNv91skMxKpgON3slI8GooBhp3frGzD+KIGhOIGm3Yhqkv7JC8TKYNh8xyoBooChWuxoUk5NvqbBKFpmzIA3Saf9r52sQBR9o1b7hpBeS5vWBRC7CEMJHwuMHeoaNA7ckxOItYChWOL7J9qK0B1tyMAgpreFUvwRi61V8GQEYgUwlJ265htlKeOBv/tKHWAYLV75XkLhf7n/sUtwPXb/t2sFQVmYkw+IAoYttahRNTCM+usBQwh67l8fO3r02LGHbjv9tNNPv/+hY5ccPfrVmqHxZANijWBIjfJX/qkGyudPjj1y7E+2nIbrdAKiuDbff8nlj9UJiycXEKuCYYvGEQQ+8on0lb9LLfF1HJcPHHvksbtO27JFAnFLAsPTN+P64iWXX/JAxwuUkeHJBMTKYNj60JI2jMz370uvNWeIoW3Rxx65DSAEDAHELVwjEhI3b77/8q+2LevGCJ88QBSbeSvoG1YxxE220I10G4h33nvb+QKHBEW0zFCI/4Z04mahEQmJZ331sw81hpg2pT5pgEiGXjWBIe1aEsaoXQbibffeef75AohQhqQRAUHdRyQUbv6JzWedddbjl3+xTeBqhOxJAkSyeGrN3K66eecJaf8HKXQXiMeOEQyNRtwChWj1EQmKAOJZHzt6TyOQaU/akwKIAkQtncIknGhV0ShHEXmGS8yTugnEB26HOtzCNaJAoUcjAoqXXdYedDVA9SQAovCU2ponNgLPfOtDFPCddivpzcRdBOID934CILQ0or+PCBhuPeushy7v9vB5wwNROhxqCUT9aEsrcrRKPluNe4XuAfET9961XcCQ9RFFw+zXiGdt/WK3O4obHIjCxKa1MYqY9GmpXTcNEG2ZY+uCXQPi927/9HYCoq0R0UH09hGhEbdu/dhnuztk8QJRnUvsP4uzRoaxrY9RIhptV+SMfxJrKfN8Q0+3gHjXvZ/e/lxXI2IWETDM0ohA4uXvNF9U50MeIIrGjhbJ6fLsia0NEKlJjVvTZcL9OdNhrQhgwoxSEjJdAuIDwCEuRyOeTtM32RpxK1rnh1upfovvpoHYfwjiveaGq666+Op37UfQdHmSrGoCRNI/cWs7RMUwpzUkG/YDh+5X2yUg3v49wDClEeVYJVsjbt36uVuOm+p0OuQCkdThzA0v+MkfO+WUU049ddN15+LWcRTQGBD3DgystaFSVcy3VNgqw0shcMibZaozgHiwDXUvIHnsTtKHKY0obB7yNOLWrY/f0z0kOkCkzdiH3/oCDcRNm147o6fFEgY0BsRoeG25gHONP5ZjFOcDaZBMla2yH4cExOEGS9V68q8dEzBMa0SsruT1Ebdu27r1lve3nn+TFBwgQh+++Dkv4EAcIqVozY40CMQmC5b3mhijtHawTaWtcgYOuwPEewUOm9KIGLCckcf3dj6zQdYfxy9/3nNe8JNMIw4NDe2Pz+EbwrsNxArGKFWOlUk6vnYZ0d3QiMduk0D0aMT8UfNWUon33NOtAYsFxLGZ+ILnAYiWRhwaeovdOHcXiBWMUSJqlVubfLR1QwYOyQHVip2y7XcPPHJ2pkYsGDVvxbXts91SiRYQ5+KZ9xAQHY04eqaVqptAFLPPLa4JCyhXNVYmZGXhMIp2dxqH0bHbEiCmNGLRPCIUIv67554uIZFDbCyOf+75Ho04Oro/Zs4qugfEKsYocklQesyqRj9l47Aa+o1Q+fbtZ2dpxMJ5RKERt13+zu6MnDkQZ+OZ5wsgOhpx5+hPxzOGHV0D4hLZerU4+0w0plsbbhtOiFCdcBjdfpcCYkojFs4jCo247cOXdUclciAuxC+UQHT6iKOjL+LJugTEKlpUso1pcS3GgSF5H0zNH7ppOnevFOL5zY2at27btu3yM7qiEjnCpuPXZWjEHfuViR142h0gitnnFltUsuDva5GGA6p64fBrd25XLXNaIxbPI0Inbtv2+Pu7ohIZECfi+D1+jbhjx5lxn5ZAN4AoxrkttqjUO3QX4XSlmgzUC4fR7Z8+WyLx/Oc2s7KCUfO2bb/enbaZARGTiM/3acTRodEuA7GSFpWwXLE6pNahRu1yFN2e4HB70jRbFtq59og0dUP/iba5G3OJXiC6fcQua0Syn27ZUgvqMG5tMcajNEG0RTXtIdp81Pcew1BFts3P3f5cx/pGbJ7KX2sWGnHbZb/bjbaZAXEyjm/2acShnaM7foHN33S4aaa9SK2OlSMiYpkKNi9t9iY6M8nuFBbZxeCxuxQOPRqx3DwiNOL7H+8yEKP5+Key+ojfZNqko0AU034tH57ENjRViJOx6Xier31WSLo5Uo+cLTTibz7zzPbnPulqxJLziN1qm5lGhJeMC3waEX3Et8WxMXHqJBDJC3nLu5rGYLk4bdltNCdn9625enUQo+iYwOEdP/jCFy694wvcQvvdH/3oO1665fTvFFjfUB9x63nbHjmjCyqRA3Epjl/iXVnZ8fPc1WjngEhTh63tVibs0KRNyrrXBVUT97Nt6HQ2UQzzyn8EEM/efsfnn9y+/cmn7+AW2pfGz7wjvn7LlbkW2nJlZdu28y4rBOJ8lSuksgIciNEM2mbfWvOrZ+IFU99OAVG0yq1tE0WhacRd9aSN4AVWVNi6p2FP90K33UZA/MF7fxNTN0++g2nEZ+L4me9cv+WJuJxGvOyDRRpxEfqh4k6JBcTFOL7Jt9Z8YTzDpoE7BESxGNdygyombSrmmYTafDzdFrrNA/kxAcTPxyeewU6BpwiIzzzzHfL0QEDcctqDcXza6V+//vrrT//4E1/fvPmTD95Hnh6e/eQTf45dfPddi+vPrr327dCIH/5wERAxrq0aihYQMS126CVp65tX2m1QR4BYkeEq5lcq2rHs4gOUW/5KXJot3ouW+ew7AJJvfIeW+H7zxKVPnbj03VueuhQd7ae+cyKO3/GOr18Zxy+9NH7N9Vfiz7M/sfnBE598Ov7oWVv/HGme+LOpN74dfcT3X1a4yodJiIqhaLNzciZ+Wcoe8c0zbFkFvOoEEKtY0IN9VlsmbQRclmo2c0OFwkIzmuYn30EguQOjZvQMz//D+B2JRjz9paQRT8Pfj59+aXzi2Wfj+MHNH49PnHVtHN+3dSv+fvTaJzBmPm/reZf91wdxJG/eBVDTVWEDbQMxQuN8wVtte8RXzlgNcyeASO1pBf06VKZd83xjU/G8AGSN/hyXGhHDFcLIpdv/Gg3y+WiV3500zYAgBiv09/Qr4ytP3xzHb9x839TUfYDgtRiovBFIFKPm88677G9/QCTKXJVB0QFitIBde69jKyuPXogI2/Sq3RpRbNBrvS9MQ+52TNoI6GFpj/Waa4JGAuLZ29FBfJKg+NeAnADiMwKIp5EuxGZSBcTNAoib73v2jWisr4Wrh7dPxVeKJT5oxL/9RhkQijQtL3klzHOBGC3NYFfzVcl20kdvxZ27QNtmIFayoBdFNAPZOpozIIYOYp2W9pJSSo34fdoq8ORr4ju+YAFxCwGRacQEiJ+cemOiEUklXkvziOdtu+w/PdWXf303AWqLxvKMvSkgivkOYPHIkVe8Yj+ym0kt0DYIxPG9LLvCoFjQS2VZ+JqboG2TNiIjLO2x6Sw3767dS404g9mb7effEf/1dwiIT6mm2a8R74tj6iMKjfjRE/Gloo8I+5vfLrBJFIOVSs+PSQMRM8AyGwL9lGcerzEgjjeyt7eaBb0oolPbq5jDXvLrhffGM1d6nnh41UlQHj/2PbTMZ3/+B5jQ3n7ppdvP/378h+e/NH4pm775+lOqaf6o1IjQgk88HceffPvWrU+//UFSidCIH/7cGb+dX/AxwkZ12pAy8wERs8BLg8Ro/zHZjQHRezppxnHl/4KOwO/939RB5mZ10WXPRCotRfzR70OR/0P6UeO9OnQzG7m6bAEhJrTP/sYXvv/0Hd+/492YR3zppfgPOMQ4+ulnTnv30/GJj38d0zR/eP1r4hNffyKOr3z2PnQM6d/b//zKE9cClVMPnnfe1sf/tAiIWFSqFoZZQHQFbt1XAMS5RsSbfd71ZGNkGj8kti/u801i/Oj3fbHT7RqiW9zPufkwWYHR9eR2bRgr/SOSQ3dxzgo2rpArd/xLrvuePeusZ5/FWAUX9jXT5A0t8RVYJM5XDcNuAbEiTdPfIBAbnoFu6JtLJ15eO7A7BziVP5KdRIHFxB4RlrEEQuwSSIBonyognLkDhRKIhEWaR7z8jKIJ7ew2quk6+ZvmXHJphucl9zbNDZHITgwg5mXtPGt3VdPlbJMDKqde+vY4zMC2J1sFgEZhGMs1Iplo297ApDN38l4sFKK0vjnvaKHRg86yukC7pUPeDkZSxU3LLJXERGQnrjsQvXU3Fas8hC0rSeMMr3TCHtHWiGiSt1C7rM9ZSTSiBKIAIzQiBs1FGrHyknevaW6gXx+AWFbuX7uzVY1ISyuP/0HQiF6OByB62eKLpNVm0UVsViOeB42ILmLQiD7uBiD6uOKLO0776wUS9Qb7xvuI1DIXDJp9ebcaF/qIeRzM/gY8b6UTd7qPGN35NbV7qvk+4j0f7oZCzJjQ9rDZRKUZbp6lQ15hNEQiO3EYrDj8fuD2ZDdpsxpx63lbMWYusot1cq3k1q8R+wdplW9qbtE3YZQNDF+JAhB9XGlXHLl6yJ5HLDNq/vVbutIy+zSiWPBVU8Uez1kBiH4YpfmCdfb01JX/5Wpij992rMU+4lZsr++GQvQAURxv8b4jdLzFp94APKaMB9IMz+NiL2vEjgMRVtrYY09Xs31EeKWrh0YU6vDIRfx4i3OclbHeBuLEIi2UTy/Mpkwo0nzpPBAfvgvub3A120fc9si3mULctStPxVT7zOkjiuMt6bOqkgAAIABJREFUbmQW2uJ4C9s+MM3wvCKV1ohjs2RJ4ICeKGfn5x2sTC6CjK9z61Q1r9DqWSpr2sSgLrepSCWOOg/ECLZgBMRmNaKtEDuIQ7dphukxjrewPMbS8RbWmCXNcCU3329JIIrREYl4Zs7FYnZ+aSCOLSikTKcOpaoAiGBPfOjI1RdffOs1sFhzTkJKl7MLQIzOeIRw2KxGvNeazO4eECHZF6d28eF4i/0cYmmG86duuBQQyS47nrniiivIJty18M/OLwVE2ucQvwF0qHPr2pa3DEQq5eEbVa/lW8jLUorpcnYDiJE8eKq5PuLjn+M9xF/sGhDHDsWHPZ4e3mJvhksz3AUfvy8DRFI0R24Up649ejWwaPdKs/NzgEj7A2ZueL2gc116t02rQMThH/GLWa+Fmgru6yFdzq4A8TgdxdecRvycPYfYyS6i3TQPxjM3+zw9nGnJMM1wDjw3XAKIsE48dKM5Ywi5xXzfYHZ+NhAnsT/gmp/VdMT+Qz6isCrhFtN/b2WNwz9uxhk0SiNuGhp6rbWHykos6HUFiJE4nLQZjfhFWmVmy3u7PujnSltiuXTG1PEWVh9xaKil4y2KgYjtxy/+WS7gt+y3dlKnBaw4YQOxDxthn/PjDCjYkW0cLrdsaLQUx6+jbgsD4ih8sRi3I+lydgeIx3FcczMa8WOXY8TM5xDzWuY/Fg/zUkS5D5UI9S8Hoj7egnEb3z08F/98PKXfyBnFmjQmVAjEiRnZL2UChtMnhqC0gBV1C4jA86scoPyM5SuFV1VRKPhlWaNhfuHzHfqjVkFZ4oRsd4AYHf/e7dgq0LA94me/aOnD6AN5WCvWlr/VPBD18RYpjfgiPnBOMzxPnIVAnJf+dixN80qOoOz8OBDhLSUNFLTyZsDfGhDRbYHPPkcj4gAak0G6nF0CYnT8zmM0cpaX2CpAuwVwOGmehfYt9wOHfBep6CISmnZFFPytXV+mwGd20Q3+0F8KUAT+EQZ2Absf2IW/SQoRmQcO9oxLZxoHT3n9I462cLxFERCxIeymtIB5m5cWsCo/ByJ6cGmgvPocNpzgVVUUCn5Z1tKdrgvE0XOMK12WOCELIK4W5NCmx3fe/mkBxNIW2h+73BowU7F2fSmKvgQsfVDg6TMErij6C/lDQXGvIuieHn0Z/z4gnooUlKrcxaRjjrdwNCJ8aDd/vEUREOfifw/0uwJ+NRsGpAWsqsaBOCUOiXHpQGPpThyrqiJQ9GuyRv/5I+ly7sQxhXrgbBIrsgDigAp3+PcT6Cc2oBG/+IjTLvPiCnW3KxKzOYDXr+LfX/wiJSCs4d+X8Q///+quDyYp1QNOpCjMpAOxJsdbpPqIbQTiTPyqtIBHR881ezPTAlaVYkBE8CU+OgzQrKqKQNGvyRpDFWKOC/QdDOkmsSLbRSBGd937CQCxpEa8/7PvtPuHqgbyl3Qi/qeLQl9O7oSqpAiMrunnt2QKYBR3socpYkr9YdIxQLQ1YmvnrBRoRD+Ado7+O+MsOS1gVTMGxMH4sAcoOzmgWVUVgaJfk7XwL54C4k5+OJxJrMh2E4jRO2+/U6jEEn3Ex2n+0OofqhrQ75clzICtryahXySkfSn6EqlFQmAU/TGa8V1/rO4IodCfn8Hj0heTDrarJ8db+DSiboGqHTX7ATS6401mp2hawKp2DIh9dCJCCihWn4JVVREo+jVZ+4E4umOHoWoSK7JdBWL08LFH7iqjEe+//B7CYeb2ADEuQcO76wPHRbOcDEWi6DNQhdRO4/8PkDqUCXEX7fofdKfYUOrX8DHC8RY/B1mi+bE14tCOoR2sT141EHGSgQsgnOxSDRCpD6cngnhVS/GG21ssxofS5RzdOfrLZthcNyBGx995+9G75Ab7zFHz1h/echlNH2bqw5KcajkZl44+3iKlEX/NsJtLp0zuBU1zlqapBojVacRkJJfqI+Z2IbqrESGdM+46euxXqG2Wnh7SFtofu+UWGMLiytSHZWRcRRoORHTI5fEWtkZEH7GF4y0KgIg805oGOphNoac1jao4a5rFHKirWaGx2JFZvKqKQsEvy9o7Kt+JtZUFRYMlTqK6DsTo+Bm3PXLsNtFN9MwjPnT06A/rAUN73QtTFPJ4C1cjvqiF4y0KgOifFhniZ66lBaxEz4C4RIeep4A4umPGLFu3BkQ52+9qRHBmSZUmXc7uAzGKHj7jd++8/ehDv0K+b7hG/NidR49+lcbKNdCGxEFLOrCCEcdb2BpxiJZUmfVAmuFKFL7fAiAm5645At4xygCUnR8Doh/QozAc0iW3quorajqOZY2J91elgZ4/8V4HIEIpnnHGt6H7jn31th/KlZUf3v/YJUePPiRACBjy1ZQ0CzoVY0vncLLcZtbbaK35lXzBreI+Is5dm3lPWsCwa9EAYmhwuMKACEDT+W0OoDF7M63fsauqo/MCPGvYVNDRH4Y1WIS3OMMTS6K1ACKKQlg849t/+tCxo5f8t/98ySWXPPSnCQiL/CDm8abiZ7Z00CUnw1hbI7Z2vEWRRoQxwQUpAL1txsxn54zSORARfnmKjmWnZVe1FB85tmgx2wGiZfPgKWddgIi6Piyg98AffPdfFAZrowulJBzpoHF+IUyyzGe/aehnzrEa5qo1YoThyssdAUORnaNX5jwCViDiQBSq1aFz3YxZgHN6IYpE/i8HYoTGmXhjrIQKzdVqBESoxej4ww/3xfO//QH89/Dx41HXB8oW7x0giuMt7mYa8VEYsLR0vEWRRowimCvcZDd5n7JKZaHBKrwFRDIvf6tF582wazR4trvDFp3MGzvrBbDibgNEcMaMhEDCTixodm+t2V8lMoUfOw4Q1u+yRE7FE8dbqI0Zj179hlaPtygGIg7PgWXsj2lN8yFsFhhknPIIOHlqATHC3cwNTGPBLtYMafFGqqosj4ygk/UiKL7s7otOOeWUU6+7FaXcb2zMQMBJTCRrBkRwyP52Mqrdjei0dOh043imsuMtioEoTio7pI522USKhuPQJ+CEUzYQ5Tf0+gTQYqeAnlqhF9JVLWS4iy06RCiOk81Zdik3ABBx0Dkus1ZbWP1OJvBJZ3aeCiyvOeujFyVzpZNf3BJAjNC/w7aVT9168cXfOhche+9UeSDKI2IOY7vn1eKIGOekIl9V88vuyXpWQBGFnFoose21XhoxcaHPeisF1e/kY790xmYXxPEWLq9FydoARKEUJfJTu0k9aFAMcjQioumQ8ORKnUrqr6qi5f31VnUpYwO/J3GtgIjBlrisZsJb7W5EViWdzLKX0oh4e3J2DiCaH0yzySPgJLc0EHEi6SLpLN8RMe2uqqecdQIiDjqXl16TzJRZNx60Wzo97cy9VoMV3d9i++C6gbiMPAMQMxgjoj1KLju5J3GNNCJ1w5PL2+HKrldnnrQdiN6zRjwyy65udmJf05xNp91V9ZSzPkAcG1yaQG87/h2MnK05iWx+dfZJu6UTLa+N7E5VySOzVBodkZ04AFEzqVQAGnEp6u8zy++l3upMorYD0VuNbGx5kmcn7goQcWAmrvSslm90Xx+NSHxdAhDpd7aOEziZQMTBn9r+hUpvrmxgmDQFIT8JZOljkT8x5ZABRJxL6ss/s6q+xDIunfWi6vOXcp8HII5nU+/0E3QT9b6JTuddmJ9XOnIqRUymeJCRlk5hLm6CNInJ2QUxveCZv0knVuQ8QJSzN+B42lWnt6qKlP/XzVq4z6OVFazvpSY83cQguadbG+y91cE3ZLtc9abqUqRHOuTdTV+uk0EU08PwRgufIkGruOqad5q9VGKdWwqIlh96y3kh3vFUVVPKCDhZi7Xmq6T7PFprtpeAnMREcmV9JYNyF6InwWCHtV0oRVaWaemQ1cOhl936S6ec8htiwc1ZKGsHEGkJd+Zlt74eWb6L1vjsYZ1HwEltXCCSH/pDR+5G0a9+F3DieHRNVzWLKTrezhof6KGrGrK+0YRMYFIs+KqPzvc7lepYLPqSWXFlFpCxslLPKUTBHFc6wtmlsXUSVmCOPrelY1jcQMgmMQvoX3MRGSuceuqpmy4+B30C3iOwE/NcHCCiDwTzG2XFQx5drUUEt6qcUkbYyhpwaNJ9HqeOMhdd9neIl9X6ds6LPIuM8EJtDR6owI50yCQLzi61NDdtuhjytDljSSej0gXRFgmYhcPMz2T5Ztjf8E61ldgibAMRQDnM/dCTR1decqeqFqWMG551ExbaPqooMwZTOde8VWhBoi9eyHmhvx8192XlxEG0s05UjW4d6cBI9XUwLjWo2DT05gudNFw6TdbEIkEbZSyDVmeTjJXYytACIoDyMsdCGwa2rFPkVMOilHHDs25iz4qPqlVmXwKeZ/LcE2W9WUiTUuN7N/uArNdrcWNLZ0ma7TMLbdo8ZRnuN99HZM0t5ywa1JscAME/A9s2yBODZ4yMJYC+tJ9FeKWbN1y2q2ric0Is62Z28fkoW2X2JWB5qseeKPVI/BbSpFTgcy1nspOaWNIhr6geH9rYysQ7w0VsSSinfqYHNYYYCXyo2Exta8RRC0EsMdGcmNYNDBcA4TlFBy5jTeNsVTVVOm8Ey3oOfkBT9MllrC4NS+wlJiN5mb3JPGQ8UdarhTQpNVpmwwvr9VrcWNIhZ5ce3zejr7Vs7ovYklWvhXhKQZGREF6YXCCOAkG6UWWJBenpWEGRC2CavDCl6JzJBopWVbMKacezrJvx9GATk3e8zL7nvtkxVgzvK4U08RZZI056365HJJfOpNhDTsLkfURy5n4uV4lFbMmqGHVSEigyEtJNraMRR/M8sUL3JVBkAkDZyZWZS+dtDNC8qqKMEwrrOhCZkEhhyonCv8dDf0eu7xsfJ1iZfY+9PR9TDP8rhTTxGmaNeLPmJ9TFWC4d7czd6SPuJFfRpoxFbDEpnRAAlEDRkPADyPLiZRJLemA7LtKKTACzXm9dFqB5VUGJTnubJijqAAslJTdZL3r9Lw7tYEg/Ef8oeS3vh5XZn8zkqZ97ovQzChTSFEni1PykRaTLN1w6C8KLsE8jvogn+0b8O7Ts3/j1TYEg0oqGsxkAIk+sijNufn8lyQCKTADCA3JaI3JXt7wOoL0g4MwDJkplbcqZ4bVsdIemOhbH71Xv5fyyMotUY+4Cu8lTU3GjJvuVLpdJXJr6RRPAZDwbt5n42oQ0H1Ei2Q0CEFMa0XLm/t4ECM3/TJ3Q/Wa/gLl/RAg46wKyFSP9jjotzcqritckUUhUB1goIWsQkFVO84lSOUvoHAs0Y2JfAzY26GFccdM8kRzqrgdJZTQiGh4zqlI8q9UvY17SDfJoxB1cseQAQ4q0xN9vFgCRe4wlHmZcmGtXzPQDMc8/oqSJ/rsOsFAKiEs+93mjo9yHdmrmX5XN+uVANFu9ppZ0IgN+b9Sg5oVZe+U09UtWYKHeczcoKwMiqkOe3VIa0fWhfWl8grb4NX59N+HhAtaW1UyC1xOr7THWze/KhMzU4B8ZIM55XRfnaUSxbkYrODrAQokUTTnx+X0kPVgh+noIcMJeELKAYG4YaICOmSN3n3Lqxe8ChrWJhslTv2SiyPzn0A2/ccov3YrJeu2Bg9HU71gBWjBTHLce1OfGC0R31GxpRN/8Qrn6SADR8bWMsxmjUeZy2CSW2YDtuGj8zQTgBTQ01n4jAFZVQWhwKu4TTaIORCYks2JZC5VLrYVay8ZUP+gzn86XolTFjDBlhm57H7kDwPo6X41keSpqJgo4PEIlSNbkk66AoanecH6xBmiO+XCe1eSWSQdtIH30KY0I/cT9ZjIUNVYH0cbKU5QNZzGt8Lq0phniAGKJRYbEVTkNxASQMb3yalY/FixbcJa1330exlR63ECauriTqMuMEsuzTgGqTUNn6ndZnqqYOgrYvVl8CvQOXPtMy76lpqlecH8xd7PgxtXsXtcf5ZKHK3n7iN9kJpWaLQ1WBVxUh3kzEgs+v4Y738LKxRKLHOfVbCTXiAC0b0L7tZVNaGe5z9Mts2jYi9s/DZp5HEmsQTWEQ7ETVLnVRZ1VFGGXvQMmyfw0zQyJgPO1nsymYjOBYzWSfF2mNeLQDlQZDWpyKbao+7K/7Ex5RgJMTPs1HIVYNFmWmOImk0lxBLkASFmkpm+wOGk0Aa+qJp4f4Fkved3nMXdj1NfkVkN+0qrM+L2ZgWoILJYDFp5nQkJFYRXqefwdtW6kaPpzFOYO5nvJSNTtaC4d1Ec6c2cdIXk66ZkMF/r7bLToBsoWiQW4jHX7XqahQiZKDEl+Y2aqgwuAvNKlgGiZa/Cqliy7lXXafR6KaUa7KCeuQsKqzLS0yUGljyay8pTkVBRWoSwgqo6HopmROTqWU4z5Gam6HG1JZ4oO+ExrxFFLsbjAKKrAyu50CsVZegIEXeAAUbc54k2e2CZlCQA35O2WDyawRs46bdaNTSjrzspaus8z9NMn2AOIbHbPT1SVmQY/FhDVYqGVp6SRRE2SErXeSYZiiqY/R2qYHdtmf8KuxlrSWaQjj0mYhttCI55rObz0cCqnCrsHBtZTjy0SYKNl0Dr02hnVXxIvWoktUrYAwHDLoysZ2Mo+lHzJqqpFJ/PGzlrMnSjXkZvIApxPROMD/b0S67mqzCkgvilRp3aeomhJFF6FnmD9SqVFFU1vPdCxLNFj8L7ayUhbOonxp7OyYhvfNKgRSzhhok9WTErQXgExlTGjh6LghUcyCYdsAZBjR7anJLXlwK5qKSa7WVNJpfu8awDDGaZuRTmfxuOiNlCVOQVEdbKMm6fhAF6FcVSjQNwQDbM9WMFAIHFYbmnEt9jmiDnA8Am3BBAj2vR0+MhvwBPrL11tTe4Kgh7JJBkpoap8aZfdNbQH65TX04SvpQ/dqqp3cn9TWcv9pCCNa8F0VgURJC4xb6zKTOe2WKBSRxOl8jSf4hQ1WByIiTWkoumry8ZomFPSgdUamklLI6KhZEND1NXDKR8HkrgyQIysbaDO5ruc/FICkB5dJU5id1tqBRoRdZpcJPd50wtLDgwFXyB1M9pH4uW1VLdElRmmTi+xQKWmxj3sVVGw7LCACKtNUQpF0yOGSRS2eCjvebHTUa50ZDNpNCL1yK2Gsi1AxEyMWMoHhOYWXQkrMaRZ4xHA7MK0wOHUQmrY4FY1TS8Vk511KqngyyTyZuPoaG1g4KCTUpUZSX+KAxEdWtmqe/JUUVATN/F39icYUzSdrOgW3ZX6j5ipoCnpiGby1ovELvJTP5RuKNsERBRlknaqUZmcS4nBicatXwDwXOKYSck3U1VNE3RjsrN2U+KeEqNDZiYuo2hkYGDYSanLjE/+JtPMmokCT546aj4+JLdYqtUY2ZfWNJ28pK1b/UfMVOy0dGQzuf/IkVd8Cl0ud5c6XtFsSVXbF1Gqafa9qOOy88sWgH6ZBdJVZQ/9weysPekpsWOQnwdEgFYelkGgwgkI8wlJT546CiPg972Vmit6x0wKZPJhAQLcEA2zD4hQNHOEQHGxDU+a9ZotOiYv0FtApLlGphJzgThBQ6vXE6iuI1MaNVHgYa+JAtBnbkBzdeqpF+83pq5ZQCQcWr4K8gTV5WcZamJiEFZeC7PeuQjDljJl7y0givMRTP8iF4iRGFq94Ypz3wC8GONCD3tZVD91gfdfcS6pCj1JmgHEjYRDT9NciC7GlsK00cnoQzvPfR6dZWIaw3wgRtGiHFnF/AQED3t5lJ5gYJMCfiBuKBwGIOZ+SxwBMiEO/hDgmR80ei8hIRNTL1EP2IuASIcgDA7aHvTSebq98n5sF7IaKy8QNxYOawTEfuoNzFkMlhL2SCYRvU8AcOgKOoPpab5Kqkr+otTFVJIoT1JOTJgkBl35o+akDqkfT3U9UdZrPj5sMBxWIh2LKe5NuT7imHTTSTKedqcbssWQFsDEnIJJPO+qrIzusFtgfu9kLVylXXMDlm4uznafh0Lp3luxRuS5ybCTJ0V6oqz30nwYIxxOqfGPlbimN61Lp6BipYBIPhnj/UdeIWeMTMdd0M4WQ0oANB0fXwE611DAMknwTxAUFN7OWpyXeZHaKiDWsvloTiUmDCSNc7eAKIY0GwqHtdCIQtHQpAQZPXzoQsxQWEpRCTgNGgeItBB8+O4EKFdjesM+PbTVbw4L8Sn3eWryj8qmyklTOIn5GVZWMie0RXXgJNrtjygyrLp2lJjRsPoeDh/E0F06D2BEah5ULHOLiX3f3mUOpLPZ4r7o3hdrRPK0IKdphfUNTe7qto2oZednC4Dm5eBJU2ksccwpb56zquqWmN1bWZO7Mdve8ZVWQXViOmxMqiNUPg+IegRs9vB5q6spo2ja7IJ9rQ4fwM+0SQarVS2DXumohd+puUXe9iQV4GwprlMxENGevtwSMHlkZN2b7PxsAWClwj6AHCfMn8MWrr1Vza8Az5qW5BzDW2wmZQU1iZcABDFgyQciNaAzn8IKFiYSzcZmQ0aXjUVR5+Nw0vfQXRiLD4ukkA05TaTmAY909DeHCqU6WqgOY0uJyhUCEVx0LavhlW6/IZ2dnyUAD1DeYmksT1VNJv4Qy3qyEfd5NIdDfnVygYjSz9wgl+vIyFYZS6g8mQpQUcLJoTjZ+tRT6TzqqeQzY3yQ9kdym6y/TjWNTUuHvrn3HblKGAfSt2q7zkc1DFvK1KkIiJgBTu81gX2TXjbIyY8JgHYIpf0sQmOZxpmHy5TcruogGubUnhhyn6cz4HxZoG94MReIVHG9bnzdfo0qRWZObXlkHEeFXyY6H8n6dLIlSvNhkiwirenxkhXtfjLGSFEYUofMzFmeJ8/aN1s6JcpfBMRF3+47avN0pkoy6cy0APBozguU/dqWoNVRs9xra3UhhkZ3Yruh/mKscgokzv3vpI84P6j1my4z9mK91VjfXKetjxUZaFUFRRWFYdAFz/txZfQwpC3nE5oTItN4XueV5lh9YxwgYmRou87f9CGMPu29iIot5SpVBES/B4Vynli1UFEU8u2Y1lg/zQDtVLVM8U1Vx+h7SdPnToFMYiIt/Nr861/+oxis4GvrS2Z0VJnR1L+c2xaipLJfrMggRwVFFbUI7PJ3LkzMcAXNJbGLkDclZWpYmzSOdLBpBR1+y0KbnBCo/osotmJLuToUAdELoJ2jFxojluz8lFBRkiW/k6RR5lrYqWqZ4pushe/IFBCF1zKluk1iQXoSbUv8+c//PcFLzOhMLVBQlZl8pHBQad2qyUhgkVZUUfhoLQvttyXGtKA5i4EPrimjesvUr0ZpbOngy31Vehffhdy1umFLuVoUAHHJD6BynliVUFESv9u4UQ5ou6qlSq8QkEl/xw5D1SROaFNvGxfWG5NGM56fHVNlJoeOFhCVtx/tDhJ7AsWlfVZBRzp7VpLtBaAprulaHvdYitP2hDYaZnxyrkYcQjtpDEoqBqIXQLY3sJSAdc2UUBEhWniPxlLiRRIDGU2gKGCyzipnHhCjib9PEGJ+pv6t3jXq7GtG20zFQZOduhIvfqiufzvpP4g3VONfVKl6PrekI06ISGtE8lysDUo6AUR42XqTcZpg0OCysBCIef4RXWK+e5N1lrexX1ZbTbx8Gf7Hv/wPDqzQCRc5pbaTJjWmbcju9V05IsoE4u/jhQU9evdVpP5xHIj4GD/i9fSABo6pRCOdMtUraJq9mgYeGd9UCRDz/COWKbypKnjjceY+hMHKvCJkEqsYMX0DayDZfxPwmvvnpGLk0NFpmiWl31PuJ7+Z4LGvP6GMpvkjVh9Rubz/I/M16Kw3WoADUXz1Pk8P3C+q98vPqXUBEJe8fcQdVfURd7BBD69qToH5I4Yt7+kHO3ecmzF9I6noyid6bro/e7Dyg4SSzlMOVvqg6VQUppAsIGKwIkbarGXgpd9QYS4d4RDd00dES8kHzoot5eqpZcGTMxLeUfMQH2SwxJwGwkwAfkDvrGzUDEfv5CrNmUccAhT0jIKnnLryKCkuMgdSZQY0X8U1op4a12RobppgaIAIH43WXuhf4NM3Dm822i0HonbmLuZZpQWC9AbGP3z9fZarqpYFT66ZTUz2+DXc+SI27cIScxoIK6FStBfQ1LtVsyutDVYoL4/7vHOZ/0VPOXXlCYh9tvbCTBnbGvpmPSBUZDChLWFogIjB5AsZeF+pnCtxPjgs2jC3DIiozkvw0adHzfAYywafFQMRM0Zpv4ZNrawc9izBVbeyggmitPs8vbZB8lYIYrLXQByMp5wJ7QieP9+nl+tg56FOH1Rk5hQMGeUlfA16NeZDGrsnHxATZ+5pjdg+IG6UtWaf+zysy+kFPgYXg0QNxHntKMeABqiaIetJrBuTka2ywVRAFPpTklJRtJCp/W5jnUFh19A0WW+0kK0RS50qYNhSprJaFjwxJwEubgTrG9ERsN3nwXCSm5nxSiWV1ZU3qGKgoQ0wh49cJbYdGOtCDxkTRRaMM9fccPHVZI4izs2inBhNzuUNFWZApNkB2TSnNeIvmBU3XxOUU2UtC57GcBax4O1GsEcUBY1v0Ia3ZIeld8VT5axKydp6Ks9BY3xGadNCLxlOuZ/GMOIyOyE4TZnxxvvLgAhO0rgh1Uekc1bY2MHH8Jx6e2ThMLtSC232DaHtMjZaKKF9l1Nk84gjALHCLxBOOcE4TrjPs83+nMRExVN5GzTiGCl7a6qHjBU1tkQbWi2TZZumKf5GCnHpyBNrPSsrrThz98jCAWLUtj0r55gWETLhVS0pIgsBeEfa9s9ccQWpJNOaSmpuYsR6Kl8IGg8ZT5RVgUKaVup63nDpoD7v8WhErPyy9QMXRUXV8sgiTcLs4kPXh7nfEMSzxZASAFp5+JNp1y4+Kk3/YLJM0peyc/GU01P5VJldBnrIeKKstwppWqnrecOBiFMhLxBAZO2bmEfEgmr+6DCnbh5ZpIEYbYx9zbKak3DO4Nm/7+uyeCpfCBoP6jxRFscLaVqp63ljAXGJjDVTfcQhmMoMUqg9AAAJ9UlEQVQVjA5z6uaRhQeIIFCppwePQ9cqmuacenor5am8Axo4pnBQ7UGdEzU5O2g7PHFo5payrg8tIGKaCibAWMbSQ0MczjXEjucStXDYUlAzjyy8Mssmk51fYwKwq5qdH3uSnTVLpIKexAcHBkbU4+TXKnP/PPUl4DtOrxN6eWNRTvoGU3NmR4BF08lvo9za0qFzvrB317bQtnYyoV4WWwrr2dNAHM8Fohz6SBdz+nBSH3sZx8UWyzdcgf0bbLB08gGRpkYPwaEu14iYBdFOhQTsGFsKYegdODaI5ez8GhOA/c2VKHrr5cwF4iSGPYevEk43zwWPlYLzVNdEYQE6PnIj3nn0VsyGLySVaIwPpWre8USudGi2/8hFBoi0d8pxe2XYUqa0QSPaXDKggZmXOvJ2E45uUBafHvbqKFg9yC2WWBakCfVkWdDQtPPaSHcuEKPJC6AU6aPDrO2jV78LXyAbMIuaabaUqmcAos0mDRpYe7xKND20R3kI/Z8EVR726ijbYudMtdisadpZbai7FBDhxhTgizFpKzoirjpE5TRbSlU0ANFmkwINuuPcpAsjwsSEwcNeFYWGmdswvvmcRI0qmnZOG+vOA8RoUp15QitJ6eootqSf+GLWBwYOpOIbIpGduDEB+KqaKpkdkZ21nU7ceRLn9BGXHCNXvZPbQ0ZFzQG7zB5xSFlbNsYHT9FrEJUhHZqqciardGEVW3REbmB53+p4KkFDJLITNyaAjKqmCscisrNmiVTQkzgHiJ4j0OTYw0NGRcFy2QLiaGIf3hgfVHnr9dtu6fhrqzjrf+rEZiduTADtrqqnnDlATO3iKz4UErsL3mMDMdkx0xgfHPbW5Lbd0vFX0yMzf0KKzU7cmACaquoC+Yksd82nhnVRI0B8k95n6o4OFQdQXazAmgHOUKljcrMZW6snTUknxalGq5SNLQ+l7MQdACIN3EpfKb6spDvIqswpjVjq4PCgERlAsoHBEuUH++JpuP4veU2lNU1CHUItSYOSNfHNiQmE0jicElvueM2P711b4fcIKyDShm5Lu6mNrx72qihsabU04quTKimaTlYb6rYJ6Si2tFBP4/u/lJQ9Q3eRebJbuBQNSmSZJ7ZQ/FZeVaBZog4fa2bfNpNsTPWwV0VhS6sFROzdEkVRNFspV7ff7Q4QJ2lMXvpKHZyrmQbTlQYu5jZFU+h4QINmGqhiQMTGVLnxVaGOlUxF4V3uyg57t+RAW9Nk72y0YHeAuNG4VGF5NWgIVQaIZmOqQh3LU0dhS+vN5h2NXU2TvbPRggGIHZaYAQ3Mya+5SG4nfRSWJcobqkadKZiOwt7bGbF9C8uCZAWQWI8ZmuadjRbyAxFHeaBLhVPgJz310WzxPAtRRRwwoBkDj2dwjNWp130LGyT0RiwPe00UnZzxvrsvOuXUi7kVgKFZlHt9n/uAKDyCU+ceF9wGuZdhi/sk3BdzgINmEaZOyWVmfjzsZVG00Sy5jGg4zeIS1DNFGogTh1HRw0euvuriW8UR9mb7bFIDxpZ61qnWpbJAMymPOp0WTo2z2WtxfGlO7GyeZ3KxaNa69tmFSwGRNsIdoa6LcMJE56S751tYbMmmHJ54OeCCZrK/355V8rDXjcJKj3YtRZm4NL0Z1zzSASJtdj90oxiYJd7A0I3m7mJRHZctNa9hzYpXCBoPez1RVq0KaVqp63njABH6kI6zMxbam4ZwkJg9E1zElnpWtC6lKgSNh72eKKs6hTSt1PW8sYGIGgmHSByIQ7C/ZAeSBY3YmiALQeNBnSfKKkQhTSt1PW8sII4dig979jU72/iK2FLPitalVIWg8bDXE2VVp5CmlbqeNxYQ0TDfTEDkfUTsa7YP4Qx9xJYkWQgaD+o8UVYZCmlaqet5w4E4Js5V9Hh6ePV+Pe+PWhSxpZ4VrUupCkHjYa8nyqpOIU0rdT1vOBCxjcLvH3FUWQ+LOhSxpZ4VrUupCkHjYa8nyqpOIU0rdT1vOBBpG4XfG9jb+MC5iC31rGhdSgXQFF1mlSUpNK23Flx1qV7T5eBAlEeJePqIO3aw02BD09w0s+nFyQJE4TFzhCOzokWG/Gu6pTLV4WUGRJiZ0kmw6T5iS6cK1KGStSoDllLyL4+hyUT+G85CS62qW7YwDIhoNNpwqkAULZctS0jXwxzwAtFaWRkiH9rNH2+xsjpwsIf5G6pekgMMiOi9JE2zO4+4owUgel2OlCxcSNY7HGBAjPRgxdaIQzuGdiQnVAu+NDZqDkDsHTC1UlMOxEE1fZPSiL/W/PRNbwNxZXh3K9LpoXc5EJdotJIeNaOP2MKEdm8Dcd/AahirlfqcOBD1Ep+rEV90jnZOCqKhaS7FWZFoYGAg7YKq/Os9lJIDkQ4juymtEVszeuhtjRiAWPZbsoAYHY4PvSS9smK8mQqqQSOWZW4UBSCW5ZUNRCyukGGsPWqGYey5nFwAIudGfjgAMZ8/5qkNRGqcX4hz1bmF9s+co5zqJm8FIBr2FYUCEIs4pJ47QMRIJJ65imlE8kHQ0uap0EdUrA6/eRxwgRjRpu8jN6rtpFdj59R+e7tjGDXn8dN5FjSiw5DM2xQQI3Ga9aFP3XrVxd86l2yPPNZxqahM8hkH/uSkP7keBSCWlWcaiDjfIjkJlmA456hD0A19xLLMDaPm8pzyARHWm4vk12LaOTczoRqAWJ69QSOW5ZUfiLlvByDmssd6GIBosSPnJgAxhzmtP1oNS3wlmRiAWJJRzSUbCUAsybgAxJKMai5ZAGJZvgUgluVUU+kCEMuyLQCxLKeaSheAWJZtAYhlOdVUugDEsmwLQCzLqabSBSCWZVsAYllONZUuALEs2wIQy3KqqXQBiGXZFoBYllNNpQtALMu2AMSynGoqXQBiWbYFIJblVFPpAhDLsi0AsSynmkoHIA439WLPvRTH8w2cvS2SZh/k7eNeb28VCED0YcIXx2xgyQ623JV1kLcvgwBEH1dCnMuB/gYO3lZJsw/ydqnjPgDRw5QQ1XkOBCB2nuchRw8HAhA9TAlRnedAAGLneR5y9HAgANHDlBDVeQ4EIHae5yFHDwcCED1MCVGd50AAYud5HnL0cCAA0cOUENV5DvQ2EA+EtebOQ86fY28DEbUPRg9+YHQ6NgCx0xwP+Xk5EIDoZUuI7DQHAhA7zfGQn5cDvX0oZOgjekHRlcjlla5kW49MAxDrIYeeL0UAYs9DoB4MWB8YWK9HSUIpepoDy2trvdwz6WnZh8oHDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDgQOBA4EDvQMB/4/TKAz95yY9dEAAAAASUVORK5CYII=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EB_NYPlWdBC",
    "outputId": "0fc28eb0-2c85-4435-f641-5fa585a141c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sentence length value:  114\n",
      "input_vocab_size: 452\n"
     ]
    }
   ],
   "source": [
    "xLengths = [len(x.split(' ')) for x in X_train]\n",
    "h = sorted(xLengths)  #sorted lengths\n",
    "maxLength =h[len(h)-1]\n",
    "print(\"The longest sentence length value: \",maxLength)\n",
    "input_tokenizer = Tokenizer(filters=\"\",oov_token=\"UNK\")\n",
    "input_tokenizer.fit_on_texts(X_train)\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "word_index = input_tokenizer.word_index\n",
    "print(\"input_vocab_size:\",input_vocab_size)\n",
    "X_train_encode = np.array(pad_sequences(input_tokenizer.texts_to_sequences(X_train), maxlen=maxLength,padding=\"post\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rA3sXud4rkcS"
   },
   "source": [
    "## 4.Enter the example using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxIekrnfrfBg",
    "outputId": "dda223e9-221f-4441-b09a-6c4528406e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input String :  một giọng nói của người trải qua sự bi_đát mong được lên tv some day\n",
      "Encode :  [ 39  18  57  22  40 176  82 112 113  14  23   5  10 114 115   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input String : \", X_train[0])\n",
    "print(\"Encode : \",X_train_encode[0])\n",
    "X_val_encode = np.array(pad_sequences(input_tokenizer.texts_to_sequences(X_val), maxlen=maxLength,padding=\"post\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzqNhkCQr7gr"
   },
   "source": [
    "## 5.Generate Embedding\n",
    "Function takes the vector of vocabulary in pre-trained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Td-ML6bqWdBE"
   },
   "outputs": [],
   "source": [
    "def generate_embedding(word_index, model_embedding,EMBEDDING_DIM):\n",
    "    count6 = 0\n",
    "    countNot6 = 0\n",
    "    #embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM)) \n",
    "    embedding_matrix = np.asarray([np.random.uniform(-0.01,0.01,EMBEDDING_DIM) for _ in range((len(word_index) + 1))])\n",
    "    list_oov = []\n",
    "    word_is_trained = []\n",
    "    for word, i in word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model_embedding[word]\n",
    "            word_is_trained.append(word)\n",
    "        except:\n",
    "            continue\n",
    "        if embedding_vector is not None:\n",
    "            count6 +=1\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    print('Number of words in pre-train embedding: ' + str(count6))\n",
    "    print('Number of words not in pre-train embedding: ' + str(countNot6))\n",
    "    return embedding_matrix,word_is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRIghLqMBuhV",
    "outputId": "2758237e-50dd-4bf1-f34b-2323db72a071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in pre-train embedding: 424\n",
      "Number of words not in pre-train embedding: 0\n",
      "['anh', 'em', 'cho', 'lên', 'đi', 'ơi', 'là', 'rồi', 'tv', 'a', 'chú', 'có', 'mong', 'tuna', 'không', 'chị', 'giọng', 'tuân', 'e', 'thì', 'của', 'được', 'vợ', 'nhà', 'cháu', 'năm', 'ko', 'còn', 'để', 'với', 'khi', 'ạ', 'show', 'và', 'bị', 'đã', 'con', 'một', 'người', 'gì', 'thấy', 'cừu', 'hay', 'xem', 'nữa', 'mặt', 'tivi', 'lần', 'nghe', 'kể', 'sống', 'video', 'thứ', 'ra', 'nào', 'nói', 'đến', 'ông', 'như', 'giống', 'xong', 'phải', 'đấy', 'cái', 'nhưng', 'lắm', 'chuyện', 'nay', 'cay', 'vào', 'sofa', 'này', 'yêu', 'ngủ', 'ngoài', 'đc', 'vài', 'về', 'thật', 'sau', 'qua', 'nhất', 'có_thể', 'cũng', 'nghĩ', 'nên', 'mình', 'nhau', 'tuổi', 'đó', 'làm', 'mẹ', 'clip', 'someday', 'lâu', 'thôi', 'mà', 'ngày', 'năm_ngoái', 'live', 'nhớ', 'group', 'chờ', 'biết', 'vì', 'nha', 'r', 'k', 'quen', 'hết', 'sự', 'bi_đát', 'some', 'day', 'thích', 'cj', 'phết', 'lời', 'buồn', 'bây_giờ', 'vs', 'vui', 'anh_em', 'v', 'quý', 'trong', 'chứ', 'tiếp', 'chỉ', 'đợi', 'chu', 'cứ', 'thồn', 'sao', 'nhỉ', 'cô', 'từ', 'trên', 'stream', 'lại', 'vẫn', 'sống_mũi', 'mãi', 'liệu', 'tập', 'mất', 'não', 'đăng_ký', 'nói_xấu', 'rất', 'đẹp_trai', 'nghĩ_lại', 'mấy', 'câu', 'hỏi', 'đen', 'tính', 'vậy', 'thế_nào', 'mọi', 'vãi', 'thẩm_định', 'tưởng', 'lấy', 'hơn', 'nhiêu', 'vid', 'nhiều', 'tôi', 'câu_chuyện', 'ghế', 'giường', 'chơi', 'trải', 'chào', 'ăn', 'món', 'xinh', 'gửi', 'chúc', 'sức_khỏe', 'sóng', 'mãi_mãi', 'ủng_hộ', 'đọc', 'radio', 'a_vậy', 'hoàn_cảnh', 'đỡ', 'dell', 'muốn', 'kết_hôn', 'đầu', 'nhì', 'đít', 'mông', 'lòng', 'ra_điều', 'các', 'bạn', 'à', 'ôi', 'cày', 'view', 'hơi', 'oi', 'o', 'quan', 'phuong', 'nao', 'chu_cha', 'loi', 'hehe', 'nhẹ', 'lạy', 'cụ', 'tổ', 'ông_cha', 'bà', 'xin', 'rõ_ràng', 'ngồi', 'chồng', 'kề', 'xấu', 'cảm_giác', 'cơm', 'chó', 'ấy', 'anh_chị', 'tháng', 'sinh_nhật', 'ba', 'tự_hào', 'may', 'dựng', 'thành', 'đê', 'https', 'www', 'facebook', 'com', 'groups', 'đau_thương', 'nói_chuyện', 'cố', 'phim', 'n', 'like', 'mún', 'dung_nhan', 'đàn_bà', 'qué', 'á', 'triệu', 'liêm_sỉ', 'cảm', 'tội_lỗi', 'trở_thành', 'youtuber', 'mạng', 'tốt', 'đánh', 'bao_nhiêu', 'từng', 'đang', 'tạt', 'nước', 'hay_là', 'đường', 'nước_mắt', 'tuôn', 'trào', 'thương', 'vl', 'tích_cực', 'quảng_cáo', 'fb', 'tránh', 'giả', 'phát_triển', 'tận', 'luôn', 'ư', 'chung', 'tin', 'read', 'love', 'gợi_ý', 'ngoại_hình', 'cao', 'm', 'da', 'obama', 'gọi', 'đồng_hương', 'trẻ_con', 'thay_đổi', 'ny', 'cũ', 'thèm', 'gym', 'đứa', 'bn', 'trả_giá', 'đắt', 'lỡi', 'tay', 'tìm', 'tồn_tại', 'mk', 'đem', 'hào_quang', 'tổ_quốc', 'chj', 'khác', 'ở', 'chỗ', 'quên', 'trừ', 'đam_mê', 'đam', 'mỹ', 'lí', 'hôn', 'oxygen', 'not', 'included', 'đừng', 'bi', 'bản_quyền', 'nhóm', 'nhé', 'lão', 'nếu', 'bọn', 'giữ', 'thế', 'vô', 'minecraft', 'rìu', 'chém', 'giải', 'chả', 'lẻ', 'mai', 'khổ', 'lam', 'review', 'di', 'hôn_nhân', 'quyết_định', 'đấm', 'edit', 'vẽ', 'phần_mềm', 'giờ', 'bố', 'cx', 'gặp', 'fan', 'exe', 'cù', 'thơi', 'truyện', 'xãy', 'hello', 'tất_cả', 'đều', 'hôm', 'xin_lỗi', 'cố_gắng', 'nek', 'hèn_gì', 'vụ', 'mơ', 'ngoại_tình', 'ghen', 'chắc', 'đáng', 'sợ', 'xự', 'bình', 'an', 'bếp', 'lửa', 'ak', 'haha', 'cute', 'ấm', 'đá', 'khỏi', 'nhá', 'moazzz', 'cuốn', 'xử', 'trước', 'đệ', 'hiếu', 'pc', 'nè', 'sẽ', 'ai', 'hút', 'ô', 'mô', 'kappa', 'zing', 'speed', 'mobile', 'hãy', 'bốc_phét', 'lớp', 'tính_toán', 'kĩ', 'sinh', 'gay', 'ạnh', 'lô_a', 'thử', 'game', 'night', 'with', 'nó']\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix,word_is_trained = generate_embedding(word_index,word_embedding,EMBEDDING_DIM)\n",
    "print(word_is_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjvoCKFAsKEK"
   },
   "source": [
    "# VI.Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8oYeHeBL-wqO"
   },
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "\tif K.backend() == 'tensorflow':\n",
    "\t\treturn K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "\telse:\n",
    "\t\treturn K.dot(x, kernel)\n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "\tdef __init__(self,\n",
    "\t\t\t\t W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "\t\t\t\t W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "\t\t\t\t bias=True, **kwargs):\n",
    "\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.init = initializers.get('glorot_uniform')\n",
    "\n",
    "\t\tself.W_regularizer = regularizers.get(W_regularizer)\n",
    "\t\tself.u_regularizer = regularizers.get(u_regularizer)\n",
    "\t\tself.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "\t\tself.W_constraint = constraints.get(W_constraint)\n",
    "\t\tself.u_constraint = constraints.get(u_constraint)\n",
    "\t\tself.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "\t\tself.bias = bias\n",
    "\t\tsuper(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tassert len(input_shape) == 3\n",
    "\n",
    "\t\tself.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "\t\t\t\t\t\t\t\t initializer=self.init,\n",
    "\t\t\t\t\t\t\t\t name='{}_W'.format(self.name),\n",
    "\t\t\t\t\t\t\t\t regularizer=self.W_regularizer,\n",
    "\t\t\t\t\t\t\t\t constraint=self.W_constraint)\n",
    "\t\tif self.bias:\n",
    "\t\t\tself.b = self.add_weight((input_shape[-1],),\n",
    "\t\t\t\t\t\t\t\t\t initializer='zero',\n",
    "\t\t\t\t\t\t\t\t\t name='{}_b'.format(self.name),\n",
    "\t\t\t\t\t\t\t\t\t regularizer=self.b_regularizer,\n",
    "\t\t\t\t\t\t\t\t\t constraint=self.b_constraint)\n",
    "\n",
    "\t\tself.u = self.add_weight((input_shape[-1],),\n",
    "\t\t\t\t\t\t\t\t initializer=self.init,\n",
    "\t\t\t\t\t\t\t\t name='{}_u'.format(self.name),\n",
    "\t\t\t\t\t\t\t\t regularizer=self.u_regularizer,\n",
    "\t\t\t\t\t\t\t\t constraint=self.u_constraint)\n",
    "\n",
    "\t\tsuper(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "\tdef compute_mask(self, input, input_mask=None):\n",
    "\t\t# do not pass the mask to the next layers\n",
    "\t\treturn None\n",
    "\n",
    "\tdef call(self, x, mask=None):\n",
    "\t\tuit = dot_product(x, self.W)\n",
    "\n",
    "\t\tif self.bias:\n",
    "\t\t\tuit += self.b\n",
    "\n",
    "\t\tuit = K.tanh(uit)\n",
    "\t\tait = dot_product(uit, self.u)\n",
    "\n",
    "\t\ta = K.exp(ait)\n",
    "\n",
    "\t\tif mask is not None:\n",
    "\t\t\ta *= K.cast(mask, K.floatx())\n",
    "\t\ta /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "\t\ta = K.expand_dims(a)\n",
    "\t\tweighted_input = x * a\n",
    "\t\t\n",
    "\t\treturn weighted_input\n",
    "\n",
    "\tdef compute_output_shape(self, input_shape):\n",
    "\t\treturn input_shape[0], input_shape[1], input_shape[2]\n",
    "\t\n",
    "class Addition(Layer):\n",
    "\tdef __init__(self, **kwargs):\n",
    "\t\tsuper(Addition, self).__init__(**kwargs)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tself.output_dim = input_shape[-1]\n",
    "\t\tsuper(Addition, self).build(input_shape)\n",
    "\n",
    "\tdef call(self, x):\n",
    "\t\treturn K.sum(x, axis=1)\n",
    "\n",
    "\tdef compute_output_shape(self, input_shape):\n",
    "\t\treturn (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrCQ522csUQ0"
   },
   "source": [
    "## 1.Build mode LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b-4SQdfzFQ8",
    "outputId": "dc8715bd-241e-4912-fd17-42b994bc928c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 100 samples, validate on 100 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - 7s 67ms/step - loss: 1.9336 - acc: 0.2000 - val_loss: 1.9281 - val_acc: 0.1900\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 529us/step - loss: 1.8478 - acc: 0.5000 - val_loss: 1.9107 - val_acc: 0.1900\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 532us/step - loss: 1.7346 - acc: 0.5300 - val_loss: 1.9296 - val_acc: 0.1900\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 529us/step - loss: 1.5512 - acc: 0.5300 - val_loss: 2.1768 - val_acc: 0.1900\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 454us/step - loss: 1.4297 - acc: 0.5300 - val_loss: 2.6318 - val_acc: 0.1900\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 372us/step - loss: 1.4199 - acc: 0.5300 - val_loss: 2.5354 - val_acc: 0.1900\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 1.3716 - acc: 0.5300 - val_loss: 2.5033 - val_acc: 0.1900\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 1.2758 - acc: 0.5400 - val_loss: 2.5913 - val_acc: 0.2100\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 418us/step - loss: 1.2972 - acc: 0.5500 - val_loss: 2.6951 - val_acc: 0.2200\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 1.3216 - acc: 0.5500 - val_loss: 2.7463 - val_acc: 0.2200\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 360us/step - loss: 1.2694 - acc: 0.5700 - val_loss: 2.7628 - val_acc: 0.2200\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 335us/step - loss: 1.2351 - acc: 0.6100 - val_loss: 2.7489 - val_acc: 0.2200\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 340us/step - loss: 1.1873 - acc: 0.6100 - val_loss: 2.7253 - val_acc: 0.2300\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 316us/step - loss: 1.2135 - acc: 0.6300 - val_loss: 2.6967 - val_acc: 0.2300\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 1.1986 - acc: 0.6000 - val_loss: 2.5614 - val_acc: 0.2300\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 355us/step - loss: 1.1232 - acc: 0.6300 - val_loss: 2.4942 - val_acc: 0.2200\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 1.1724 - acc: 0.6300 - val_loss: 2.3774 - val_acc: 0.2200\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 312us/step - loss: 1.0760 - acc: 0.6200 - val_loss: 2.2791 - val_acc: 0.2300\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 317us/step - loss: 1.0301 - acc: 0.6300 - val_loss: 2.1742 - val_acc: 0.2400\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 325us/step - loss: 1.1095 - acc: 0.6100 - val_loss: 2.1395 - val_acc: 0.2300\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 333us/step - loss: 1.0336 - acc: 0.6500 - val_loss: 2.1309 - val_acc: 0.2200\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 348us/step - loss: 1.0080 - acc: 0.6100 - val_loss: 2.1276 - val_acc: 0.2200\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.9853 - acc: 0.6000 - val_loss: 2.1378 - val_acc: 0.2200\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.9412 - acc: 0.6300 - val_loss: 2.1551 - val_acc: 0.2300\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.9581 - acc: 0.6600 - val_loss: 2.1773 - val_acc: 0.2200\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.9923 - acc: 0.6400 - val_loss: 2.1798 - val_acc: 0.2200\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 364us/step - loss: 0.9618 - acc: 0.7000 - val_loss: 2.1909 - val_acc: 0.2200\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.9689 - acc: 0.6600 - val_loss: 2.1990 - val_acc: 0.2600\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.8805 - acc: 0.6400 - val_loss: 2.2242 - val_acc: 0.2700\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.8690 - acc: 0.7100 - val_loss: 2.2582 - val_acc: 0.2700\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.8896 - acc: 0.6800 - val_loss: 2.3052 - val_acc: 0.2600\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.9144 - acc: 0.7100 - val_loss: 2.3267 - val_acc: 0.2700\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.8124 - acc: 0.7300 - val_loss: 2.3658 - val_acc: 0.2800\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.7387 - acc: 0.7000 - val_loss: 2.4291 - val_acc: 0.3000\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.8172 - acc: 0.7200 - val_loss: 2.5084 - val_acc: 0.3000\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.7448 - acc: 0.7700 - val_loss: 2.5643 - val_acc: 0.3000\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 0s 342us/step - loss: 0.7877 - acc: 0.7300 - val_loss: 2.6066 - val_acc: 0.3000\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.7648 - acc: 0.7800 - val_loss: 2.6211 - val_acc: 0.3100\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.6951 - acc: 0.7300 - val_loss: 2.6202 - val_acc: 0.2900\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.6717 - acc: 0.7800 - val_loss: 2.6006 - val_acc: 0.3200\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.6878 - acc: 0.7900 - val_loss: 2.6182 - val_acc: 0.3300\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.6333 - acc: 0.7500 - val_loss: 2.6798 - val_acc: 0.3300\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.6169 - acc: 0.8000 - val_loss: 2.7105 - val_acc: 0.3200\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 0s 420us/step - loss: 0.5713 - acc: 0.8100 - val_loss: 2.7506 - val_acc: 0.3200\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.5620 - acc: 0.8300 - val_loss: 2.8585 - val_acc: 0.3200\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 0s 404us/step - loss: 0.6112 - acc: 0.8400 - val_loss: 2.9813 - val_acc: 0.3200\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.5880 - acc: 0.8200 - val_loss: 3.0915 - val_acc: 0.3200\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.4820 - acc: 0.8500 - val_loss: 3.2030 - val_acc: 0.3200\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.4813 - acc: 0.8400 - val_loss: 3.2936 - val_acc: 0.3100\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.5256 - acc: 0.8500 - val_loss: 3.3447 - val_acc: 0.3200\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.4242 - acc: 0.8300 - val_loss: 3.3257 - val_acc: 0.3200\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.4616 - acc: 0.8200 - val_loss: 3.3046 - val_acc: 0.3100\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.5119 - acc: 0.8100 - val_loss: 3.3225 - val_acc: 0.3100\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.5586 - acc: 0.8300 - val_loss: 3.3512 - val_acc: 0.3300\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.5077 - acc: 0.8100 - val_loss: 3.4149 - val_acc: 0.3300\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.4834 - acc: 0.8500 - val_loss: 3.5182 - val_acc: 0.3300\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.4298 - acc: 0.8500 - val_loss: 3.6618 - val_acc: 0.3200\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.4061 - acc: 0.8400 - val_loss: 3.7338 - val_acc: 0.3200\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.4405 - acc: 0.8500 - val_loss: 3.7926 - val_acc: 0.3200\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 0.3463 - acc: 0.9100 - val_loss: 3.8773 - val_acc: 0.3100\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.3452 - acc: 0.8700 - val_loss: 3.9023 - val_acc: 0.3000\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 0s 354us/step - loss: 0.3660 - acc: 0.8900 - val_loss: 3.9084 - val_acc: 0.3200\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.3582 - acc: 0.8600 - val_loss: 3.8847 - val_acc: 0.3200\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.3739 - acc: 0.9100 - val_loss: 3.8626 - val_acc: 0.3100\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.3411 - acc: 0.9200 - val_loss: 3.9186 - val_acc: 0.3000\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.3046 - acc: 0.9000 - val_loss: 4.0196 - val_acc: 0.3000\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.3570 - acc: 0.9100 - val_loss: 4.1454 - val_acc: 0.3000\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.4211 - acc: 0.8500 - val_loss: 4.2590 - val_acc: 0.3000\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.3070 - acc: 0.8900 - val_loss: 4.4089 - val_acc: 0.3000\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.2857 - acc: 0.8800 - val_loss: 4.4930 - val_acc: 0.3000\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 0s 345us/step - loss: 0.3311 - acc: 0.9200 - val_loss: 4.5480 - val_acc: 0.3000\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.2646 - acc: 0.9300 - val_loss: 4.6089 - val_acc: 0.3000\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.2758 - acc: 0.9200 - val_loss: 4.6768 - val_acc: 0.3100\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.2707 - acc: 0.8800 - val_loss: 4.7287 - val_acc: 0.3100\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 0s 323us/step - loss: 0.2059 - acc: 0.9600 - val_loss: 4.7490 - val_acc: 0.3100\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.3456 - acc: 0.8700 - val_loss: 4.7245 - val_acc: 0.3100\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.2437 - acc: 0.9200 - val_loss: 4.7394 - val_acc: 0.3000\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.3969 - acc: 0.8500 - val_loss: 4.7202 - val_acc: 0.3000\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.2331 - acc: 0.9200 - val_loss: 4.6897 - val_acc: 0.3000\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.1837 - acc: 0.9300 - val_loss: 4.5898 - val_acc: 0.3100\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.2122 - acc: 0.9100 - val_loss: 4.4847 - val_acc: 0.3100\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.1821 - acc: 0.9600 - val_loss: 4.3607 - val_acc: 0.3000\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.2019 - acc: 0.9300 - val_loss: 4.2750 - val_acc: 0.3100\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.1970 - acc: 0.9500 - val_loss: 4.3048 - val_acc: 0.3100\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.1748 - acc: 0.9300 - val_loss: 4.3638 - val_acc: 0.3100\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.2922 - acc: 0.9100 - val_loss: 4.5161 - val_acc: 0.3100\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.1513 - acc: 0.9600 - val_loss: 4.7108 - val_acc: 0.3400\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.1731 - acc: 0.9500 - val_loss: 4.8537 - val_acc: 0.3400\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.1650 - acc: 0.9500 - val_loss: 4.9351 - val_acc: 0.3400\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 0s 345us/step - loss: 0.2147 - acc: 0.9100 - val_loss: 4.9713 - val_acc: 0.3400\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.1372 - acc: 0.9700 - val_loss: 5.0143 - val_acc: 0.3400\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.1980 - acc: 0.9500 - val_loss: 5.0315 - val_acc: 0.3300\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 0s 347us/step - loss: 0.1233 - acc: 0.9800 - val_loss: 4.9947 - val_acc: 0.3300\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.2248 - acc: 0.9300 - val_loss: 5.0223 - val_acc: 0.3300\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.2175 - acc: 0.9200 - val_loss: 4.9718 - val_acc: 0.3300\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.1361 - acc: 0.9700 - val_loss: 4.9578 - val_acc: 0.3300\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.0985 - acc: 0.9900 - val_loss: 4.9932 - val_acc: 0.3300\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.1276 - acc: 0.9600 - val_loss: 5.0284 - val_acc: 0.3300\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.2355 - acc: 0.9000 - val_loss: 5.0787 - val_acc: 0.3400\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 0s 322us/step - loss: 0.1036 - acc: 0.9600 - val_loss: 5.0918 - val_acc: 0.3400\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.1012 - acc: 0.9700 - val_loss: 5.1234 - val_acc: 0.3300\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.1385 - acc: 0.9500 - val_loss: 5.1273 - val_acc: 0.3300\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.1469 - acc: 0.9300 - val_loss: 5.1575 - val_acc: 0.3300\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.1478 - acc: 0.9600 - val_loss: 5.1129 - val_acc: 0.3100\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.2187 - acc: 0.9300 - val_loss: 5.0282 - val_acc: 0.3100\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.1161 - acc: 0.9600 - val_loss: 5.0091 - val_acc: 0.3200\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 0s 327us/step - loss: 0.0733 - acc: 0.9800 - val_loss: 5.0333 - val_acc: 0.3500\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 0.0901 - acc: 0.9800 - val_loss: 5.0572 - val_acc: 0.3500\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.1257 - acc: 0.9500 - val_loss: 5.0567 - val_acc: 0.3300\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 0.1039 - acc: 0.9600 - val_loss: 5.1358 - val_acc: 0.3200\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.0616 - acc: 0.9900 - val_loss: 5.2373 - val_acc: 0.3200\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.1468 - acc: 0.9500 - val_loss: 5.3021 - val_acc: 0.2900\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.0857 - acc: 0.9800 - val_loss: 5.3962 - val_acc: 0.2800\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.1606 - acc: 0.9500 - val_loss: 5.4945 - val_acc: 0.3000\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.1122 - acc: 0.9600 - val_loss: 5.5275 - val_acc: 0.3300\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.0885 - acc: 0.9800 - val_loss: 5.5974 - val_acc: 0.3300\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0972 - acc: 0.9600 - val_loss: 5.6476 - val_acc: 0.3400\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.1205 - acc: 0.9600 - val_loss: 5.6832 - val_acc: 0.3500\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0320 - acc: 0.9900 - val_loss: 5.7082 - val_acc: 0.3500\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0932 - acc: 0.9600 - val_loss: 5.6734 - val_acc: 0.3600\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 0s 427us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 5.6456 - val_acc: 0.3500\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0900 - acc: 0.9800 - val_loss: 5.6281 - val_acc: 0.3500\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 0s 324us/step - loss: 0.0567 - acc: 0.9800 - val_loss: 5.6187 - val_acc: 0.3400\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.1077 - acc: 0.9700 - val_loss: 5.5828 - val_acc: 0.3300\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 0s 347us/step - loss: 0.0901 - acc: 0.9700 - val_loss: 5.5908 - val_acc: 0.3100\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0616 - acc: 0.9900 - val_loss: 5.6394 - val_acc: 0.2700\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0907 - acc: 0.9700 - val_loss: 5.6829 - val_acc: 0.2600\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0548 - acc: 0.9800 - val_loss: 5.6807 - val_acc: 0.2500\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.0399 - acc: 0.9900 - val_loss: 5.6787 - val_acc: 0.2600\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 0s 362us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 5.7133 - val_acc: 0.2700\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0548 - acc: 0.9800 - val_loss: 5.7656 - val_acc: 0.2900\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 0s 406us/step - loss: 0.0779 - acc: 0.9600 - val_loss: 5.8431 - val_acc: 0.2900\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0906 - acc: 0.9800 - val_loss: 5.9253 - val_acc: 0.2900\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 0s 335us/step - loss: 0.0699 - acc: 0.9900 - val_loss: 6.0339 - val_acc: 0.2900\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0682 - acc: 0.9800 - val_loss: 6.2132 - val_acc: 0.2900\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0977 - acc: 0.9700 - val_loss: 6.3166 - val_acc: 0.3000\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0357 - acc: 0.9900 - val_loss: 6.6340 - val_acc: 0.2500\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0374 - acc: 0.9900 - val_loss: 6.4717 - val_acc: 0.2600\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.1426 - acc: 0.9700 - val_loss: 5.7911 - val_acc: 0.2800\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 5.8299 - val_acc: 0.2700\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.1745 - acc: 0.9500 - val_loss: 5.6832 - val_acc: 0.2700\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0727 - acc: 0.9900 - val_loss: 5.6738 - val_acc: 0.2700\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.1260 - acc: 0.9800 - val_loss: 5.7407 - val_acc: 0.3100\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0806 - acc: 0.9800 - val_loss: 5.9081 - val_acc: 0.3100\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0473 - acc: 0.9900 - val_loss: 6.0901 - val_acc: 0.3100\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0953 - acc: 0.9800 - val_loss: 6.2846 - val_acc: 0.3400\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 6.4502 - val_acc: 0.3400\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0336 - acc: 0.9900 - val_loss: 6.5891 - val_acc: 0.3400\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.1004 - acc: 0.9800 - val_loss: 6.6442 - val_acc: 0.3400\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 0s 377us/step - loss: 0.0621 - acc: 0.9700 - val_loss: 6.6080 - val_acc: 0.3400\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0829 - acc: 0.9700 - val_loss: 6.5067 - val_acc: 0.3400\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0622 - acc: 0.9900 - val_loss: 6.4111 - val_acc: 0.3500\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0585 - acc: 0.9900 - val_loss: 6.3164 - val_acc: 0.3400\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0859 - acc: 0.9900 - val_loss: 6.2219 - val_acc: 0.3100\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.1114 - acc: 0.9600 - val_loss: 6.1523 - val_acc: 0.3100\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 0s 444us/step - loss: 0.0592 - acc: 0.9800 - val_loss: 6.0761 - val_acc: 0.3200\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.0713 - acc: 0.9700 - val_loss: 6.0081 - val_acc: 0.3200\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0456 - acc: 0.9800 - val_loss: 5.9764 - val_acc: 0.3200\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 0.0603 - acc: 0.9800 - val_loss: 5.9864 - val_acc: 0.3200\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.1459 - acc: 0.9400 - val_loss: 5.9532 - val_acc: 0.3300\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.0629 - acc: 0.9900 - val_loss: 5.9611 - val_acc: 0.3400\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0539 - acc: 0.9900 - val_loss: 5.9726 - val_acc: 0.3500\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0374 - acc: 0.9900 - val_loss: 5.9787 - val_acc: 0.3500\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.0599 - acc: 0.9700 - val_loss: 5.9474 - val_acc: 0.3400\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0712 - acc: 0.9800 - val_loss: 5.8999 - val_acc: 0.3400\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0522 - acc: 0.9800 - val_loss: 5.8849 - val_acc: 0.3400\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 5.8788 - val_acc: 0.3400\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0548 - acc: 0.9800 - val_loss: 5.8786 - val_acc: 0.3400\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0452 - acc: 0.9900 - val_loss: 5.8922 - val_acc: 0.3400\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 5.9189 - val_acc: 0.3600\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 0s 467us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 5.9454 - val_acc: 0.3500\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0625 - acc: 0.9900 - val_loss: 5.9553 - val_acc: 0.3500\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.0437 - acc: 0.9900 - val_loss: 5.9843 - val_acc: 0.3400\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 6.0155 - val_acc: 0.3400\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.0559 - acc: 0.9900 - val_loss: 6.0489 - val_acc: 0.3400\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0413 - acc: 0.9900 - val_loss: 6.1009 - val_acc: 0.3400\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 0s 447us/step - loss: 0.0571 - acc: 0.9800 - val_loss: 6.1406 - val_acc: 0.3300\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.0254 - acc: 0.9900 - val_loss: 6.1674 - val_acc: 0.3300\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 6.2048 - val_acc: 0.3200\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.0290 - acc: 0.9900 - val_loss: 6.2265 - val_acc: 0.3200\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0642 - acc: 0.9700 - val_loss: 6.1835 - val_acc: 0.3200\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 6.1157 - val_acc: 0.3200\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 0s 488us/step - loss: 0.0223 - acc: 0.9900 - val_loss: 6.0709 - val_acc: 0.3400\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 0s 485us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 6.0328 - val_acc: 0.3400\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0346 - acc: 0.9800 - val_loss: 6.0223 - val_acc: 0.3400\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.0338 - acc: 0.9800 - val_loss: 6.0065 - val_acc: 0.3300\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0499 - acc: 0.9900 - val_loss: 5.9998 - val_acc: 0.3300\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 5.9968 - val_acc: 0.3300\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.0395 - acc: 0.9900 - val_loss: 5.9983 - val_acc: 0.3200\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 0s 362us/step - loss: 0.0254 - acc: 0.9900 - val_loss: 5.9926 - val_acc: 0.3200\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 5.9829 - val_acc: 0.3200\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0441 - acc: 0.9900 - val_loss: 5.9980 - val_acc: 0.3200\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 6.0224 - val_acc: 0.3300\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 6.0592 - val_acc: 0.3300\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 6.1017 - val_acc: 0.3400\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 6.1438 - val_acc: 0.3400\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0698 - acc: 0.9600 - val_loss: 6.2756 - val_acc: 0.3500\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 6.4155 - val_acc: 0.3500\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 0s 406us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 6.5354 - val_acc: 0.3400\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0238 - acc: 0.9900 - val_loss: 6.6466 - val_acc: 0.3300\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0161 - acc: 0.9900 - val_loss: 6.7231 - val_acc: 0.3200\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 0s 462us/step - loss: 0.0267 - acc: 0.9800 - val_loss: 6.7826 - val_acc: 0.3200\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0236 - acc: 0.9900 - val_loss: 6.8104 - val_acc: 0.3300\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 6.8182 - val_acc: 0.3300\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 6.8135 - val_acc: 0.3400\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 0s 463us/step - loss: 0.0483 - acc: 0.9900 - val_loss: 6.7767 - val_acc: 0.3500\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.0230 - acc: 0.9900 - val_loss: 6.6971 - val_acc: 0.3400\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 0s 362us/step - loss: 0.0522 - acc: 0.9800 - val_loss: 6.6762 - val_acc: 0.3400\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.0197 - acc: 0.9900 - val_loss: 6.6731 - val_acc: 0.3400\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 6.6616 - val_acc: 0.3400\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.0475 - acc: 0.9800 - val_loss: 6.6253 - val_acc: 0.3300\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0626 - acc: 0.9800 - val_loss: 6.4878 - val_acc: 0.3300\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 6.3818 - val_acc: 0.3200\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 6.3533 - val_acc: 0.3100\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 0s 448us/step - loss: 0.0354 - acc: 0.9900 - val_loss: 6.3470 - val_acc: 0.3000\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0365 - acc: 0.9900 - val_loss: 6.3409 - val_acc: 0.3000\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.0249 - acc: 0.9900 - val_loss: 6.3213 - val_acc: 0.3100\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 0.0426 - acc: 0.9900 - val_loss: 6.2894 - val_acc: 0.3100\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0293 - acc: 1.0000 - val_loss: 6.2932 - val_acc: 0.3100\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0459 - acc: 0.9800 - val_loss: 6.3025 - val_acc: 0.3200\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0349 - acc: 0.9900 - val_loss: 6.3076 - val_acc: 0.3100\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 6.3173 - val_acc: 0.3100\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 6.3357 - val_acc: 0.3100\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.0170 - acc: 0.9900 - val_loss: 6.3720 - val_acc: 0.3100\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 6.3847 - val_acc: 0.3100\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 6.4096 - val_acc: 0.3200\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 6.4376 - val_acc: 0.3400\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0324 - acc: 0.9900 - val_loss: 6.4828 - val_acc: 0.3300\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0628 - acc: 0.9800 - val_loss: 6.5290 - val_acc: 0.3500\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 6.5800 - val_acc: 0.3600\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0295 - acc: 1.0000 - val_loss: 6.6417 - val_acc: 0.3600\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 6.7177 - val_acc: 0.3600\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0159 - acc: 0.9900 - val_loss: 6.7673 - val_acc: 0.3500\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0267 - acc: 0.9900 - val_loss: 6.8098 - val_acc: 0.3600\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0514 - acc: 0.9800 - val_loss: 6.8295 - val_acc: 0.3700\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0325 - acc: 0.9900 - val_loss: 6.8293 - val_acc: 0.3800\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 0s 442us/step - loss: 0.0175 - acc: 0.9900 - val_loss: 6.8333 - val_acc: 0.3700\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 0s 404us/step - loss: 0.0269 - acc: 0.9900 - val_loss: 6.8368 - val_acc: 0.3700\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 6.8340 - val_acc: 0.3600\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 6.8363 - val_acc: 0.3500\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.1011 - acc: 0.9700 - val_loss: 6.8464 - val_acc: 0.3500\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0201 - acc: 0.9900 - val_loss: 6.8545 - val_acc: 0.3400\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.0612 - acc: 0.9700 - val_loss: 6.8647 - val_acc: 0.3400\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 0s 551us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 6.8610 - val_acc: 0.3400\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0202 - acc: 0.9900 - val_loss: 6.8546 - val_acc: 0.3400\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 6.8618 - val_acc: 0.3400\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0160 - acc: 0.9900 - val_loss: 6.8762 - val_acc: 0.3300\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 6.8970 - val_acc: 0.3300\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 6.9233 - val_acc: 0.3300\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 6.9478 - val_acc: 0.3100\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 6.9726 - val_acc: 0.3100\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0114 - acc: 0.9900 - val_loss: 7.0026 - val_acc: 0.3200\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0271 - acc: 0.9900 - val_loss: 7.0397 - val_acc: 0.3200\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.0492 - acc: 0.9900 - val_loss: 7.0482 - val_acc: 0.3200\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0237 - acc: 0.9900 - val_loss: 7.0326 - val_acc: 0.3200\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 0s 455us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 7.0264 - val_acc: 0.3100\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 0s 418us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 7.0044 - val_acc: 0.3200\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 6.9853 - val_acc: 0.3200\n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 0s 426us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 6.9717 - val_acc: 0.3200\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 0.0173 - acc: 0.9900 - val_loss: 6.9964 - val_acc: 0.3200\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 7.0187 - val_acc: 0.3200\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 7.0431 - val_acc: 0.3200\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0181 - acc: 0.9900 - val_loss: 7.0487 - val_acc: 0.3300\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.0373 - acc: 0.9800 - val_loss: 7.0716 - val_acc: 0.3300\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0154 - acc: 0.9900 - val_loss: 7.1006 - val_acc: 0.3200\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 7.1216 - val_acc: 0.3200\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 7.1350 - val_acc: 0.3200\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 7.1453 - val_acc: 0.3200\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 7.1564 - val_acc: 0.3200\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0498 - acc: 0.9900 - val_loss: 7.1773 - val_acc: 0.3200\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 7.2007 - val_acc: 0.3300\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 7.2310 - val_acc: 0.3300\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.2588 - val_acc: 0.3300\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 7.2793 - val_acc: 0.3300\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 0.0298 - acc: 0.9900 - val_loss: 7.2953 - val_acc: 0.3300\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 7.3082 - val_acc: 0.3300\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 7.3249 - val_acc: 0.3300\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 7.3379 - val_acc: 0.3300\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.3484 - val_acc: 0.3300\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 7.3681 - val_acc: 0.3200\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 7.3592 - val_acc: 0.3300\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 7.3561 - val_acc: 0.3100\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.0399 - acc: 0.9900 - val_loss: 7.3347 - val_acc: 0.3100\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 7.3111 - val_acc: 0.3100\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.0317 - acc: 0.9900 - val_loss: 7.3076 - val_acc: 0.3300\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 7.3012 - val_acc: 0.3300\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 7.3153 - val_acc: 0.3300\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 7.3191 - val_acc: 0.3400\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 7.3318 - val_acc: 0.3500\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 7.3619 - val_acc: 0.3500\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.0654 - acc: 0.9900 - val_loss: 7.4364 - val_acc: 0.3500\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 0s 449us/step - loss: 0.0207 - acc: 0.9800 - val_loss: 7.5236 - val_acc: 0.3600\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 7.5867 - val_acc: 0.3500\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 0s 413us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 7.6046 - val_acc: 0.3500\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 7.5978 - val_acc: 0.3500\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 7.5860 - val_acc: 0.3400\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 0.0153 - acc: 0.9900 - val_loss: 7.5600 - val_acc: 0.3400\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.0398 - acc: 0.9900 - val_loss: 7.5359 - val_acc: 0.3400\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 7.5157 - val_acc: 0.3300\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0462 - acc: 0.9800 - val_loss: 7.5251 - val_acc: 0.3200\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.0256 - acc: 0.9900 - val_loss: 7.5439 - val_acc: 0.3300\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 7.5485 - val_acc: 0.3300\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 7.5598 - val_acc: 0.3200\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 7.5733 - val_acc: 0.3100\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0352 - acc: 0.9900 - val_loss: 7.5610 - val_acc: 0.3100\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 7.5571 - val_acc: 0.3100\n",
      "Epoch 307/1000\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 7.5580 - val_acc: 0.3100\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 7.5645 - val_acc: 0.3000\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 7.5709 - val_acc: 0.3000\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 0s 406us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 7.5807 - val_acc: 0.3000\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 7.5858 - val_acc: 0.2900\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0174 - acc: 0.9900 - val_loss: 7.5622 - val_acc: 0.3100\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - 0s 418us/step - loss: 0.0474 - acc: 0.9900 - val_loss: 7.5358 - val_acc: 0.3000\n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 0s 354us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 7.5089 - val_acc: 0.3100\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 7.4943 - val_acc: 0.3100\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.0289 - acc: 0.9800 - val_loss: 7.4875 - val_acc: 0.3000\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 7.4746 - val_acc: 0.3000\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 0s 403us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 7.4658 - val_acc: 0.3100\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.0575 - acc: 0.9900 - val_loss: 7.4512 - val_acc: 0.3200\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0149 - acc: 0.9900 - val_loss: 7.4265 - val_acc: 0.3100\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 7.3953 - val_acc: 0.3100\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0112 - acc: 0.9900 - val_loss: 7.3395 - val_acc: 0.3200\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 0s 418us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.2985 - val_acc: 0.3200\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 7.2660 - val_acc: 0.3100\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 7.2464 - val_acc: 0.3100\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 7.2395 - val_acc: 0.3100\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 7.2131 - val_acc: 0.3100\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 7.1953 - val_acc: 0.3200\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0482 - acc: 0.9700 - val_loss: 7.1786 - val_acc: 0.3200\n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.0375 - acc: 0.9900 - val_loss: 7.1671 - val_acc: 0.3200\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 0s 345us/step - loss: 0.0503 - acc: 0.9900 - val_loss: 7.1434 - val_acc: 0.3200\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 0s 482us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 7.1152 - val_acc: 0.3200\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 7.1018 - val_acc: 0.3200\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 7.0972 - val_acc: 0.3200\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.0173 - acc: 0.9900 - val_loss: 7.1184 - val_acc: 0.3200\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.0302 - acc: 0.9900 - val_loss: 7.1445 - val_acc: 0.3200\n",
      "Epoch 337/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 7.1625 - val_acc: 0.3200\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 0s 467us/step - loss: 0.0180 - acc: 0.9900 - val_loss: 7.1946 - val_acc: 0.3200\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 7.2214 - val_acc: 0.3100\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0232 - acc: 0.9900 - val_loss: 7.2394 - val_acc: 0.3100\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 0s 377us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 7.2370 - val_acc: 0.3200\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 7.2280 - val_acc: 0.3300\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.2173 - val_acc: 0.3400\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.0230 - acc: 0.9900 - val_loss: 7.2131 - val_acc: 0.3400\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 7.2147 - val_acc: 0.3400\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 0s 432us/step - loss: 0.0140 - acc: 0.9900 - val_loss: 7.2222 - val_acc: 0.3400\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0119 - acc: 0.9900 - val_loss: 7.2315 - val_acc: 0.3400\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0517 - acc: 0.9900 - val_loss: 7.2358 - val_acc: 0.3600\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 0s 439us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.2380 - val_acc: 0.3600\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0283 - acc: 0.9900 - val_loss: 7.2839 - val_acc: 0.3400\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 7.3098 - val_acc: 0.3400\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 7.3267 - val_acc: 0.3400\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0375 - acc: 0.9900 - val_loss: 7.3319 - val_acc: 0.3300\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 7.3363 - val_acc: 0.3400\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 7.3422 - val_acc: 0.3400\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 0s 432us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 7.3454 - val_acc: 0.3400\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0301 - acc: 0.9900 - val_loss: 7.2986 - val_acc: 0.3200\n",
      "Epoch 358/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0284 - acc: 0.9900 - val_loss: 7.3095 - val_acc: 0.3300\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0232 - acc: 0.9900 - val_loss: 7.4416 - val_acc: 0.3300\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0153 - acc: 0.9900 - val_loss: 7.5372 - val_acc: 0.3200\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 7.6111 - val_acc: 0.3300\n",
      "Epoch 362/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.6662 - val_acc: 0.3300\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.7065 - val_acc: 0.3200\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 7.7322 - val_acc: 0.3200\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 7.7560 - val_acc: 0.3200\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0158 - acc: 0.9900 - val_loss: 7.7831 - val_acc: 0.3200\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.8053 - val_acc: 0.3200\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 7.8165 - val_acc: 0.3200\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 7.8383 - val_acc: 0.3200\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 7.8564 - val_acc: 0.3200\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0925 - acc: 0.9700 - val_loss: 7.8372 - val_acc: 0.3300\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 7.8111 - val_acc: 0.3600\n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 7.7995 - val_acc: 0.3600\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 7.8037 - val_acc: 0.3500\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 0s 432us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 7.8101 - val_acc: 0.3500\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.0118 - acc: 0.9900 - val_loss: 7.7939 - val_acc: 0.3500\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 0s 384us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 7.7899 - val_acc: 0.3400\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 7.7903 - val_acc: 0.3400\n",
      "Epoch 379/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 7.7816 - val_acc: 0.3400\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 7.7626 - val_acc: 0.3400\n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 0s 427us/step - loss: 0.0225 - acc: 0.9900 - val_loss: 7.6868 - val_acc: 0.3300\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.0288 - acc: 0.9900 - val_loss: 7.5175 - val_acc: 0.3500\n",
      "Epoch 383/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 7.3614 - val_acc: 0.3500\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.2526 - val_acc: 0.3300\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 7.1853 - val_acc: 0.3300\n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 7.1575 - val_acc: 0.3200\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 7.1391 - val_acc: 0.3100\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 7.1410 - val_acc: 0.3100\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0174 - acc: 0.9900 - val_loss: 7.1632 - val_acc: 0.3100\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 0s 460us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 7.1893 - val_acc: 0.3100\n",
      "Epoch 391/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 7.2319 - val_acc: 0.3100\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0181 - acc: 0.9900 - val_loss: 7.2465 - val_acc: 0.3100\n",
      "Epoch 393/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2353 - val_acc: 0.3100\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.2347 - val_acc: 0.3100\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.2434 - val_acc: 0.3000\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 7.2543 - val_acc: 0.3000\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0099 - acc: 0.9900 - val_loss: 7.2783 - val_acc: 0.3000\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - 0s 428us/step - loss: 7.2620e-04 - acc: 1.0000 - val_loss: 7.3045 - val_acc: 0.3100\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 0s 426us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 7.3436 - val_acc: 0.3200\n",
      "Epoch 400/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0156 - acc: 0.9900 - val_loss: 7.4186 - val_acc: 0.3200\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0217 - acc: 0.9900 - val_loss: 7.5015 - val_acc: 0.3100\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 7.5848 - val_acc: 0.3100\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 7.6645 - val_acc: 0.3100\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.7315 - val_acc: 0.3100\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 0s 377us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 7.7679 - val_acc: 0.3100\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0409 - acc: 0.9900 - val_loss: 7.7830 - val_acc: 0.3100\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 7.8038 - val_acc: 0.3100\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0171 - acc: 0.9900 - val_loss: 7.7608 - val_acc: 0.2900\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 7.7245 - val_acc: 0.3000\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.0114 - acc: 0.9900 - val_loss: 7.8078 - val_acc: 0.3100\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0364 - acc: 0.9900 - val_loss: 7.9299 - val_acc: 0.2900\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 0s 498us/step - loss: 0.0921 - acc: 0.9700 - val_loss: 7.9695 - val_acc: 0.2900\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0199 - acc: 0.9800 - val_loss: 7.9416 - val_acc: 0.3100\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 7.8786 - val_acc: 0.3100\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 7.8379 - val_acc: 0.3100\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0253 - acc: 0.9800 - val_loss: 7.8009 - val_acc: 0.3000\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 0.0460 - acc: 0.9900 - val_loss: 7.6477 - val_acc: 0.3100\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 7.5248 - val_acc: 0.3100\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 0.0660 - acc: 0.9900 - val_loss: 7.4456 - val_acc: 0.3100\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 0s 442us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 7.3819 - val_acc: 0.3200\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0183 - acc: 0.9900 - val_loss: 7.3440 - val_acc: 0.3200\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 7.3187 - val_acc: 0.3100\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 0s 453us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 7.3180 - val_acc: 0.2800\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.0218 - acc: 0.9900 - val_loss: 7.3198 - val_acc: 0.2900\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 7.3066 - val_acc: 0.3000\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 7.2940 - val_acc: 0.3000\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 7.2803 - val_acc: 0.3000\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 7.2855 - val_acc: 0.3000\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 7.2976 - val_acc: 0.3000\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0607 - acc: 0.9900 - val_loss: 7.2700 - val_acc: 0.3200\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0329 - acc: 0.9800 - val_loss: 7.2195 - val_acc: 0.3200\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 0s 413us/step - loss: 0.0363 - acc: 0.9800 - val_loss: 7.2081 - val_acc: 0.3400\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 0.0164 - acc: 0.9900 - val_loss: 7.1850 - val_acc: 0.3200\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 0s 453us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 7.1745 - val_acc: 0.3300\n",
      "Epoch 435/1000\n",
      "100/100 [==============================] - 0s 480us/step - loss: 0.0852 - acc: 0.9700 - val_loss: 7.2352 - val_acc: 0.3200\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 7.3144 - val_acc: 0.3100\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 0s 446us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 7.4006 - val_acc: 0.2900\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.0686 - acc: 0.9800 - val_loss: 7.4188 - val_acc: 0.2900\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0341 - acc: 0.9900 - val_loss: 7.3779 - val_acc: 0.3000\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 7.3516 - val_acc: 0.3100\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 7.3372 - val_acc: 0.2900\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 7.3373 - val_acc: 0.2900\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 0.0386 - acc: 0.9800 - val_loss: 7.2157 - val_acc: 0.3000\n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 0s 449us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 7.1263 - val_acc: 0.3000\n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 7.0619 - val_acc: 0.2900\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0526 - acc: 0.9900 - val_loss: 7.0530 - val_acc: 0.2900\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 7.1097 - val_acc: 0.3000\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 7.1701 - val_acc: 0.3000\n",
      "Epoch 449/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 7.2254 - val_acc: 0.3000\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.0312 - acc: 0.9900 - val_loss: 7.2195 - val_acc: 0.3000\n",
      "Epoch 451/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.0148 - acc: 0.9900 - val_loss: 7.1887 - val_acc: 0.2900\n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0186 - acc: 0.9900 - val_loss: 7.1323 - val_acc: 0.2700\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.0918 - val_acc: 0.2700\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 0s 364us/step - loss: 0.0168 - acc: 0.9900 - val_loss: 7.0481 - val_acc: 0.2700\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 7.0222 - val_acc: 0.2600\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 0s 404us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 7.0137 - val_acc: 0.2600\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 7.0210 - val_acc: 0.2700\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 0s 508us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 7.0285 - val_acc: 0.2800\n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 7.0357 - val_acc: 0.2700\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 7.0735 - val_acc: 0.2700\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 7.1130 - val_acc: 0.2800\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0245 - acc: 0.9900 - val_loss: 7.1060 - val_acc: 0.2700\n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 0s 358us/step - loss: 7.5679e-04 - acc: 1.0000 - val_loss: 7.0662 - val_acc: 0.2700\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.0232 - acc: 0.9900 - val_loss: 7.0486 - val_acc: 0.2900\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.0426 - val_acc: 0.2800\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.0379 - acc: 0.9900 - val_loss: 7.0246 - val_acc: 0.2800\n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 0s 499us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 6.9631 - val_acc: 0.2900\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9183 - val_acc: 0.2900\n",
      "Epoch 469/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 6.8899 - val_acc: 0.3000\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 6.8724 - val_acc: 0.3100\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8630 - val_acc: 0.3100\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 6.8554 - val_acc: 0.3100\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 6.8559 - val_acc: 0.3200\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 6.8586 - val_acc: 0.3100\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 6.8678 - val_acc: 0.3200\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 0s 404us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.8802 - val_acc: 0.3100\n",
      "Epoch 477/1000\n",
      "100/100 [==============================] - 0s 420us/step - loss: 0.0372 - acc: 0.9900 - val_loss: 6.8767 - val_acc: 0.2900\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 6.8864 - val_acc: 0.2900\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 0s 454us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 6.9333 - val_acc: 0.2800\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 6.9291e-04 - acc: 1.0000 - val_loss: 6.9851 - val_acc: 0.2800\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 0s 404us/step - loss: 0.0250 - acc: 0.9900 - val_loss: 7.0319 - val_acc: 0.2800\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 7.0937 - val_acc: 0.2800\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 7.1458 - val_acc: 0.2900\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 7.2043 - val_acc: 0.2900\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 7.2526 - val_acc: 0.2800\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 7.2931 - val_acc: 0.2600\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 7.3288 - val_acc: 0.2700\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 7.3782 - val_acc: 0.2700\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 7.4393 - val_acc: 0.2800\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 7.4833 - val_acc: 0.2800\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 7.5230 - val_acc: 0.2800\n",
      "Epoch 492/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 7.5410 - val_acc: 0.2800\n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0607 - acc: 0.9800 - val_loss: 7.5659 - val_acc: 0.2900\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 0s 440us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.6355 - val_acc: 0.2800\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 4.9932e-04 - acc: 1.0000 - val_loss: 7.6953 - val_acc: 0.3100\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 7.8019 - val_acc: 0.3000\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0289 - acc: 0.9900 - val_loss: 7.8921 - val_acc: 0.3100\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0184 - acc: 0.9900 - val_loss: 7.9147 - val_acc: 0.3100\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0179 - acc: 0.9900 - val_loss: 7.9127 - val_acc: 0.3000\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 7.9386 - val_acc: 0.3000\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 0.0137 - acc: 0.9900 - val_loss: 7.9411 - val_acc: 0.3000\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 0s 406us/step - loss: 0.0202 - acc: 0.9900 - val_loss: 7.9020 - val_acc: 0.3000\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 7.8598 - val_acc: 0.3000\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.8245 - val_acc: 0.3200\n",
      "Epoch 505/1000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 7.7986 - val_acc: 0.3200\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 0s 470us/step - loss: 6.1846e-04 - acc: 1.0000 - val_loss: 7.7776 - val_acc: 0.3300\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 7.7708 - val_acc: 0.3200\n",
      "Epoch 508/1000\n",
      "100/100 [==============================] - 0s 432us/step - loss: 0.0235 - acc: 0.9800 - val_loss: 7.8058 - val_acc: 0.3200\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 7.8438 - val_acc: 0.3100\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 7.9012 - val_acc: 0.3200\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 0s 413us/step - loss: 0.0220 - acc: 0.9900 - val_loss: 7.9960 - val_acc: 0.3100\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - 0s 446us/step - loss: 0.0171 - acc: 0.9900 - val_loss: 8.0523 - val_acc: 0.3000\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 8.0736 - val_acc: 0.2900\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.1076 - val_acc: 0.2900\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.0305 - acc: 0.9900 - val_loss: 8.0836 - val_acc: 0.2900\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 8.0682 - val_acc: 0.3000\n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 8.0483 - val_acc: 0.3000\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0284 - acc: 0.9900 - val_loss: 8.0198 - val_acc: 0.2900\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 7.9965 - val_acc: 0.2900\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 7.9934 - val_acc: 0.3000\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 7.9929 - val_acc: 0.2900\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 7.9948 - val_acc: 0.2900\n",
      "Epoch 523/1000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 7.9878 - val_acc: 0.2900\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 7.9872 - val_acc: 0.3000\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 7.9913 - val_acc: 0.3000\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 0.0319 - acc: 0.9900 - val_loss: 8.0061 - val_acc: 0.3000\n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 8.0613 - val_acc: 0.3000\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 0s 436us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 8.1250 - val_acc: 0.3100\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 0s 458us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 8.1880 - val_acc: 0.3000\n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 8.2448 - val_acc: 0.3100\n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 8.2878 - val_acc: 0.3100\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.3214 - val_acc: 0.3100\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 8.3518 - val_acc: 0.3100\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 8.4026 - val_acc: 0.3100\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 8.4479 - val_acc: 0.3100\n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 0s 449us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 8.4894 - val_acc: 0.3100\n",
      "Epoch 537/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 7.7921e-04 - acc: 1.0000 - val_loss: 8.5242 - val_acc: 0.3100\n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 7.9572e-04 - acc: 1.0000 - val_loss: 8.5514 - val_acc: 0.3100\n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 8.5601 - val_acc: 0.3100\n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 8.5619 - val_acc: 0.3100\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 8.5622 - val_acc: 0.3100\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 8.5528 - val_acc: 0.3200\n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.0141 - acc: 0.9900 - val_loss: 8.2982 - val_acc: 0.3100\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 8.0781 - val_acc: 0.3100\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.9340 - val_acc: 0.3200\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 6.6198e-04 - acc: 1.0000 - val_loss: 7.8563 - val_acc: 0.3300\n",
      "Epoch 547/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.7933 - val_acc: 0.3300\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 7.7667 - val_acc: 0.3400\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - 0s 460us/step - loss: 7.2511e-04 - acc: 1.0000 - val_loss: 7.7663 - val_acc: 0.3400\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - 0s 428us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 7.7639 - val_acc: 0.3400\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - 0s 455us/step - loss: 0.0087 - acc: 0.9900 - val_loss: 7.7709 - val_acc: 0.3400\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 7.7883 - val_acc: 0.3300\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 7.8035 - val_acc: 0.3300\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 0s 455us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.8147 - val_acc: 0.3300\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 0s 428us/step - loss: 0.0126 - acc: 0.9900 - val_loss: 7.8525 - val_acc: 0.3300\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.8718 - val_acc: 0.3300\n",
      "Epoch 557/1000\n",
      "100/100 [==============================] - 0s 455us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 7.8814 - val_acc: 0.3300\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - 0s 513us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 7.8478 - val_acc: 0.3300\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 9.5657e-04 - acc: 1.0000 - val_loss: 7.7999 - val_acc: 0.3300\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0283 - acc: 0.9900 - val_loss: 7.6866 - val_acc: 0.3300\n",
      "Epoch 561/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.5998 - val_acc: 0.3300\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 7.5145e-04 - acc: 1.0000 - val_loss: 7.5414 - val_acc: 0.3400\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 7.5041 - val_acc: 0.3400\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 0s 385us/step - loss: 9.2737e-04 - acc: 1.0000 - val_loss: 7.4800 - val_acc: 0.3500\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 0s 447us/step - loss: 7.9283e-04 - acc: 1.0000 - val_loss: 7.4648 - val_acc: 0.3500\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0097 - acc: 0.9900 - val_loss: 7.5033 - val_acc: 0.3400\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 8.7010e-04 - acc: 1.0000 - val_loss: 7.5468 - val_acc: 0.3400\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 7.5833 - val_acc: 0.3400\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 7.6263 - val_acc: 0.3400\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 0s 508us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 7.7274 - val_acc: 0.3500\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0714 - acc: 0.9900 - val_loss: 7.8496 - val_acc: 0.3300\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 0s 455us/step - loss: 0.0192 - acc: 0.9800 - val_loss: 8.0296 - val_acc: 0.3400\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 8.1975 - val_acc: 0.3300\n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.3585 - val_acc: 0.3200\n",
      "Epoch 575/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 8.4969 - val_acc: 0.3100\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0281 - acc: 0.9900 - val_loss: 8.4377 - val_acc: 0.3000\n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 2.8755e-04 - acc: 1.0000 - val_loss: 8.3865 - val_acc: 0.3000\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 8.3353 - val_acc: 0.3100\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 8.2894 - val_acc: 0.3100\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.0161 - acc: 0.9900 - val_loss: 8.2258 - val_acc: 0.3200\n",
      "Epoch 581/1000\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.1764 - val_acc: 0.3000\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 8.6262e-04 - acc: 1.0000 - val_loss: 8.1417 - val_acc: 0.3100\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 0s 406us/step - loss: 6.2277e-04 - acc: 1.0000 - val_loss: 8.1152 - val_acc: 0.3100\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 0s 447us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.0902 - val_acc: 0.3000\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.0471 - val_acc: 0.3100\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 0s 447us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 8.0143 - val_acc: 0.3000\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 0s 449us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 7.9866 - val_acc: 0.3000\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 3.3440e-04 - acc: 1.0000 - val_loss: 7.9676 - val_acc: 0.3000\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 7.9528 - val_acc: 0.3000\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 7.9768 - val_acc: 0.3100\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 0s 442us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 8.0071 - val_acc: 0.3200\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 0s 445us/step - loss: 6.8110e-04 - acc: 1.0000 - val_loss: 8.0381 - val_acc: 0.3000\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 8.0670 - val_acc: 0.3000\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 5.4555e-04 - acc: 1.0000 - val_loss: 8.0917 - val_acc: 0.3000\n",
      "Epoch 595/1000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 9.7943e-04 - acc: 1.0000 - val_loss: 8.1102 - val_acc: 0.2900\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 8.1200 - val_acc: 0.2900\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 0s 420us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.1269 - val_acc: 0.2900\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 0s 373us/step - loss: 6.3680e-04 - acc: 1.0000 - val_loss: 8.1320 - val_acc: 0.2900\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 7.7440e-04 - acc: 1.0000 - val_loss: 8.1382 - val_acc: 0.2900\n",
      "Epoch 600/1000\n",
      "100/100 [==============================] - 0s 427us/step - loss: 7.4502e-04 - acc: 1.0000 - val_loss: 8.1434 - val_acc: 0.2900\n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 8.1451 - val_acc: 0.2900\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.1579 - val_acc: 0.3000\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 0s 404us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 8.1700 - val_acc: 0.3000\n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 8.1856 - val_acc: 0.2900\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.2073 - val_acc: 0.2900\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 8.2388 - val_acc: 0.2900\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 0s 354us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 8.2607 - val_acc: 0.2900\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.2681 - val_acc: 0.2900\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.2702 - val_acc: 0.2900\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 8.2684 - val_acc: 0.2900\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0340 - acc: 0.9900 - val_loss: 8.3187 - val_acc: 0.2900\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 8.8682e-04 - acc: 1.0000 - val_loss: 8.4124 - val_acc: 0.2800\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 8.7278e-04 - acc: 1.0000 - val_loss: 8.4898 - val_acc: 0.2900\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 0s 426us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 8.5428 - val_acc: 0.2900\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0183 - acc: 0.9900 - val_loss: 8.5001 - val_acc: 0.2900\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.3854 - val_acc: 0.2800\n",
      "Epoch 617/1000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0245 - acc: 0.9900 - val_loss: 8.3863 - val_acc: 0.2700\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 8.3822 - val_acc: 0.2700\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 0s 467us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 8.4229 - val_acc: 0.2700\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 8.6365e-04 - acc: 1.0000 - val_loss: 8.4438 - val_acc: 0.2800\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 0s 448us/step - loss: 0.0186 - acc: 0.9800 - val_loss: 8.3704 - val_acc: 0.2800\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.0141 - acc: 0.9900 - val_loss: 8.1020 - val_acc: 0.3200\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.9234 - val_acc: 0.3400\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 5.1775e-04 - acc: 1.0000 - val_loss: 7.8218 - val_acc: 0.3500\n",
      "Epoch 625/1000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 7.7608 - val_acc: 0.3400\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 7.7386 - val_acc: 0.3300\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 0s 418us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 7.7201 - val_acc: 0.3200\n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 7.7306 - val_acc: 0.3200\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 0s 436us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.7602 - val_acc: 0.3100\n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.1841 - acc: 0.9800 - val_loss: 7.7444 - val_acc: 0.3100\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 0s 428us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.7177 - val_acc: 0.3200\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 0s 619us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 7.7150 - val_acc: 0.3300\n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 0s 505us/step - loss: 0.0522 - acc: 0.9900 - val_loss: 7.7350 - val_acc: 0.3300\n",
      "Epoch 634/1000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 7.8068 - val_acc: 0.3100\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 7.8904 - val_acc: 0.2800\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0152 - acc: 0.9900 - val_loss: 7.9671 - val_acc: 0.3000\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 8.0439 - val_acc: 0.2900\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.0326 - acc: 0.9900 - val_loss: 8.0314 - val_acc: 0.2800\n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 7.9887 - val_acc: 0.3000\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.0156 - acc: 0.9900 - val_loss: 7.9033 - val_acc: 0.3000\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 0s 427us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 7.8069 - val_acc: 0.3000\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 9.3686e-04 - acc: 1.0000 - val_loss: 7.7433 - val_acc: 0.3000\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 7.6980 - val_acc: 0.2900\n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 0s 446us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 7.6666 - val_acc: 0.2900\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.6456 - val_acc: 0.3000\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 0s 455us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 7.6356 - val_acc: 0.3100\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.6308 - val_acc: 0.3100\n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.6301 - val_acc: 0.3100\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.6316 - val_acc: 0.3100\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 7.6536 - val_acc: 0.3100\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 7.6792 - val_acc: 0.3100\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 7.7155 - val_acc: 0.3100\n",
      "Epoch 653/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0685 - acc: 0.9900 - val_loss: 7.8040 - val_acc: 0.3100\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 7.9295 - val_acc: 0.3000\n",
      "Epoch 655/1000\n",
      "100/100 [==============================] - 0s 367us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 8.0326 - val_acc: 0.3000\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 8.1061 - val_acc: 0.3000\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 7.3623e-04 - acc: 1.0000 - val_loss: 8.1464 - val_acc: 0.3000\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 0s 460us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.1821 - val_acc: 0.3000\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 8.2439 - val_acc: 0.2900\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 0s 460us/step - loss: 6.1870e-04 - acc: 1.0000 - val_loss: 8.2936 - val_acc: 0.2900\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 0s 440us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 8.3290 - val_acc: 0.3000\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 8.3538 - val_acc: 0.2900\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0111 - acc: 0.9900 - val_loss: 8.3759 - val_acc: 0.2900\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 8.4012 - val_acc: 0.2900\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 0s 463us/step - loss: 0.0096 - acc: 0.9900 - val_loss: 8.4243 - val_acc: 0.2900\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 8.4499 - val_acc: 0.2900\n",
      "Epoch 667/1000\n",
      "100/100 [==============================] - 0s 512us/step - loss: 4.4273e-04 - acc: 1.0000 - val_loss: 8.4804 - val_acc: 0.2900\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0174 - acc: 0.9900 - val_loss: 8.5359 - val_acc: 0.3000\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0156 - acc: 0.9900 - val_loss: 8.5671 - val_acc: 0.3000\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 9.0093e-04 - acc: 1.0000 - val_loss: 8.5693 - val_acc: 0.3000\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 0.0417 - acc: 0.9900 - val_loss: 8.5425 - val_acc: 0.3000\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 0s 440us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 8.5009 - val_acc: 0.2900\n",
      "Epoch 673/1000\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 8.4846 - val_acc: 0.2900\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.0298 - acc: 0.9900 - val_loss: 8.4131 - val_acc: 0.2900\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 8.9114e-04 - acc: 1.0000 - val_loss: 8.3555 - val_acc: 0.2700\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0231 - acc: 0.9900 - val_loss: 8.2875 - val_acc: 0.2800\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 8.2470 - val_acc: 0.2900\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 0s 403us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.2199 - val_acc: 0.2900\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 0s 468us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.2111 - val_acc: 0.3000\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 8.2059 - val_acc: 0.3000\n",
      "Epoch 681/1000\n",
      "100/100 [==============================] - 0s 419us/step - loss: 5.5812e-04 - acc: 1.0000 - val_loss: 8.2040 - val_acc: 0.3000\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 8.2045 - val_acc: 0.3000\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 4.7846e-04 - acc: 1.0000 - val_loss: 8.2064 - val_acc: 0.3000\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 0s 439us/step - loss: 4.2640e-04 - acc: 1.0000 - val_loss: 8.2084 - val_acc: 0.3000\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 5.1722e-04 - acc: 1.0000 - val_loss: 8.2079 - val_acc: 0.3000\n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 0.0471 - acc: 0.9900 - val_loss: 8.1197 - val_acc: 0.3000\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0119 - acc: 0.9900 - val_loss: 8.0211 - val_acc: 0.2900\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 0s 531us/step - loss: 7.4848e-04 - acc: 1.0000 - val_loss: 7.9645 - val_acc: 0.3000\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 7.9272 - val_acc: 0.2800\n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 7.9981e-04 - acc: 1.0000 - val_loss: 7.8944 - val_acc: 0.2800\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 7.8650 - val_acc: 0.2800\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 0s 403us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 7.8415 - val_acc: 0.2600\n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0814 - acc: 0.9800 - val_loss: 7.8932 - val_acc: 0.2800\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 8.0518 - val_acc: 0.3100\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - 0s 456us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.2166 - val_acc: 0.3100\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 0.0213 - acc: 0.9900 - val_loss: 8.3402 - val_acc: 0.3200\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 8.4586 - val_acc: 0.3300\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 8.5581 - val_acc: 0.3300\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 8.6327 - val_acc: 0.3200\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 0s 499us/step - loss: 8.6459e-04 - acc: 1.0000 - val_loss: 8.6830 - val_acc: 0.3200\n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 7.5582e-04 - acc: 1.0000 - val_loss: 8.7231 - val_acc: 0.3200\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.7608 - val_acc: 0.3200\n",
      "Epoch 703/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 5.3100e-04 - acc: 1.0000 - val_loss: 8.7899 - val_acc: 0.3200\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 8.8014 - val_acc: 0.3200\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 0s 470us/step - loss: 9.9649e-04 - acc: 1.0000 - val_loss: 8.8087 - val_acc: 0.3200\n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 8.8090 - val_acc: 0.3200\n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 0s 448us/step - loss: 7.5771e-04 - acc: 1.0000 - val_loss: 8.8093 - val_acc: 0.3200\n",
      "Epoch 708/1000\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0208 - acc: 0.9900 - val_loss: 8.8399 - val_acc: 0.3100\n",
      "Epoch 709/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0106 - acc: 0.9900 - val_loss: 8.8088 - val_acc: 0.3100\n",
      "Epoch 710/1000\n",
      "100/100 [==============================] - 0s 405us/step - loss: 2.5142e-04 - acc: 1.0000 - val_loss: 8.7840 - val_acc: 0.3200\n",
      "Epoch 711/1000\n",
      "100/100 [==============================] - 0s 459us/step - loss: 5.4049e-04 - acc: 1.0000 - val_loss: 8.7638 - val_acc: 0.3200\n",
      "Epoch 712/1000\n",
      "100/100 [==============================] - 0s 535us/step - loss: 0.0130 - acc: 0.9900 - val_loss: 8.7722 - val_acc: 0.3200\n",
      "Epoch 713/1000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 8.7731 - val_acc: 0.3300\n",
      "Epoch 714/1000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 8.7982 - val_acc: 0.3300\n",
      "Epoch 715/1000\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.0542 - acc: 0.9900 - val_loss: 8.7572 - val_acc: 0.3300\n",
      "Epoch 716/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 8.6322 - val_acc: 0.3300\n",
      "Epoch 717/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 4.8071e-04 - acc: 1.0000 - val_loss: 8.5328 - val_acc: 0.3200\n",
      "Epoch 718/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 8.4600 - val_acc: 0.3200\n",
      "Epoch 719/1000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.4158 - val_acc: 0.3200\n",
      "Epoch 720/1000\n",
      "100/100 [==============================] - 0s 462us/step - loss: 0.0186 - acc: 0.9800 - val_loss: 8.3979 - val_acc: 0.3200\n",
      "Epoch 721/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 2.7808e-04 - acc: 1.0000 - val_loss: 8.4190 - val_acc: 0.3200\n",
      "Epoch 722/1000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.4333 - val_acc: 0.3200\n",
      "Epoch 723/1000\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 8.4506 - val_acc: 0.3200\n",
      "Epoch 724/1000\n",
      "100/100 [==============================] - 0s 454us/step - loss: 7.1146e-04 - acc: 1.0000 - val_loss: 8.4741 - val_acc: 0.3200\n",
      "Epoch 725/1000\n",
      "100/100 [==============================] - 0s 433us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 8.5073 - val_acc: 0.3200\n",
      "Epoch 726/1000\n",
      "100/100 [==============================] - 0s 505us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 8.5460 - val_acc: 0.3200\n",
      "Epoch 727/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 0.0743 - acc: 0.9700 - val_loss: 8.3208 - val_acc: 0.3100\n",
      "Epoch 728/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.1490e-04 - acc: 1.0000 - val_loss: 8.0298 - val_acc: 0.3000\n",
      "Epoch 729/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 5.6952e-04 - acc: 1.0000 - val_loss: 7.7928 - val_acc: 0.3000\n",
      "Epoch 730/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 7.6304 - val_acc: 0.3000\n",
      "Epoch 731/1000\n",
      "100/100 [==============================] - 0s 468us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 7.5441 - val_acc: 0.2900\n",
      "Epoch 732/1000\n",
      "100/100 [==============================] - 0s 475us/step - loss: 0.0288 - acc: 0.9900 - val_loss: 7.4843 - val_acc: 0.2900\n",
      "Epoch 733/1000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 7.4580 - val_acc: 0.3100\n",
      "Epoch 734/1000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.1260 - acc: 0.9800 - val_loss: 7.4875 - val_acc: 0.2800\n",
      "Epoch 735/1000\n",
      "100/100 [==============================] - 0s 468us/step - loss: 0.0211 - acc: 0.9900 - val_loss: 7.5818 - val_acc: 0.2700\n",
      "Epoch 736/1000\n",
      "100/100 [==============================] - 0s 437us/step - loss: 7.4407e-04 - acc: 1.0000 - val_loss: 7.6975 - val_acc: 0.2800\n",
      "Epoch 737/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 7.8012 - val_acc: 0.2900\n",
      "Epoch 738/1000\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.8918 - val_acc: 0.2900\n",
      "Epoch 739/1000\n",
      "100/100 [==============================] - 0s 468us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 7.9695 - val_acc: 0.2700\n",
      "Epoch 740/1000\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.0296 - val_acc: 0.2600\n",
      "Epoch 741/1000\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 8.0846 - val_acc: 0.2700\n",
      "Epoch 742/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 8.7956e-04 - acc: 1.0000 - val_loss: 8.1331 - val_acc: 0.2700\n",
      "Epoch 743/1000\n",
      "100/100 [==============================] - 0s 439us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.1734 - val_acc: 0.2700\n",
      "Epoch 744/1000\n",
      "100/100 [==============================] - 0s 487us/step - loss: 5.7012e-04 - acc: 1.0000 - val_loss: 8.2066 - val_acc: 0.2700\n",
      "Epoch 745/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 8.2294 - val_acc: 0.2700\n",
      "Epoch 746/1000\n",
      "100/100 [==============================] - 0s 510us/step - loss: 0.0430 - acc: 0.9800 - val_loss: 8.1642 - val_acc: 0.2700\n",
      "Epoch 747/1000\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.0102 - acc: 0.9900 - val_loss: 8.1138 - val_acc: 0.2800\n",
      "Epoch 748/1000\n",
      "100/100 [==============================] - 0s 464us/step - loss: 8.8918e-04 - acc: 1.0000 - val_loss: 8.0752 - val_acc: 0.2900\n",
      "Epoch 749/1000\n",
      "100/100 [==============================] - 0s 485us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 8.0234 - val_acc: 0.3000\n",
      "Epoch 750/1000\n",
      "100/100 [==============================] - 0s 484us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 7.9771 - val_acc: 0.2900\n",
      "Epoch 751/1000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 7.9378 - val_acc: 0.2900\n",
      "Epoch 752/1000\n",
      "100/100 [==============================] - 0s 454us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.8978 - val_acc: 0.2900\n",
      "Epoch 753/1000\n",
      "100/100 [==============================] - 0s 494us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 7.8475 - val_acc: 0.3000\n",
      "Epoch 754/1000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 7.8130 - val_acc: 0.3000\n",
      "Epoch 755/1000\n",
      "100/100 [==============================] - 0s 554us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 7.7562 - val_acc: 0.3200\n",
      "Epoch 756/1000\n",
      "100/100 [==============================] - 0s 446us/step - loss: 0.0088 - acc: 0.9900 - val_loss: 7.6541 - val_acc: 0.3000\n",
      "Epoch 757/1000\n",
      "100/100 [==============================] - 0s 427us/step - loss: 4.1032e-04 - acc: 1.0000 - val_loss: 7.5718 - val_acc: 0.3000\n",
      "Epoch 758/1000\n",
      "100/100 [==============================] - 0s 476us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 7.5211 - val_acc: 0.3100\n",
      "Epoch 759/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 7.4853 - val_acc: 0.3000\n",
      "Epoch 760/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 7.4559 - val_acc: 0.3200\n",
      "Epoch 761/1000\n",
      "100/100 [==============================] - 0s 460us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.4486 - val_acc: 0.3100\n",
      "Epoch 762/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 7.4539 - val_acc: 0.3000\n",
      "Epoch 763/1000\n",
      "100/100 [==============================] - 0s 456us/step - loss: 4.1128e-04 - acc: 1.0000 - val_loss: 7.4684 - val_acc: 0.3000\n",
      "Epoch 764/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 9.0314e-04 - acc: 1.0000 - val_loss: 7.4837 - val_acc: 0.3000\n",
      "Epoch 765/1000\n",
      "100/100 [==============================] - 0s 547us/step - loss: 6.8377e-04 - acc: 1.0000 - val_loss: 7.4994 - val_acc: 0.3000\n",
      "Epoch 766/1000\n",
      "100/100 [==============================] - 0s 462us/step - loss: 2.4245e-04 - acc: 1.0000 - val_loss: 7.5130 - val_acc: 0.3000\n",
      "Epoch 767/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0146 - acc: 0.9900 - val_loss: 7.5573 - val_acc: 0.3000\n",
      "Epoch 768/1000\n",
      "100/100 [==============================] - 0s 514us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 7.6057 - val_acc: 0.3100\n",
      "Epoch 769/1000\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.6507 - val_acc: 0.3000\n",
      "Epoch 770/1000\n",
      "100/100 [==============================] - 0s 453us/step - loss: 0.0079 - acc: 0.9900 - val_loss: 7.6794 - val_acc: 0.3000\n",
      "Epoch 771/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.7045 - val_acc: 0.3000\n",
      "Epoch 772/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 7.7371 - val_acc: 0.3000\n",
      "Epoch 773/1000\n",
      "100/100 [==============================] - 0s 419us/step - loss: 3.3664e-04 - acc: 1.0000 - val_loss: 7.7777 - val_acc: 0.2900\n",
      "Epoch 774/1000\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 7.8699 - val_acc: 0.2800\n",
      "Epoch 775/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 4.0610e-04 - acc: 1.0000 - val_loss: 7.9564 - val_acc: 0.2800\n",
      "Epoch 776/1000\n",
      "100/100 [==============================] - 0s 497us/step - loss: 2.8395e-04 - acc: 1.0000 - val_loss: 8.0240 - val_acc: 0.2700\n",
      "Epoch 777/1000\n",
      "100/100 [==============================] - 0s 413us/step - loss: 2.8875e-04 - acc: 1.0000 - val_loss: 8.0775 - val_acc: 0.2700\n",
      "Epoch 778/1000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0242 - acc: 0.9900 - val_loss: 8.0904 - val_acc: 0.2700\n",
      "Epoch 779/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0299 - acc: 0.9900 - val_loss: 7.9310 - val_acc: 0.2700\n",
      "Epoch 780/1000\n",
      "100/100 [==============================] - 0s 437us/step - loss: 8.5281e-05 - acc: 1.0000 - val_loss: 7.8053 - val_acc: 0.2800\n",
      "Epoch 781/1000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 3.0908e-04 - acc: 1.0000 - val_loss: 7.7093 - val_acc: 0.2800\n",
      "Epoch 782/1000\n",
      "100/100 [==============================] - 0s 447us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 7.6328 - val_acc: 0.2800\n",
      "Epoch 783/1000\n",
      "100/100 [==============================] - 0s 420us/step - loss: 0.0107 - acc: 0.9900 - val_loss: 7.5693 - val_acc: 0.3000\n",
      "Epoch 784/1000\n",
      "100/100 [==============================] - 0s 455us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.5346 - val_acc: 0.3000\n",
      "Epoch 785/1000\n",
      "100/100 [==============================] - 0s 439us/step - loss: 2.8006e-04 - acc: 1.0000 - val_loss: 7.5116 - val_acc: 0.2900\n",
      "Epoch 786/1000\n",
      "100/100 [==============================] - 0s 439us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 7.4988 - val_acc: 0.2900\n",
      "Epoch 787/1000\n",
      "100/100 [==============================] - 0s 553us/step - loss: 0.0152 - acc: 0.9900 - val_loss: 7.5328 - val_acc: 0.2900\n",
      "Epoch 788/1000\n",
      "100/100 [==============================] - 0s 493us/step - loss: 0.0796 - acc: 0.9900 - val_loss: 7.4580 - val_acc: 0.3000\n",
      "Epoch 789/1000\n",
      "100/100 [==============================] - 0s 403us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 7.4184 - val_acc: 0.3200\n",
      "Epoch 790/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.3977 - val_acc: 0.3100\n",
      "Epoch 791/1000\n",
      "100/100 [==============================] - 0s 370us/step - loss: 2.6659e-04 - acc: 1.0000 - val_loss: 7.3877 - val_acc: 0.3000\n",
      "Epoch 792/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 7.3771 - val_acc: 0.3100\n",
      "Epoch 793/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.3626 - val_acc: 0.3100\n",
      "Epoch 794/1000\n",
      "100/100 [==============================] - 0s 578us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.3531 - val_acc: 0.3100\n",
      "Epoch 795/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0132 - acc: 0.9900 - val_loss: 7.3490 - val_acc: 0.3100\n",
      "Epoch 796/1000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 7.3616 - val_acc: 0.3100\n",
      "Epoch 797/1000\n",
      "100/100 [==============================] - 0s 479us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 7.3747 - val_acc: 0.3000\n",
      "Epoch 798/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3860 - val_acc: 0.3100\n",
      "Epoch 799/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 3.2625e-04 - acc: 1.0000 - val_loss: 7.4013 - val_acc: 0.3200\n",
      "Epoch 800/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 7.4184 - val_acc: 0.3000\n",
      "Epoch 801/1000\n",
      "100/100 [==============================] - 0s 426us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.4352 - val_acc: 0.3000\n",
      "Epoch 802/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.4556 - val_acc: 0.3000\n",
      "Epoch 803/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 5.2116e-04 - acc: 1.0000 - val_loss: 7.4739 - val_acc: 0.3000\n",
      "Epoch 804/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 2.6880e-04 - acc: 1.0000 - val_loss: 7.4905 - val_acc: 0.3000\n",
      "Epoch 805/1000\n",
      "100/100 [==============================] - 0s 479us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.5058 - val_acc: 0.3000\n",
      "Epoch 806/1000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 7.5213 - val_acc: 0.2900\n",
      "Epoch 807/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.5354 - val_acc: 0.2900\n",
      "Epoch 808/1000\n",
      "100/100 [==============================] - 0s 413us/step - loss: 6.8684e-04 - acc: 1.0000 - val_loss: 7.5495 - val_acc: 0.2900\n",
      "Epoch 809/1000\n",
      "100/100 [==============================] - 0s 459us/step - loss: 1.9326e-04 - acc: 1.0000 - val_loss: 7.5612 - val_acc: 0.2900\n",
      "Epoch 810/1000\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.0161 - acc: 0.9900 - val_loss: 7.5595 - val_acc: 0.2900\n",
      "Epoch 811/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 7.5500 - val_acc: 0.2900\n",
      "Epoch 812/1000\n",
      "100/100 [==============================] - 0s 447us/step - loss: 0.0219 - acc: 0.9900 - val_loss: 7.6077 - val_acc: 0.2900\n",
      "Epoch 813/1000\n",
      "100/100 [==============================] - 0s 385us/step - loss: 2.8379e-04 - acc: 1.0000 - val_loss: 7.6721 - val_acc: 0.2900\n",
      "Epoch 814/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 7.7180 - val_acc: 0.3000\n",
      "Epoch 815/1000\n",
      "100/100 [==============================] - 0s 473us/step - loss: 5.5300e-04 - acc: 1.0000 - val_loss: 7.7441 - val_acc: 0.3100\n",
      "Epoch 816/1000\n",
      "100/100 [==============================] - 0s 454us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 7.7501 - val_acc: 0.3100\n",
      "Epoch 817/1000\n",
      "100/100 [==============================] - 0s 418us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.7544 - val_acc: 0.3200\n",
      "Epoch 818/1000\n",
      "100/100 [==============================] - 0s 428us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.7611 - val_acc: 0.3200\n",
      "Epoch 819/1000\n",
      "100/100 [==============================] - 0s 483us/step - loss: 0.0216 - acc: 0.9900 - val_loss: 7.7548 - val_acc: 0.3300\n",
      "Epoch 820/1000\n",
      "100/100 [==============================] - 0s 483us/step - loss: 5.3946e-04 - acc: 1.0000 - val_loss: 7.7447 - val_acc: 0.3100\n",
      "Epoch 821/1000\n",
      "100/100 [==============================] - 0s 516us/step - loss: 0.0324 - acc: 0.9900 - val_loss: 7.7845 - val_acc: 0.3400\n",
      "Epoch 822/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 7.7890 - val_acc: 0.3300\n",
      "Epoch 823/1000\n",
      "100/100 [==============================] - 0s 477us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 7.7950 - val_acc: 0.3400\n",
      "Epoch 824/1000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.9597e-04 - acc: 1.0000 - val_loss: 7.8052 - val_acc: 0.3400\n",
      "Epoch 825/1000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 0.0639 - acc: 0.9800 - val_loss: 7.7141 - val_acc: 0.3400\n",
      "Epoch 826/1000\n",
      "100/100 [==============================] - 0s 463us/step - loss: 1.2823e-04 - acc: 1.0000 - val_loss: 7.6022 - val_acc: 0.3300\n",
      "Epoch 827/1000\n",
      "100/100 [==============================] - 0s 458us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.5812 - val_acc: 0.3300\n",
      "Epoch 828/1000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 0.0127 - acc: 0.9900 - val_loss: 7.5405 - val_acc: 0.3200\n",
      "Epoch 829/1000\n",
      "100/100 [==============================] - 0s 513us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 7.5038 - val_acc: 0.3000\n",
      "Epoch 830/1000\n",
      "100/100 [==============================] - 0s 488us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 7.4779 - val_acc: 0.3000\n",
      "Epoch 831/1000\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.0113 - acc: 0.9900 - val_loss: 7.4645 - val_acc: 0.3100\n",
      "Epoch 832/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0183 - acc: 0.9900 - val_loss: 7.4651 - val_acc: 0.3200\n",
      "Epoch 833/1000\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 7.4675 - val_acc: 0.3200\n",
      "Epoch 834/1000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 0.0424 - acc: 0.9900 - val_loss: 7.4714 - val_acc: 0.3100\n",
      "Epoch 835/1000\n",
      "100/100 [==============================] - 0s 404us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 7.4680 - val_acc: 0.3100\n",
      "Epoch 836/1000\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 7.4669 - val_acc: 0.3200\n",
      "Epoch 837/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0337 - acc: 0.9900 - val_loss: 7.4659 - val_acc: 0.3200\n",
      "Epoch 838/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 7.5894 - val_acc: 0.2900\n",
      "Epoch 839/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.7638 - val_acc: 0.3100\n",
      "Epoch 840/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 0.0141 - acc: 0.9900 - val_loss: 7.8511 - val_acc: 0.3000\n",
      "Epoch 841/1000\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 7.8763 - val_acc: 0.3000\n",
      "Epoch 842/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.8927 - val_acc: 0.3000\n",
      "Epoch 843/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0488 - acc: 0.9800 - val_loss: 7.8857 - val_acc: 0.3000\n",
      "Epoch 844/1000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 7.9368 - val_acc: 0.3100\n",
      "Epoch 845/1000\n",
      "100/100 [==============================] - 0s 506us/step - loss: 0.0192 - acc: 0.9900 - val_loss: 8.0066 - val_acc: 0.3200\n",
      "Epoch 846/1000\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 8.0398 - val_acc: 0.3200\n",
      "Epoch 847/1000\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 8.0735 - val_acc: 0.3200\n",
      "Epoch 848/1000\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 8.0960 - val_acc: 0.3200\n",
      "Epoch 849/1000\n",
      "100/100 [==============================] - 0s 427us/step - loss: 0.0102 - acc: 0.9900 - val_loss: 8.0759 - val_acc: 0.3300\n",
      "Epoch 850/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0214 - acc: 0.9900 - val_loss: 8.0240 - val_acc: 0.3400\n",
      "Epoch 851/1000\n",
      "100/100 [==============================] - 0s 448us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 7.9851 - val_acc: 0.3400\n",
      "Epoch 852/1000\n",
      "100/100 [==============================] - 0s 439us/step - loss: 0.0330 - acc: 0.9900 - val_loss: 7.9537 - val_acc: 0.3500\n",
      "Epoch 853/1000\n",
      "100/100 [==============================] - 0s 497us/step - loss: 0.0134 - acc: 0.9900 - val_loss: 7.9500 - val_acc: 0.3400\n",
      "Epoch 854/1000\n",
      "100/100 [==============================] - 0s 492us/step - loss: 0.0109 - acc: 0.9900 - val_loss: 7.9416 - val_acc: 0.3300\n",
      "Epoch 855/1000\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.0177 - acc: 0.9900 - val_loss: 7.9349 - val_acc: 0.3200\n",
      "Epoch 856/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 7.9334 - val_acc: 0.3300\n",
      "Epoch 857/1000\n",
      "100/100 [==============================] - 0s 357us/step - loss: 2.8172e-04 - acc: 1.0000 - val_loss: 7.9334 - val_acc: 0.3300\n",
      "Epoch 858/1000\n",
      "100/100 [==============================] - 0s 436us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 7.9307 - val_acc: 0.3300\n",
      "Epoch 859/1000\n",
      "100/100 [==============================] - 0s 495us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.9317 - val_acc: 0.3300\n",
      "Epoch 860/1000\n",
      "100/100 [==============================] - 0s 463us/step - loss: 7.2437e-04 - acc: 1.0000 - val_loss: 7.9344 - val_acc: 0.3300\n",
      "Epoch 861/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.9424 - val_acc: 0.3300\n",
      "Epoch 862/1000\n",
      "100/100 [==============================] - 0s 460us/step - loss: 0.0544 - acc: 0.9900 - val_loss: 7.9566 - val_acc: 0.3300\n",
      "Epoch 863/1000\n",
      "100/100 [==============================] - 0s 516us/step - loss: 0.0224 - acc: 0.9900 - val_loss: 7.9656 - val_acc: 0.3400\n",
      "Epoch 864/1000\n",
      "100/100 [==============================] - 0s 462us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 7.9651 - val_acc: 0.3500\n",
      "Epoch 865/1000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 7.9710 - val_acc: 0.3500\n",
      "Epoch 866/1000\n",
      "100/100 [==============================] - 0s 427us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 7.9818 - val_acc: 0.3500\n",
      "Epoch 867/1000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.9926 - val_acc: 0.3500\n",
      "Epoch 868/1000\n",
      "100/100 [==============================] - 0s 456us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 8.0111 - val_acc: 0.3400\n",
      "Epoch 869/1000\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 8.0460 - val_acc: 0.3400\n",
      "Epoch 870/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 0.0250 - acc: 0.9900 - val_loss: 8.0888 - val_acc: 0.3400\n",
      "Epoch 871/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 7.3355e-04 - acc: 1.0000 - val_loss: 8.1356 - val_acc: 0.3400\n",
      "Epoch 872/1000\n",
      "100/100 [==============================] - 0s 493us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 8.1706 - val_acc: 0.3200\n",
      "Epoch 873/1000\n",
      "100/100 [==============================] - 0s 492us/step - loss: 5.8739e-04 - acc: 1.0000 - val_loss: 8.1977 - val_acc: 0.3200\n",
      "Epoch 874/1000\n",
      "100/100 [==============================] - 0s 447us/step - loss: 5.9052e-04 - acc: 1.0000 - val_loss: 8.2204 - val_acc: 0.3200\n",
      "Epoch 875/1000\n",
      "100/100 [==============================] - 0s 487us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 8.2651 - val_acc: 0.3200\n",
      "Epoch 876/1000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.3030 - val_acc: 0.3200\n",
      "Epoch 877/1000\n",
      "100/100 [==============================] - 0s 476us/step - loss: 0.0231 - acc: 0.9900 - val_loss: 8.3288 - val_acc: 0.3200\n",
      "Epoch 878/1000\n",
      "100/100 [==============================] - 0s 494us/step - loss: 0.0126 - acc: 0.9900 - val_loss: 8.2581 - val_acc: 0.3400\n",
      "Epoch 879/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 0.0301 - acc: 0.9900 - val_loss: 8.1761 - val_acc: 0.3500\n",
      "Epoch 880/1000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.1422e-04 - acc: 1.0000 - val_loss: 8.0907 - val_acc: 0.3600\n",
      "Epoch 881/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 8.9655e-04 - acc: 1.0000 - val_loss: 8.0270 - val_acc: 0.3600\n",
      "Epoch 882/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 7.9837 - val_acc: 0.3600\n",
      "Epoch 883/1000\n",
      "100/100 [==============================] - 0s 492us/step - loss: 3.7357e-04 - acc: 1.0000 - val_loss: 7.9581 - val_acc: 0.3600\n",
      "Epoch 884/1000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 5.9329e-04 - acc: 1.0000 - val_loss: 7.9421 - val_acc: 0.3600\n",
      "Epoch 885/1000\n",
      "100/100 [==============================] - 0s 454us/step - loss: 4.1896e-04 - acc: 1.0000 - val_loss: 7.9325 - val_acc: 0.3600\n",
      "Epoch 886/1000\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 7.9227 - val_acc: 0.3600\n",
      "Epoch 887/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 7.9183 - val_acc: 0.3600\n",
      "Epoch 888/1000\n",
      "100/100 [==============================] - 0s 380us/step - loss: 7.5695e-04 - acc: 1.0000 - val_loss: 7.9194 - val_acc: 0.3600\n",
      "Epoch 889/1000\n",
      "100/100 [==============================] - 0s 384us/step - loss: 0.0173 - acc: 0.9900 - val_loss: 7.8666 - val_acc: 0.3500\n",
      "Epoch 890/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 7.8473 - val_acc: 0.3500\n",
      "Epoch 891/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 2.6090e-04 - acc: 1.0000 - val_loss: 7.8490 - val_acc: 0.3500\n",
      "Epoch 892/1000\n",
      "100/100 [==============================] - 0s 477us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 7.8553 - val_acc: 0.3500\n",
      "Epoch 893/1000\n",
      "100/100 [==============================] - 0s 443us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 7.8617 - val_acc: 0.3600\n",
      "Epoch 894/1000\n",
      "100/100 [==============================] - 0s 387us/step - loss: 5.1051e-04 - acc: 1.0000 - val_loss: 7.8649 - val_acc: 0.3700\n",
      "Epoch 895/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 6.6117e-04 - acc: 1.0000 - val_loss: 7.8717 - val_acc: 0.3700\n",
      "Epoch 896/1000\n",
      "100/100 [==============================] - 0s 626us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 7.8858 - val_acc: 0.3700\n",
      "Epoch 897/1000\n",
      "100/100 [==============================] - 0s 427us/step - loss: 0.0116 - acc: 0.9900 - val_loss: 7.9649 - val_acc: 0.3700\n",
      "Epoch 898/1000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.4532e-04 - acc: 1.0000 - val_loss: 8.0903 - val_acc: 0.3600\n",
      "Epoch 899/1000\n",
      "100/100 [==============================] - 0s 430us/step - loss: 6.8337e-04 - acc: 1.0000 - val_loss: 8.1842 - val_acc: 0.3600\n",
      "Epoch 900/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 8.2680 - val_acc: 0.3600\n",
      "Epoch 901/1000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 8.3414 - val_acc: 0.3600\n",
      "Epoch 902/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0380 - acc: 0.9900 - val_loss: 8.4217 - val_acc: 0.3500\n",
      "Epoch 903/1000\n",
      "100/100 [==============================] - 0s 403us/step - loss: 7.1899e-04 - acc: 1.0000 - val_loss: 8.4938 - val_acc: 0.3500\n",
      "Epoch 904/1000\n",
      "100/100 [==============================] - 0s 444us/step - loss: 3.9623e-04 - acc: 1.0000 - val_loss: 8.5551 - val_acc: 0.3500\n",
      "Epoch 905/1000\n",
      "100/100 [==============================] - 0s 503us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 8.6041 - val_acc: 0.3500\n",
      "Epoch 906/1000\n",
      "100/100 [==============================] - 0s 488us/step - loss: 9.5732e-04 - acc: 1.0000 - val_loss: 8.6408 - val_acc: 0.3600\n",
      "Epoch 907/1000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 8.6673 - val_acc: 0.3600\n",
      "Epoch 908/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 8.6162 - val_acc: 0.3600\n",
      "Epoch 909/1000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 3.1032e-04 - acc: 1.0000 - val_loss: 8.5734 - val_acc: 0.3600\n",
      "Epoch 910/1000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 6.4741e-04 - acc: 1.0000 - val_loss: 8.5358 - val_acc: 0.3600\n",
      "Epoch 911/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0140 - acc: 0.9900 - val_loss: 8.4779 - val_acc: 0.3600\n",
      "Epoch 912/1000\n",
      "100/100 [==============================] - 0s 495us/step - loss: 9.2154e-04 - acc: 1.0000 - val_loss: 8.4069 - val_acc: 0.3500\n",
      "Epoch 913/1000\n",
      "100/100 [==============================] - 0s 447us/step - loss: 4.2746e-04 - acc: 1.0000 - val_loss: 8.3534 - val_acc: 0.3500\n",
      "Epoch 914/1000\n",
      "100/100 [==============================] - 0s 456us/step - loss: 5.8624e-04 - acc: 1.0000 - val_loss: 8.3109 - val_acc: 0.3600\n",
      "Epoch 915/1000\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 8.2759 - val_acc: 0.3500\n",
      "Epoch 916/1000\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 8.2424 - val_acc: 0.3600\n",
      "Epoch 917/1000\n",
      "100/100 [==============================] - 0s 494us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 8.2206 - val_acc: 0.3600\n",
      "Epoch 918/1000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 7.2462e-04 - acc: 1.0000 - val_loss: 8.2047 - val_acc: 0.3600\n",
      "Epoch 919/1000\n",
      "100/100 [==============================] - 0s 486us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 8.1936 - val_acc: 0.3600\n",
      "Epoch 920/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 8.1731 - val_acc: 0.3500\n",
      "Epoch 921/1000\n",
      "100/100 [==============================] - 0s 466us/step - loss: 1.3689e-04 - acc: 1.0000 - val_loss: 8.1572 - val_acc: 0.3500\n",
      "Epoch 922/1000\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 8.1461 - val_acc: 0.3500\n",
      "Epoch 923/1000\n",
      "100/100 [==============================] - 0s 458us/step - loss: 3.9152e-04 - acc: 1.0000 - val_loss: 8.1387 - val_acc: 0.3500\n",
      "Epoch 924/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 0.0614 - acc: 0.9800 - val_loss: 8.0313 - val_acc: 0.3500\n",
      "Epoch 925/1000\n",
      "100/100 [==============================] - 0s 479us/step - loss: 4.9973e-04 - acc: 1.0000 - val_loss: 7.9132 - val_acc: 0.3300\n",
      "Epoch 926/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 7.8700e-04 - acc: 1.0000 - val_loss: 7.8199 - val_acc: 0.3300\n",
      "Epoch 927/1000\n",
      "100/100 [==============================] - 0s 487us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.7424 - val_acc: 0.3300\n",
      "Epoch 928/1000\n",
      "100/100 [==============================] - 0s 489us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 7.7014 - val_acc: 0.3300\n",
      "Epoch 929/1000\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.6742 - val_acc: 0.3300\n",
      "Epoch 930/1000\n",
      "100/100 [==============================] - 0s 466us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 7.6861 - val_acc: 0.3300\n",
      "Epoch 931/1000\n",
      "100/100 [==============================] - 0s 512us/step - loss: 3.4823e-04 - acc: 1.0000 - val_loss: 7.7186 - val_acc: 0.3300\n",
      "Epoch 932/1000\n",
      "100/100 [==============================] - 0s 448us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.7451 - val_acc: 0.3300\n",
      "Epoch 933/1000\n",
      "100/100 [==============================] - 0s 473us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 7.8049 - val_acc: 0.3300\n",
      "Epoch 934/1000\n",
      "100/100 [==============================] - 0s 493us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 7.8683 - val_acc: 0.3300\n",
      "Epoch 935/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 3.2098e-04 - acc: 1.0000 - val_loss: 7.9182 - val_acc: 0.3300\n",
      "Epoch 936/1000\n",
      "100/100 [==============================] - 0s 442us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 7.9723 - val_acc: 0.3300\n",
      "Epoch 937/1000\n",
      "100/100 [==============================] - 0s 452us/step - loss: 1.5132e-04 - acc: 1.0000 - val_loss: 8.0193 - val_acc: 0.3300\n",
      "Epoch 938/1000\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 8.0458 - val_acc: 0.3300\n",
      "Epoch 939/1000\n",
      "100/100 [==============================] - 0s 428us/step - loss: 0.0195 - acc: 0.9900 - val_loss: 8.0908 - val_acc: 0.3300\n",
      "Epoch 940/1000\n",
      "100/100 [==============================] - 0s 444us/step - loss: 1.6876e-04 - acc: 1.0000 - val_loss: 8.1329 - val_acc: 0.3300\n",
      "Epoch 941/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.0077 - acc: 0.9900 - val_loss: 8.1333 - val_acc: 0.3300\n",
      "Epoch 942/1000\n",
      "100/100 [==============================] - 0s 487us/step - loss: 0.0398 - acc: 0.9900 - val_loss: 8.1892 - val_acc: 0.3200\n",
      "Epoch 943/1000\n",
      "100/100 [==============================] - 0s 433us/step - loss: 2.9524e-04 - acc: 1.0000 - val_loss: 8.2450 - val_acc: 0.3100\n",
      "Epoch 944/1000\n",
      "100/100 [==============================] - 0s 434us/step - loss: 3.5578e-04 - acc: 1.0000 - val_loss: 8.3116 - val_acc: 0.3100\n",
      "Epoch 945/1000\n",
      "100/100 [==============================] - 0s 452us/step - loss: 0.0803 - acc: 0.9800 - val_loss: 8.5760 - val_acc: 0.3200\n",
      "Epoch 946/1000\n",
      "100/100 [==============================] - 0s 433us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 8.8827 - val_acc: 0.3200\n",
      "Epoch 947/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 5.6230e-04 - acc: 1.0000 - val_loss: 9.0228 - val_acc: 0.3100\n",
      "Epoch 948/1000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 9.1282 - val_acc: 0.3100\n",
      "Epoch 949/1000\n",
      "100/100 [==============================] - 0s 426us/step - loss: 6.0926e-04 - acc: 1.0000 - val_loss: 9.2032 - val_acc: 0.3100\n",
      "Epoch 950/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 0.0111 - acc: 0.9900 - val_loss: 9.1593 - val_acc: 0.3200\n",
      "Epoch 951/1000\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 9.0214 - val_acc: 0.3200\n",
      "Epoch 952/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 3.3690e-04 - acc: 1.0000 - val_loss: 8.9137 - val_acc: 0.3400\n",
      "Epoch 953/1000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 1.6704e-04 - acc: 1.0000 - val_loss: 8.8359 - val_acc: 0.3600\n",
      "Epoch 954/1000\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 8.7830 - val_acc: 0.3500\n",
      "Epoch 955/1000\n",
      "100/100 [==============================] - 0s 465us/step - loss: 5.3633e-04 - acc: 1.0000 - val_loss: 8.7424 - val_acc: 0.3500\n",
      "Epoch 956/1000\n",
      "100/100 [==============================] - 0s 483us/step - loss: 7.6040e-04 - acc: 1.0000 - val_loss: 8.7114 - val_acc: 0.3500\n",
      "Epoch 957/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0123 - acc: 0.9900 - val_loss: 8.6624 - val_acc: 0.3600\n",
      "Epoch 958/1000\n",
      "100/100 [==============================] - 0s 454us/step - loss: 7.6439e-04 - acc: 1.0000 - val_loss: 8.6089 - val_acc: 0.3600\n",
      "Epoch 959/1000\n",
      "100/100 [==============================] - 0s 464us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 8.5298 - val_acc: 0.3500\n",
      "Epoch 960/1000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 8.9877e-04 - acc: 1.0000 - val_loss: 8.4309 - val_acc: 0.3300\n",
      "Epoch 961/1000\n",
      "100/100 [==============================] - 0s 423us/step - loss: 4.1213e-04 - acc: 1.0000 - val_loss: 8.3274 - val_acc: 0.3300\n",
      "Epoch 962/1000\n",
      "100/100 [==============================] - 0s 439us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 8.2338 - val_acc: 0.3200\n",
      "Epoch 963/1000\n",
      "100/100 [==============================] - 0s 443us/step - loss: 0.0112 - acc: 0.9900 - val_loss: 8.2077 - val_acc: 0.3200\n",
      "Epoch 964/1000\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 8.1826 - val_acc: 0.3200\n",
      "Epoch 965/1000\n",
      "100/100 [==============================] - 0s 456us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.1613 - val_acc: 0.3200\n",
      "Epoch 966/1000\n",
      "100/100 [==============================] - 0s 450us/step - loss: 9.5984e-04 - acc: 1.0000 - val_loss: 8.1466 - val_acc: 0.3200\n",
      "Epoch 967/1000\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 8.1582 - val_acc: 0.3200\n",
      "Epoch 968/1000\n",
      "100/100 [==============================] - 0s 443us/step - loss: 3.8816e-04 - acc: 1.0000 - val_loss: 8.1720 - val_acc: 0.3200\n",
      "Epoch 969/1000\n",
      "100/100 [==============================] - 0s 519us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 8.1699 - val_acc: 0.3200\n",
      "Epoch 970/1000\n",
      "100/100 [==============================] - 0s 463us/step - loss: 3.7966e-04 - acc: 1.0000 - val_loss: 8.1670 - val_acc: 0.3100\n",
      "Epoch 971/1000\n",
      "100/100 [==============================] - 0s 487us/step - loss: 5.8589e-04 - acc: 1.0000 - val_loss: 8.1663 - val_acc: 0.3100\n",
      "Epoch 972/1000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 8.1728 - val_acc: 0.3100\n",
      "Epoch 973/1000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 8.1946 - val_acc: 0.3100\n",
      "Epoch 974/1000\n",
      "100/100 [==============================] - 0s 436us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 8.2081 - val_acc: 0.3100\n",
      "Epoch 975/1000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 8.2241 - val_acc: 0.3100\n",
      "Epoch 976/1000\n",
      "100/100 [==============================] - 0s 436us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 8.2383 - val_acc: 0.3100\n",
      "Epoch 977/1000\n",
      "100/100 [==============================] - 0s 346us/step - loss: 2.3534e-04 - acc: 1.0000 - val_loss: 8.2491 - val_acc: 0.3100\n",
      "Epoch 978/1000\n",
      "100/100 [==============================] - 0s 383us/step - loss: 2.9763e-04 - acc: 1.0000 - val_loss: 8.2572 - val_acc: 0.3100\n",
      "Epoch 979/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 2.6626e-04 - acc: 1.0000 - val_loss: 8.2645 - val_acc: 0.3100\n",
      "Epoch 980/1000\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 8.2653 - val_acc: 0.3100\n",
      "Epoch 981/1000\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 8.2739 - val_acc: 0.3200\n",
      "Epoch 982/1000\n",
      "100/100 [==============================] - 0s 429us/step - loss: 9.4838e-04 - acc: 1.0000 - val_loss: 8.2859 - val_acc: 0.3200\n",
      "Epoch 983/1000\n",
      "100/100 [==============================] - 0s 426us/step - loss: 5.1419e-04 - acc: 1.0000 - val_loss: 8.2992 - val_acc: 0.3200\n",
      "Epoch 984/1000\n",
      "100/100 [==============================] - 0s 410us/step - loss: 6.7466e-04 - acc: 1.0000 - val_loss: 8.3127 - val_acc: 0.3200\n",
      "Epoch 985/1000\n",
      "100/100 [==============================] - 0s 470us/step - loss: 8.2183e-04 - acc: 1.0000 - val_loss: 8.3249 - val_acc: 0.3200\n",
      "Epoch 986/1000\n",
      "100/100 [==============================] - 0s 428us/step - loss: 0.0414 - acc: 0.9900 - val_loss: 8.3499 - val_acc: 0.3200\n",
      "Epoch 987/1000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 8.3997 - val_acc: 0.3100\n",
      "Epoch 988/1000\n",
      "100/100 [==============================] - 0s 425us/step - loss: 1.8293e-04 - acc: 1.0000 - val_loss: 8.4525 - val_acc: 0.3100\n",
      "Epoch 989/1000\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0121 - acc: 0.9900 - val_loss: 8.4110 - val_acc: 0.3200\n",
      "Epoch 990/1000\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 8.3772 - val_acc: 0.3200\n",
      "Epoch 991/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 8.3660 - val_acc: 0.3200\n",
      "Epoch 992/1000\n",
      "100/100 [==============================] - 0s 384us/step - loss: 3.7969e-04 - acc: 1.0000 - val_loss: 8.3727 - val_acc: 0.3300\n",
      "Epoch 993/1000\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 8.3836 - val_acc: 0.3400\n",
      "Epoch 994/1000\n",
      "100/100 [==============================] - 0s 403us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 8.3950 - val_acc: 0.3400\n",
      "Epoch 995/1000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0148 - acc: 0.9900 - val_loss: 8.4009 - val_acc: 0.3400\n",
      "Epoch 996/1000\n",
      "100/100 [==============================] - 0s 390us/step - loss: 4.4517e-04 - acc: 1.0000 - val_loss: 8.4036 - val_acc: 0.3500\n",
      "Epoch 997/1000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 3.1623e-04 - acc: 1.0000 - val_loss: 8.4060 - val_acc: 0.3500\n",
      "Epoch 998/1000\n",
      "100/100 [==============================] - 0s 531us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 8.4030 - val_acc: 0.3400\n",
      "Epoch 999/1000\n",
      "100/100 [==============================] - 0s 406us/step - loss: 4.0498e-04 - acc: 1.0000 - val_loss: 8.3954 - val_acc: 0.3300\n",
      "Epoch 1000/1000\n",
      "100/100 [==============================] - 0s 394us/step - loss: 1.6700e-04 - acc: 1.0000 - val_loss: 8.3907 - val_acc: 0.3300\n"
     ]
    }
   ],
   "source": [
    "filter_nums = 128\n",
    "def build_model():\n",
    "        inputs  = Input(shape=(maxLength, ), dtype='float64', name='inputs')    \n",
    "        embedding_layer = Embedding(input_vocab_size,EMBEDDING_DIM,weights=[embedding_matrix], input_length=maxLength, trainable=True,name = 'word_emb')(inputs)\n",
    "        embedding_layer = SpatialDropout1D(0.75)(embedding_layer)\n",
    "                \n",
    "              \n",
    "        lstm_feature1 = CuDNNLSTM(filter_nums, return_sequences=True)(embedding_layer)\n",
    "\n",
    "        att1 = AttentionWithContext()(lstm_feature1)\n",
    "        att1 = Addition()(att1)\n",
    "\n",
    "        fc1 = Dropout(0.5)(Dense(256, name = 'dense_1')(att1))\n",
    "        output1 = Dense(len(classes),name=\"output1\", activation='softmax')(fc1)\n",
    "\n",
    "    \n",
    "        # define optimizer\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=output1)\n",
    "        tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
    "        \n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "        history = model.fit(X_train_encode, np.array(y_train_encode), validation_data = (X_val_encode,np.array(y_val_encode)) , batch_size=50, epochs=1000,callbacks=[tensorBoardCallback])\n",
    "        return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MmCoU4ksp67"
   },
   "source": [
    "## 2.Predict the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l-go-cbR7aE"
   },
   "source": [
    "### Generator model\n",
    "\n",
    "\n",
    "```\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "gen_encoder = Model(encoder_input,[encoder_output3,encoder_h3,encoder_c3])\n",
    "\n",
    "gen_decoder_value_input = Input(shape=(question_sequence_size,hidden_size))\n",
    "gen_decoder_h_input = Input(shape=[hidden_size])\n",
    "gen_decoder_c_input = Input(shape=[hidden_size])\n",
    "\n",
    "gen_decoder_embedded = decoder_embedding(decoder_input)\n",
    "gen_decoder_output,gen_decoder_h,gen_decoder_c = decoder_lstm(gen_decoder_embedded,initial_state=[gen_decoder_h_input,gen_decoder_c_input])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHB3CI-2SDYy"
   },
   "source": [
    "### Attention([querys,values])\n",
    "\n",
    "\n",
    "```\n",
    "gen_attention_context = attn_layer([gen_decoder_output,gen_decoder_value_input])\n",
    "gen_decoder_output = Concatenate(axis=-1)([gen_decoder_output,gen_attention_context])\n",
    "\n",
    "gen_decoder_output = dense1(gen_decoder_output)\n",
    "gen_decoder_output = decoder_softmax(gen_decoder_output)\n",
    "\n",
    "gen_decoder = Model([decoder_input]+[gen_decoder_value_input,gen_decoder_h_input,gen_decoder_c_input],[gen_decoder_output]+[gen_decoder_h,gen_decoder_c])\n",
    "plot_model(gen_encoder)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "![z2493438225890_47664fd1af1148a147937ce8f02185bc.jpg](data:image/jpeg;base64,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)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmcATVnzSouq"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "plot_model(gen_decoder)\n",
    "```\n",
    "\n",
    "\n",
    "![z2493448009920_5e141f50acb4f5a1a7cb6af511bef903.jpg](data:image/jpeg;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQwJ75p_WdBJ",
    "outputId": "29e296e7-8fb7-4629-bdc9-0d9d8a281b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sadness', 'Enjoyment', 'Enjoyment', 'Other', 'Enjoyment', 'Other', 'Other', 'Other', 'Other', 'Enjoyment']\n"
     ]
    }
   ],
   "source": [
    "X_test_encode = np.array(pad_sequences(input_tokenizer.texts_to_sequences(X_test), maxlen=maxLength,padding=\"post\"))\n",
    "test_length = len(X_test_encode)\n",
    "\n",
    "y_predict = []\n",
    "predicted = model.predict(X_test_encode)\n",
    "for predict in predicted:\n",
    "    index2, value = max(enumerate(predict), key=operator.itemgetter(1))\n",
    "    y_predict.append(classes[index2])\n",
    "    \n",
    "print(y_predict[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rkh2YZJNRxys"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VXZOPGcs9O_"
   },
   "source": [
    "## 3.Report the performance metrics (Accuracy, F1-score...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoEymwgf0joR",
    "outputId": "acb626db-c2ec-4b98-dee7-2eb926e42e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result model LSTM + Attention layer\n",
      "Results of the models\n",
      "Precision:  0.19096470588235298\n",
      "Recall:  0.22\n",
      "F1-Score:  0.22\n",
      "Accuracy:  0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.00      0.00      0.00         7\n",
      "     Disgust       0.00      0.00      0.00        21\n",
      "   Enjoyment       0.28      0.41      0.33        34\n",
      "        Fear       0.00      0.00      0.00         1\n",
      "       Other       0.18      0.33      0.23        18\n",
      "     Sadness       0.00      0.00      0.00         3\n",
      "    Surprise       0.40      0.12      0.19        16\n",
      "\n",
      "    accuracy                           0.22       100\n",
      "   macro avg       0.12      0.12      0.11       100\n",
      "weighted avg       0.19      0.22      0.19       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_predict, average='weighted')\n",
    "recall = recall_score(y_test, y_predict, average='weighted')\n",
    "f1score = f1_score(y_test, y_predict, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(\"Result model LSTM + Attention layer\")\n",
    "print(\"Results of the models\")\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1-Score: \", f1score)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2pll3z0tLDW"
   },
   "source": [
    "# VII.Enter the demo program into 1 sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3WyndWU_0joU"
   },
   "outputs": [],
   "source": [
    "def sample_indices(str):\n",
    "  demo_pre = clean_doc(str)\n",
    "  X_demo_encode = np.array(pad_sequences(input_tokenizer.texts_to_sequences([demo_pre]), maxlen=maxLength,padding=\"post\"))\n",
    "  predicted = model.predict(X_demo_encode)\n",
    "  index2, value = max(enumerate(predicted[0]), key=operator.itemgetter(1))\n",
    "  print(str)\n",
    "  print(\"Predict the results:\", classes[index2])\n",
    "  print(\"=\"*45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKS-TPecTNhI"
   },
   "source": [
    "## Results on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzD77bVsHnt6",
    "outputId": "98560ecc-ca1c-4335-9e48-6fb7f0b7e842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "một giọng nói của người trải qua sự bi_đát mong được lên tv some day\n",
      "Predict the results: Enjoyment\n",
      "=============================================\n",
      "vũ_nương_à\n",
      "Predict the results: Other\n",
      "=============================================\n",
      "chào anh tuân anh thích ăn món gì nhất\n",
      "Predict the results: Enjoyment\n",
      "=============================================\n",
      "anh tuna ơi em thấy cj cừu xinh phết anh có_thể cho em gửi lời chúc sức_khỏe đến cj cừu ko ạ mong anh cho em lên sóng mãi_mãi ủng_hộ anh tuna cj_cừu\n",
      "Predict the results: Enjoyment\n",
      "=============================================\n",
      "giọng ông đọc radio buồn được phết\n",
      "Predict the results: Sadness\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "for i in X_train[:5]:\n",
    "  sample_indices(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9shd0HZUTOa"
   },
   "source": [
    "## Results on sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVJw8Vi5thbF",
    "outputId": "4fdb7197-83ca-46ca-ada3-b5411ba4e068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi buồn không biết vì sao tôi buồn chắc vì người ta vui.Người ta vui vì tôi buồn.Cười cho đời thêm màu mới\n",
      "Predict the results: Sadness\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "sample_indices('Tôi buồn không biết vì sao tôi buồn chắc vì người ta vui.Người ta vui vì tôi buồn.Cười cho đời thêm màu mới')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Task3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
