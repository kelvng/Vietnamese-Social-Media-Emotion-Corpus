{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpZkvkuny0k6"
      },
      "source": [
        "#**LSTM + Attention**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeNTCKnKnN6R"
      },
      "source": [
        "# I.Import Library\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaU0uvTT3q9c"
      },
      "source": [
        "## Install Packet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2syH6iwq3nyh",
        "outputId": "8b74aaee-c7b4-4bac-aed7-20c45e548b52"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install keras==2.2.5\n",
        "!pip install pyvi"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN8rgbmrdKJP"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import random\n",
        "import os, pickle, re, keras, sklearn, string\n",
        "from keras.callbacks import *\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from pyvi import ViTokenizer, ViPosTagger\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "import gensim, operator, json\n",
        "import pandas as pd\n",
        "from sklearn.metrics import *\n",
        "import keras.backend as K\n",
        "from keras.models import *\n",
        "from keras import initializers, regularizers\n",
        "from keras import optimizers\n",
        "from keras.engine.topology import Layer\n",
        "from keras import constraints"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqqjA5rmnXW9"
      },
      "source": [
        "# II.Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCS65PY-6a2v",
        "outputId": "1130579f-011b-49f6-97e6-3e4b2774bfa3"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "if not os.path.exists(\"baomoi.model.bin\"):\n",
        "  !wget -P /content/ -c \"https://thiaisotajppub.s3-ap-northeast-1.amazonaws.com/publicfiles/baomoi.model.bin\"\n",
        "else:\n",
        "  print(\"word2vec already downloaded\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "word2vec already downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yczmPOK6ez2",
        "outputId": "23fbc04f-832c-48a2-8f67-5872224a8a52"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "if not os.path.exists(\"UIT-VSMEC.zip\"):\n",
        "  !wget https://github.com/nthanhkhang/Vietnamese-Social-Media-Emotion-Corpus/raw/main/Data/UIT-VSMEC.zip\n",
        "else:\n",
        "  print(\"UIT-VSMEC.zip already downloaded\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "UIT-VSMEC.zip already downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6I-G2B7CwyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789f632f-d889-49f6-9c51-86e3074f2ac0"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"UIT-VSMEC.zip\",\"r\") as zf:\n",
        "    zf.extractall()\n",
        "print(zf)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<zipfile.ZipFile [closed]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp1-Qa_81FEY"
      },
      "source": [
        "path_train ='data/train_nor_811.csv'\n",
        "path_valid ='data/valid_nor_811.csv'\n",
        "path_test ='data/test_nor_811.csv'\n",
        "path_stopword = 'data/stopwords.txt'"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3JUFIaAndQo"
      },
      "source": [
        "# III.Word2vec using baomoi.model.bin\n",
        "\n",
        "*   Function reading pretrain word embedding library.\n",
        "*   The word embedding pretrain has been trained in new news, 300-way news\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skg7lUZ9LYAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406e4dee-ab1a-4615-cd5c-6d24cf30e5a0"
      },
      "source": [
        "path_embedding= 'baomoi.model.bin'\n",
        "\n",
        "import io\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word_embedding = KeyedVectors.load_word2vec_format(path_embedding, binary=True)\n",
        "# Example of taking vector of 1 word in the word embedding pretrain\n",
        "EMBEDDING_DIM = word_embedding['yêu'].shape[0]\n",
        "print(\"Embedding: \",EMBEDDING_DIM)\n",
        "# Vector of love words in pretrained word embedding set.\n",
        "print(word_embedding['yêu'])\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding:  400\n",
            "[-0.78774583 -0.22327825 -0.6274532  -2.7228408  -2.2186291   0.38002455\n",
            "  3.8660462   0.9853684  -1.4683082  -1.7013292  -0.5839958  -0.14467287\n",
            "  3.600142    3.381808   -0.02930526  3.0047843  -0.2006207  -1.0937127\n",
            "  1.7360235   2.3691583  -0.71597415  3.319453    0.2824182  -3.0814204\n",
            "  2.6810844  -0.810977    1.5186927  -2.10329     1.3271075  -1.3646411\n",
            " -0.11144319 -4.6505136  -1.7251624  -2.31126     1.583203   -0.8746506\n",
            " -2.6937015  -1.7733976   0.557898   -1.7562917   1.3282276  -0.3805479\n",
            " -1.3979301  -0.1536707  -1.1909302   1.3283668   0.22275637 -2.7959821\n",
            " -5.188217   -0.6404673   0.0164395   0.67177856 -1.4948794   0.21867418\n",
            " -1.4103376   0.99262404  2.2180524  -0.4881204   3.0988753  -0.31382522\n",
            "  1.3226501   0.21269594 -1.6409203   1.7758838   2.3379912  -2.4666297\n",
            " -0.599687    0.551105   -1.3755493  -1.4293027  -2.6366289   0.40759587\n",
            " -0.77850854 -0.6169452  -0.84525913  0.02801617  2.1296268   0.13715844\n",
            " -1.1562283  -2.1226277  -0.1346792   0.88932824 -1.5711976   0.36148685\n",
            "  2.2572796  -2.0762215   1.736077   -0.3133224   0.48849696  2.1262195\n",
            " -2.3417432   0.7264937   1.3197432  -1.0578146   1.9603167  -1.957219\n",
            " -0.47556064 -3.2944543  -1.540249    1.6060241   0.02990843 -1.0645736\n",
            " -0.5550473   1.589397   -0.5811684  -1.2199221  -0.9025384  -1.2436662\n",
            "  0.50163126  0.11698119  0.8760743   0.8978141  -1.8893797  -0.1424527\n",
            " -3.0423136  -0.88489795  0.49000955 -3.4689097  -1.8564429  -0.66697997\n",
            "  5.3912683  -2.092744   -0.5973023  -0.7118058  -1.0953093   0.4417508\n",
            "  2.440871    1.1271865   1.4602836  -2.714987   -1.3927895  -0.16143057\n",
            "  0.07596377 -2.0885456  -1.0929846  -1.1670731   0.7352281  -1.0726835\n",
            "  0.4963534  -0.78458273  2.3078787  -3.5055773   0.9567256  -0.5207236\n",
            "  0.36697528  0.8511779   0.878965    1.3028007   0.04724613  0.9892602\n",
            " -0.8373782   0.27926713  2.268885   -0.11917569  0.8163163   0.3869213\n",
            "  0.20561185 -2.2969527  -1.6468542  -3.9922614  -0.96281457  3.2537632\n",
            "  0.48358652 -0.6078726   3.2632709   0.11489751 -2.6600893   0.92677915\n",
            " -0.528953    3.4760187   2.31958     2.23189     2.2253554  -1.8307585\n",
            " -1.7324418  -1.2364737  -4.273679    0.9341229   0.59669524 -0.03376843\n",
            " -2.971719    1.9712305  -0.549242    0.4829846   1.4618144  -1.3703161\n",
            " -1.1212839   0.4291749   1.4675773  -0.67144257 -0.49444234  1.7652586\n",
            "  1.7143794   0.54265493  2.1978571   3.2426474  -2.7528286  -2.2640996\n",
            "  0.09805597  1.2702079   1.156494   -1.1671641  -2.3361897   1.2424865\n",
            " -2.1413488  -0.22989413 -2.7570245  -1.2689328  -0.11422111  0.340871\n",
            " -0.72356385 -3.100242   -0.2113436   0.08352826  3.0843058   0.2549431\n",
            "  3.6576512  -0.71284246 -1.8232595  -1.0566906  -0.7372802   0.18872899\n",
            "  0.11927979  3.0378866   0.7687284   0.7458194   3.392024   -0.10601766\n",
            "  1.7550762  -3.9328496   0.5543825   2.4240685   2.4877627  -1.8583341\n",
            " -2.7361338   0.9327119   1.4136555   0.6736002  -0.56006515 -0.17299697\n",
            "  2.3964696   1.4890865   0.47563386 -1.7579868  -3.2750478  -2.711356\n",
            "  1.1631078   0.5226146  -0.77252626  2.0378802  -2.1662908   1.1695647\n",
            "  1.0302314   1.2815226   1.8774925   1.0482382  -2.829525   -1.3818443\n",
            "  1.0274167  -0.61302423  0.24060939 -2.8208141   1.2254591  -1.9544963\n",
            "  1.7342434  -0.9264713   0.39906958  1.4076114   0.68284744  2.4939642\n",
            "  2.1315014   0.20849855 -1.4851028   4.6376705   2.2327776   2.2943447\n",
            " -1.253777   -2.385657   -2.5678577  -1.7067193   2.387362   -1.3572613\n",
            " -4.5016227   0.7827232  -0.44352373  0.3998332  -0.5178318   0.6794015\n",
            "  3.7974224  -0.774167   -1.1981938   0.3985697  -1.8760519   0.1238703\n",
            "  0.05213618 -1.1321199  -2.8599005  -1.7278007   2.1998515  -2.5468414\n",
            "  0.9428754   0.992005   -2.7554674  -1.364683   -0.8704408  -1.1697435\n",
            "  1.880865    1.9564949   3.1174672   0.14133504 -2.2360458  -1.173718\n",
            "  1.3261789  -2.2110426   0.589773    3.4267988   3.2046275  -0.91721445\n",
            "  0.7951813  -2.3174386  -0.8497346   1.6120318  -0.40876418  0.7933062\n",
            " -0.8393237  -0.41007656  2.8945262   0.993892   -1.7588191  -4.925732\n",
            " -2.4419074   3.0766954  -1.9000514  -2.0604458   3.4133394  -2.0102491\n",
            "  2.046963    0.71078193  2.2965722   1.72548     1.2269657  -2.2357993\n",
            "  0.50008225  4.8475957  -1.0541344   2.308317   -1.1630418   1.1258802\n",
            " -1.2478187   1.0942221   0.92810786 -1.5838045  -2.0654778  -0.28107494\n",
            "  2.4073355   1.3492072   0.48608387 -0.4716219   2.1616933  -1.3125483\n",
            "  1.5123384  -4.5521007  -1.8622614   1.088746    1.6043898  -4.609651\n",
            " -0.4500263   1.9802842   1.9102592  -0.47483805 -4.2590923   1.1523023\n",
            "  0.9832213   1.9767743   3.2593958   0.41252086  0.37052628  0.5532108\n",
            " -0.44213554  1.3767333  -0.8914752  -4.444391   -1.9290444  -1.6292545\n",
            " -2.6812217  -1.0284953   0.0313996   4.0027394   0.6476944  -0.02785059\n",
            " -2.4854484  -0.82289666  1.3539648   3.0980484  -1.3214976  -1.5370079\n",
            "  0.96148336  0.1992502   3.5529153   2.4300497 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo7k112MoVAQ"
      },
      "source": [
        "# IV. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5Gb-4LVo1bf"
      },
      "source": [
        "## 1.Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWTniSb1o0d9"
      },
      "source": [
        "def tokenizer(text):\n",
        "    token = ViTokenizer.tokenize(text)\n",
        "    return token"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsAfz-Kco86j"
      },
      "source": [
        "## 2.Delete Icon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCchYWSMo9y5"
      },
      "source": [
        "def deleteIcon(text):\n",
        "    text = text.lower()\n",
        "    s = ''\n",
        "    pattern = r\"[a-zA-ZaăâbcdđeêghiklmnoôơpqrstuưvxyàằầbcdđèềghìklmnòồờpqrstùừvxỳáắấbcdđéếghíklmnóốớpqrstúứvxýảẳẩbcdđẻểghỉklmnỏổởpqrstủửvxỷạặậbcdđẹệghịklmnọộợpqrstụựvxỵãẵẫbcdđẽễghĩklmnõỗỡpqrstũữvxỹAĂÂBCDĐEÊGHIKLMNOÔƠPQRSTUƯVXYÀẰẦBCDĐÈỀGHÌKLMNÒỒỜPQRSTÙỪVXỲÁẮẤBCDĐÉẾGHÍKLMNÓỐỚPQRSTÚỨVXÝẠẶẬBCDĐẸỆGHỊKLMNỌỘỢPQRSTỤỰVXỴẢẲẨBCDĐẺỂGHỈKLMNỎỔỞPQRSTỦỬVXỶÃẴẪBCDĐẼỄGHĨKLMNÕỖỠPQRSTŨỮVXỸ,._]\"\n",
        "    for char in text:\n",
        "        if char !=' ':\n",
        "            if len(re.findall(pattern, char)) != 0:\n",
        "                s+=char\n",
        "            elif char == '_':\n",
        "                s+=char\n",
        "        else:\n",
        "            s+=char\n",
        "    s = re.sub('\\\\s+',' ',s)\n",
        "    return s.strip()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5xJDr9epIEJ"
      },
      "source": [
        "## 3.Clean Doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1_TFsm9WdA0"
      },
      "source": [
        "def clean_doc(doc):\n",
        "    doc = tokenizer(doc)\n",
        "    for punc in string.punctuation:# delete all punctuation (!,? ..) in a sentence\n",
        "        if punc != \"_\":\n",
        "            doc = doc.replace(punc,' ')\n",
        "    doc = deleteIcon(doc) \n",
        "    doc = re.sub(r\"[0-9]+\", \" num \", doc)# Delete numbers\n",
        "    doc = doc.lower()#lowercase \n",
        "    doc = re.sub('\\\\s+',' ',doc)# Remove lots of spaces\n",
        "    return doc"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJlgGwaxudQc"
      },
      "source": [
        "## 4.Stopword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPeiHFV2vRMY"
      },
      "source": [
        "# from underthesea import word_tokenize\n",
        "def pre_process(questions):\n",
        "    stop_words = stopwords.words(\"english\")\n",
        "    questions_stop = [[t for t in tokens if (t not in stop_words) and (3 < len(t.strip()) < 15)]\n",
        "                      for tokens in questions_tokens]\n",
        "    questions_stop = pd.Series(questions_stop)\n",
        "    return questions_stop"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpylx70bxTGD"
      },
      "source": [
        "## 5.Word Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmCkYJpypwlS"
      },
      "source": [
        "# V.Train/Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usy-4ygPWdA2"
      },
      "source": [
        "train_data = pd.read_csv(path_train)\n",
        "valid_data = pd.read_csv(path_valid)\n",
        "test_data = pd.read_csv(path_test)\n",
        "\n",
        "X_train = train_data[\"Sentence\"].apply(lambda x : clean_doc(x))\n",
        "y_train = train_data[\"Emotion\"]\n",
        "\n",
        "X_val = valid_data[\"Sentence\"].apply(lambda x : clean_doc(x))\n",
        "y_val = valid_data[\"Emotion\"]\n",
        "\n",
        "X_test = test_data[\"Sentence\"].apply(lambda x : clean_doc(x))\n",
        "y_test = test_data[\"Emotion\"]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnYcGTbL0jnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31a9b00-c4c1-47ca-975a-17c3e4787019"
      },
      "source": [
        "print(len(X_train),len(y_train))\n",
        "print(len(X_val),len(y_val))\n",
        "print(len(X_test),len(y_test))\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5548 5548\n",
            "686 686\n",
            "693 693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyPnd4f4qDSJ"
      },
      "source": [
        "## 1.Catalog vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyIQeZi-WdA4"
      },
      "source": [
        "classes = ['Anger','Disgust','Enjoyment','Fear','Other','Sadness','Surprise']\n",
        "def to_category_vector(label):\n",
        "    vector = np.zeros(len(classes)).astype(np.float64)\n",
        "    index = classes.index(label)\n",
        "    vector[index] = 1.0\n",
        "    return vector"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ppniGtjqfhg"
      },
      "source": [
        "## 2.Convert labels to numbers in train and test practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqYyTPmLWdA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5fc40d5-4d5e-4dac-83a3-d1e568bcb121"
      },
      "source": [
        "y_train_encode = []\n",
        "for label in y_train:\n",
        "    y_train_encode.append(to_category_vector(label))\n",
        "\n",
        "\n",
        "y_val_encode = []\n",
        "for label in y_val:\n",
        "    y_val_encode.append(to_category_vector(label))\n",
        "\n",
        "print(classes)\n",
        "print(y_train_encode[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Anger', 'Disgust', 'Enjoyment', 'Fear', 'Other', 'Sadness', 'Surprise']\n",
            "[0. 0. 0. 0. 1. 0. 0.]\n",
            "Other\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK6nyuqOq171"
      },
      "source": [
        "## 3.LSTM\n",
        "\n",
        "\n",
        "*   All the words in the X_train set will form a dictionary\n",
        "*   Each vector of the input word, it will turn into a vector with a fixed number of dimensions and each vocabulary will be replaced by its index in the dictionary\n",
        "* Number of vector dimensions per input we will take the longest sentence which is the direction of the vector and the shorter arcs will automatically add the value 0 after"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EB_NYPlWdBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77422940-84cc-4a33-cdd3-4de598ab5653"
      },
      "source": [
        "xLengths = [len(x.split(' ')) for x in X_train]\n",
        "h = sorted(xLengths)  #sorted lengths\n",
        "maxLength =h[len(h)-1]\n",
        "print(\"The longest sentence length value: \",maxLength)\n",
        "input_tokenizer = Tokenizer(filters=\"\",oov_token=\"UNK\")\n",
        "input_tokenizer.fit_on_texts(X_train)\n",
        "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
        "word_index = input_tokenizer.word_index\n",
        "print(\"input_vocab_size:\",input_vocab_size)\n",
        "X_train_encode = np.array(pad_sequences(input_tokenizer.texts_to_sequences(X_train), maxlen=maxLength,padding=\"post\"))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The longest sentence length value:  134\n",
            "input_vocab_size: 6135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA3sXud4rkcS"
      },
      "source": [
        "## 4.Enter the example using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxIekrnfrfBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43d96a9-47f6-4bac-af57-8ef3dbf7aea2"
      },
      "source": [
        "print(\"Input String : \", X_train[0])\n",
        "print(\"Encode : \",X_train_encode[0])\n",
        "\n",
        "X_val_encode = np.array(pad_sequences(input_tokenizer.texts_to_sequences(X_val), maxlen=maxLength,padding=\"post\"))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input String :  cho mình xin bài nhạc tên là gì với ạ\n",
            "Encode :  [ 13  23 292 166 417 372   4  17  47 182   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzqNhkCQr7gr"
      },
      "source": [
        "## 5.Generate Embedding\n",
        "Function takes the vector of vocabulary in pre-trained word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td-ML6bqWdBE"
      },
      "source": [
        "def generate_embedding(word_index, model_embedding,EMBEDDING_DIM):\n",
        "    count6 = 0\n",
        "    countNot6 = 0\n",
        "    #embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM)) \n",
        "    embedding_matrix = np.asarray([np.random.uniform(-0.01,0.01,EMBEDDING_DIM) for _ in range((len(word_index) + 1))])\n",
        "    list_oov = []\n",
        "    word_is_trained = []\n",
        "    for word, i in word_index.items():\n",
        "        try:\n",
        "            embedding_vector = model_embedding[word]\n",
        "            word_is_trained.append(word)\n",
        "        except:\n",
        "            continue\n",
        "        if embedding_vector is not None:\n",
        "            count6 +=1\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    \n",
        "    print('Number of words in pre-train embedding: ' + str(count6))\n",
        "    print('Number of words not in pre-train embedding: ' + str(countNot6))\n",
        "    return embedding_matrix,word_is_trained"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRIghLqMBuhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a6fcead-4649-45f9-b7ef-4ac5e3b1fe84"
      },
      "source": [
        "embedding_matrix,word_is_trained = generate_embedding(word_index,word_embedding,EMBEDDING_DIM)\n",
        "print(word_is_trained)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in pre-train embedding: 5647\n",
            "Number of words not in pre-train embedding: 0\n",
            "['không', 'tao', 'là', 'có', 'mà', 'này', 'nó', 'đi', 'thì', 'rồi', 'cái', 'cho', 'per', 'được', 'cũng', 'gì', 'con', 'quá', 'người', 'lại', 'như', 'mình', 'làm', 'còn', 'của', 'mày', 'ra', 'thấy', 'phải', 'mấy', 'vãi', 'thôi', 'em', 'nào', 'và', 'đó', 'anh', 'để', 'luôn', 'đã', 'thế', 'chứ', 'nhìn', 'đéo', 'hay', 'với', 'bạn', 'biết', 'bị', 'sao', 'nhưng', 'cả', 'thằng', 'chỉ', 'thật', 'đâu', 'xem', 'ai', 'mới', 'nhà', 'nữa', 'vậy', 'khi', 'mẹ', 'nói', 'vào', 'lắm', 'ăn', 'lên', 'sợ', 'về', 'vẫn', 'đến', 'một', 'chưa', 'nhiều', 'lần', 'hết', 'ở', 'hơn', 'yêu', 'năm', 'sẽ', 'ngày', 'tôi', 'muốn', 'đấy', 'nên', 'các', 'xong', 'phim', 'trong', 'cười', 'đây', 'những', 'vì', 'cứ', 'đúng', 'đứa', 'nhỉ', 'ông', 'thích', 'giờ', 'lúc', 'mặt', 'nhau', 'ấy', 'nhớ', 'à', 'tiền', 'đáng', 'nhất', 'chắc', 'gặp', 'đang', 'nhé', 'từ', 'học', 'bọn', 'mất', 'đừng', 'nghe', 'chó', 'chết', 'rất', 'khác', 'bố', 'buồn', 'sau', 'bà', 'v', 'cần', 'đẹp', 'kiểu', 'trước', 'vừa', 'bé', 'xe', 'mua', 'toàn', 'ngu', 'qua', 'đầu', 'nghĩ', 'chạy', 'tới', 'lấy', 'vợ', 'chả', 'mỗi', 'chơi', 'coi', 'hồi', 'đời', 'hiểu', 'người_yêu', 'đường', 'tốt', 'bao_giờ', 'nhỏ', 'lol', 'họ', 'bài', 'ngồi', 'giống', 'thứ', 't', 'vui', 'bỏ', 'chị', 'kia', 'nay', 'lũ', 'đọc', 'nè', 'gái', 'cô', 'bán', 'ạ', 'ơi', 'video', 'trời', 'lớp', 'hỏi', 'bắt', 'khóc', 'nuôi', 'ghê', 'tin', 'nếu', 'má', 'bằng', 'chửi', 'ta', 'bảo', 'có_thể', 'sai', 'tay', 'mọi', 'chuyện', 'đỗ', 'sống', 'quay', 'huhu', 'cơm', 'haha', 'thương', 'câu', 'tội', 'từng', 'đau', 'trên', 'lòng', 'ngay', 'cưng', 'bộ', 'gọi', 'dễ_thương', 'nấu', 'nha', 'nước', 'theo', 'xuống', 'thêm', 'thế_nào', 'chỗ', 'con_trai', 'bác', 'bên', 'hạnh_phúc', 'cùng', 'tình_yêu', 'phát', 'lớn', 'cây', 'con_gái', 'đánh', 'nam', 'mong', 'phạt', 'con_mẹ', 'hôm', 'ngủ', 'tưởng', 'đồ', 'quan_trọng', 'mắt', 'đm', 'ngày_xưa', 'dí', 'nói_chuyện', 'chúng_mày', 'ý', 'cắt', 'cao', 'quả', 'c', 'tiếng', 'chân', 'ba', 'thời', 'chán', 'việc', 'câu_chuyện', 'chẳng', 'ngáo', 'bây_giờ', 'tụi', 'cuối', 'cách', 'giận', 'hả', 'chúng_nó', 'đoạn', 'tháng', 'sự', 'việt', 'nhanh', 'như_vậy', 'đủ', 'tóc', 'dám', 'trai', 'nhận', 'nổi', 'lâu', 'phòng', 'xin', 'trẻ', 'mèo', 'mưa', 'xinh', 'gần', 'ngoài', 'cụ', 'ngỗng', 'ghét', 'càng', 'vô', 'k', 'crush', 'não', 'nhện', 'đồng_nghiệp', 'bếp', 'bình_luận', 'chụp', 'chồng', 'giết', 'dân', 'loại', 'gia_đình', 'hãy', 'điều', 'ma', 'mệt', 'tự', 'vài', 'ý_thức', 'ngon', 'khó', 'kết', 'chuẩn', 'đều', 'thiệt', 'tuổi', 'chịu', 'tr', 'viết', 'tính', 'khổ', 'bao_nhiêu', 'n', 'tuổi_thơ', 'chi', 'già', 'dọn', 'hai', 'xấu', 'cuộc_sống', 'ôi', 'chủ', 'kêu', 'đứng', 'thi', 'mồm', 'hàng', 'dù', 'cảm_giác', 'á', 'xem_lại', 'tìm', 'dùng', 'thế_là', 'to', 'chúng_ta', 'thế_giới', 'ảnh', 'tình', 'nhảy', 'mắc', 'tất_cả', 'tiếc', 'trông', 'nơi', 'mai', 'hơi', 'tên', 'quen', 'bánh', 'điên', 'ý_nghĩa', 'kkk', 'sấp_mặt', 'đưa', 'sớm', 'cắn', 'quan_tâm', 'mãi', 'thành', 'không_thể', 'kể', 'đăng', 'dễ', 'tí', 'giọng', 'cảm_thấy', 'vàng', 'đỡ', 'thề', 'hãm', 'quên', 'tù', 'giỏi', 'dậy', 'tập', 'mất_dạy', 'quần', 'nguy_hiểm', 'nỗi', 'lo', 'thịt', 'ông_bà', 'chính', 'mang', 'con_người', 'may', 'sang', 'đổ', 'chúc', 'trả', 'chia_tay', 'nhạc', 'công_nhận', 'chọn', 'đẹp_trai', 'đem', 'cơ', 'cảm_ơn', 'lông', 'nằm', 'xa', 'đuổi', 'đàn_ông', 'điện', 'tim', 'cảnh', 'móng', 'bình_thường', 'ỉa', 'trường', 'ám_ảnh', 'cuộc_đời', 'cháu', 'dài', 'ước', 'lun', 'khỏi', 'quán', 'cấp', 'tại', 'chú', 'tại_sao', 'sáng', 'dạy', 'bữa', 'buồn_cười', 'y', 'cậu', 'mặc', 'bẩn', 'dưới', 'chút', 'do', 'nước_mắt', 'bản_thân', 'lời', 'hiền', 'suốt', 'đập', 'bố_mẹ', 'nhờ', 'vị', 'đau_lòng', 'chờ', 'la', 'cầm', 'xã_hội', 'thử', 'đợi', 'sau_này', 'đùa', 'rớt', 'cha', 'làm_sao', 'phí', 'điện_thoại', 'tối', 'quỳ', 'uống', 'cầu', 'kìa', 'đôi', 'trâu', 'cuối_cùng', 'ủa', 'ko', 'dầu', 'ảo_tưởng', 'lỡ', 'cấm', 'bệnh', 'ít', 'chị_em', 'ác', 'diễn', 'xưa', 'vậy_mà', 'đen', 'đá', 'thanh_niên', 'ngang', 'hàng_xóm', 'chất', 'vụ', 'thớt', 'hôm_nay', 'trung_thu', 'dm', 'khá', 'đốt', 'tàu', 'thời_gian', 'trừ', 'triệu', 'đóng', 'hẳn', 'thật_sự', 'thả', 'rơi', 'phê', 'tai', 'chung', 'lợn', 'hình_như', 'gym', 'bao', 'sinh', 'bay', 'thiếu', 'bất_hạnh', 'bây', 'giúp', 'kiếm', 'cố', 'cực', 'ôm', 'niềm', 'tuần', 'ah', 'quyền', 'tuyệt_vời', 'công', 'học_sinh', 'hát', 'ế', 'ổng', 'đất_nước', 'giữ', 'cưới', 'vẽ', 'ngắn', 'áo', 'đất', 'sắp', 'thua', 'chục', 'chữ', 'hoặc', 'thân', 'điểm', 'ơ', 'đòi', 'thay', 'béo', 'ngọt', 'tâm', 'đêm', 'đầy', 'boss', 'gà', 'chủ_tịch', 'té', 'khốn_nạn', 'kiếp', 'hihi', 'tớ', 'hành_động', 'đặt', 'bàn', 'đậu', 'đông', 'hình', 'chiều', 'nhá', 'gấu', 'cạnh', 'kinh', 'xin_lỗi', 'tầm', 'thèm', 'vui_vẻ', 'óc', 'cơ_mà', 'mạnh', 'sông', 'làm_việc', 'i', 'tạo', 'trăm', 'thấp', 'cứng', 'nghề', 'đẻ', 'yêu_thương', 'nhắn_tin', 'khách', 'trượt', 'cổ', 'giả', 'độ', 'rút', 'nóng', 'nhẹ', 'đơn_giản', 'tết', 'quê', 'chia', 'may_mắn', 'gửi', 'lương', 'phết', 'tài', 'cha_mẹ', 'tây', 'sữa', 'tán', 'giàu', 'thu', 'tỏ', 'cay', 'nhạt', 'tặng', 'liền', 'tuy', 'yên', 'hoa', 'răng', 'nữ', 'nghỉ', 'khúc', 'hài', 'kiến', 'giá', 'rượt', 'gây', 'lạ', 'bớt', 'cháy', 'kém', 'biển', 'dăm_ba', 'ngã', 'số', 'ngành', 'thầy', 'admin', 'bồ', 'định', 'dừng', 'nguyên', 'cố_gắng', 'tỉnh', 'mụ', 'cẩn_thận', 'đầu_tiên', 'mở', 'lúc_nào', 'giáo_dục', 'kinh_dị', 'bước', 'cô_đơn', 'dạo', 'bình', 'trái', 'bò', 'anh_em', 'tự_nhiên', 'giữa', 'lỗi', 'xử', 'tương_lai', 'trách', 'vỡ', 'tức', 'cứt', '_', 'nhắn', 'co', 'cơ_hội', 'họp', 'hôn', 'màu', 'ư', 'nắng', 'hại', 'thảo', 'mông', 'trò', 'dữ', 'liên_quan', 'vả', 'rác', 'thế_mà', 'hoài', 'sừng', 'thanh_xuân', 'lừa_đảo', 'súc_vật', 'sạch', 'lò', 'z', 'nhìu', 'nội', 'mạng', 'xàm', 'mùa', 'kết_hôn', 'bụng', 'xài', 'tụt', 'mát', 'công_an', 'bắn', 'trêu', 'báo', 'tha', 'cute', 'thể_loại', 'bất_ngờ', 'bắt_đầu', 'đỉnh', 'nghiệp', 'dành', 'quay_phim', 'gớm', 'kệ', 'chọc', 'giảm', 'chắc_chắn', 'pháp', 'cặp', 'ho', 'xác_định', 'đền', 's', 'chế', 'miệng', 'kem', 'ngoại', 'ghi', 'luật', 'chàng', 'buổi', 'suy_nghĩ', 'mối', 'kaka', 'phá', 'màn_hình', 'người_lớn', 'hic', 'váy', 'cuộc', 'cục', 'cô_giáo', 'phường', 'dân_trí', 'bắc', 'cảm_xúc', 'trà', 'kinh_nghiệm', 'nhầm', 'thế_thì', 'm', 'mũ', 'tận', 'í', 'chim', 'trốn', 'hỏng', 'đống', 'mức', 'vẻ', 'phần', 'so', 'sân', 'rắn', 'mổ', 'động_lực', 'việt_nam', 'nv', 'cổ_tích', 'chớ', 'phụ_huynh', 'nghiệt', 'xạo', 'đĩ', 'hòa', 'kéo', 'nặng', 'ghép', 'cu', 'p', 'sướng', 'bác_sĩ', 'haizz', 'riêng', 'mọc', 'nghèo', 'mê', 'kịp', 'tỏ_tình', 'thật_ra', 'đồng', 'ha', 'vứt', 'game', 'miếng', 'mừng', 'ô', 'khôn', 'thần_kinh', 'vỉa_hè', 'rõ', 'hix', 'no', 'giải_quyết', 'ca', 'tốt_đẹp', 'nói_chung', 'có_lẽ', 'khổ_thân', 'nghi', 'mặn', 'xô', 'đụ', 'lao_động', 'tag', 'nhổ', 'nhẹ_nhàng', 'tởm', 'bả', 'nợ', 'thường', 'quảng_cáo', 'thú_vị', 'viện', 'hi_vọng', 'hú_hồn', 'thâm', 'đái', 'khiếp', 'nhể', 'cảm_động', 'chê', 'nà', 'tổn_thương', 'chúc_mừng', 'giật_mình', 'ai_ngờ', 'auto', 'd', 'phục_vụ', 'tệ', 'tránh', 'mơ', 'sếp', 'ly', 'tát', 'ngầu', 'nồi', 'rộng', 'bắt_nạt', 'lười', 'tấm', 'tuổi_trẻ', 'hết_hồn', 'ấm', 'h', 'mùi', 'đấm', 'tiếp', 'heo', 'b', 'đội', 'lái', 'thông_minh', 'sinh_nhật', 'ban', 'thay_đổi', 'kẻ', 'tồn_tại', 'ấn', 'da', 'chua', 'thể', 'xây', 'cửa', 'năm_ngoái', 'quyết_định', 'cục_súc', 'ổn', 'quỷ', 'u', 'vấn_đề', 'cá_nhân', 'cửa_nhà', 'áp_lực', 'tỷ', 'canh', 'bảo_vệ', 'fan', 'vkl', 'dỗ', 'rạp', 'phút', 'lỗ', 'cứu', 'thành_công', 'hút', 'xuất_hiện', 'đám', 'chuẩn_bị', 'a', 'áp_dụng', 'tắt', 'xả', 'lưng', 'ngôn', 'nhà_nước', 'đít', 'cân', 'gậy', 'ham', 'nước_ngoài', 'vl', 'ước_mơ', 'mập', 'con_cháu', 'trở_nên', 'dcm', 'đối_với', 'ảnh_hưởng', 'vâng', 'vn', 'lửa', 'rằng', 'mãi_mãi', 'nuốt', 'giải_trí', 'chời', 'nhắc', 'tuyệt', 'lão', 'đại_học', 'khó_khăn', 'o', 'đắng', 'đạp', 'múi', 'thính', 'như_vầy', 'sờ', 'thuộc', 'hôm_qua', 'vớ_vẩn', 'bởi', 'giấy', 'mi', 'đằng', 'rụng', 'món', 'động', 'hài_hước', 'chúng_tôi', 'đồng_tiền', 'thất_tình', 'phẫn_nộ', 'minh', 'củ', 'phụ_nữ', 'xảy', 'oto', 'chiếc', 'thải', 'cao_su', 'nướng', 'hahaha', 'thực_tế', 'hộp', 'quà', 'tử_hình', 'tình_cảm', 'mất_công', 'vô_duyên', 'bông', 'hy_vọng', 'cãi', 'đa', 'trung', 'xếp', 'karaoke', 'chấp_nhận', 'chuột', 'huyền_thoại', 'trẻ_con', 'tỉ', 'xác', 'hình_ảnh', 'bướng', 'hành_tinh', 'giá_trị', 'rủ', 'cắm', 'lùn', 'cờ', 'hấp_dẫn', 'si', 'xíu', 'cức', 'lạc', 'chợ', 'giày', 'pháp_luật', 'tăng', 'văn', 'mặc_dù', 'rõ_ràng', 'dã_man', 'lầy', 'chấm', 'đại', 'bóng', 'page', 'dẹp', 'máy', 'chăm_sóc', 'góc', 'bể', 'hóng', 'cua', 'nhân_tính', 'dính', 'hội', 'gió', 'bỏ_mẹ', 'gấp', 'thiên_hạ', 'tè', 'ngưỡng_mộ', 'đàn_bà', 'zai', 'sóng', 'làng', 'dòng', 'giật', 'ngắm', 'lịch_sự', 'hư', 'chép', 'dỗi', 'facebook', 'lừa', 'kính', 'hành', 'ly_hôn', 'tham', 'quá_khứ', 'giả_vờ', 'mệt_mỏi', 'đến_nỗi', 'đôi_khi', 'tn', 'cột', 'thuê', 'em_gái', 'chúng', 'khoảng', 'đĩa', 'riết', 'khiến', 'dẫn', 'khả_năng', 'tốn', 'duyên', 'ruột', 'ml', 'kk', 'cơn', 'chăm', 'ga', 'truyện', 'ừ', 'này_nọ', 'sửa', 'chống', 'nhục', 'khoe', 'quét', 'yêu_đương', 'trách_nhiệm', 'thoải_mái', 'sáng_tạo', 'thu_nhập', 'va', 'sơn', 'công_nhân', 'thể_hiện', 'thánh', 'cam', 'ngược_lại', 'tự_dưng', 'diễn_viên', 'trứng', 'bạn_bè', 'lựa_chọn', 'độc', 'chuyển', 'fa', 'phú', 'trưa', 'lúa', 'mỏi', 'đạo_đức', 'hét', 'tóm', 'nhột', 'đau_khổ', 'trời_ơi', 'hết_sức', 'khiển_trách', 'máu', 'nta', 'thân_thiết', 'tý', 'hiệu_quả', 'xỉu', 'đỉ', 'lòi', 'bàn_tay', 'rửa', 'củi', 'rơm', 'ờ', 'chảy', 'đâm', 'vệ_sinh', 'khuyên', 'đàng_hoàng', 'xương', 'bốc', 'trúng', 'trộm', 'e', 'cỏ', 'mạnh_mẽ', 'xốp', 'dơ', 'sinh_viên', 'kinh_khủng', 'hè', 'muối', 'pha', 'công_việc', 'nhân', 'liên_tục', 'phốt', 'cán_bộ', 'na', 'gia', 'nét', 'thần_tài', 'ô_tô', 'vải', 'sắc', 'thức', 'dái', 'lai', 'hằng', 'ức_chế', 'tài_năng', 'xe_đạp', 'bày_đặt', 'nụ', 'mẫu_giáo', 'dắt', 'tổ_chức', 'hợp', 'bầy', 'rùi', 'thời_điểm', 'thất_bại', 'thê', 'dạng', 'xiên', 'hóa', 'caphe', 'mời', 'mềnh', 'mê_tín', 'an_toàn', 'tưởng_tượng', 'sắt', 'hộ', 'giáo_viên', 'mõm', 'tém', 'kiểm_tra', 'văn_hoá', 'hoàn_cảnh', 'lâu_lâu', 'vô_tình', 'hà', 'tu', 'x', 'nghĩ_lại', 'đề', 'tận_cùng', 'bệnh_viện', 'cạo', 'thui', 'mắng', 'ói', 'wow', 'hehe', 'trung_nguyên', 'đam_mê', 'lao', 'chia_sẻ', 'duy_nhất', 'trân_trọng', 'tự_hào', 'nát', 'cạp', 'say', 'lãng_mạn', 'bênh', 'ráng', 'công_khai', 'dạ', 'thú_vui', 'ui', 'lái_xe', 'kết_thúc', 'rảnh', 'đoán', 'ngày_tháng', 'vầy', 'lí_do', 'đòn', 'tui', 'bi', 'ý_kiến', 'share', 'môi_trường', 'dễ_dàng', 'ha_ha', 'dô', 'hí', 'đeo', 'gọn', 'nhật', 'biết_bao', 'khác_nào', 'tro', 'cẩu', 'nhai', 'nge', 'trèo', 'khuôn_mặt', 'chùa', 'vong', 'ngứa_mắt', 'bơi', 'đức', 'nhây', 'sử', 'giao_thông', 'hahaa', 'bát', 'chất_lượng', 'chợt', 'người_ngoài', 'bất_cứ', 'thiết_kế', 'nọ', 'ăn_nói', 'láo', 'chân_thành', 'ngoan', 'làm_ăn', 'phụ', 'né', 'ném', 'xử_lý', 'quanh', 'súc_sinh', 'như_thế', 'thoát', 'tắc', 'võng', 'chứng_minh', 'thành_phần', 'mún', 'gù', 'thực_ra', 'thanh', 'khó_chịu', 'ý_định', 'tiêu', 'dai', 'hiện_tại', 'nửa', 'công_ty', 'chưởng', 'ng', 'sức', 'phun', 'tài_sản', 'lẫn', 'danh', 'khoảnh_khắc', 'dth', 'phân_biệt', 'chang', 'gục', 'gato', 'lợi_dụng', 'bản_lĩnh', 'thay_vì', 'u_ám', 'thối', 'táp', 'khoái', 'hường', 'đặc_biệt', 'con_cái', 'gai_ốc', 'lòn', 'nhậu', 'nốt', 'soi', 've', 'gương', 'gê', 'hồ', 'nguồn', 'án', 'vi', 'lau', 'trồng', 'mượn', 'cú', 'ngại', 'chủ_nhiệm', 'vàng_trắng', 'buông', 'dây', 'dập', 'dâu', 'bo', 'cút', 'kinh_doanh', 'êu', 'nặn', 'add', 'ak', 'hề', 'có_hậu', 'liệu', 'võ', 'hợp_lí', 'miền', 'đảm_bảo', 'tôn_trọng', 'kể_cả', 'nghìn', 'mau', 'best', 'cưa', 'hốt', 'phá_hoại', 'vô_tâm', 'roi', 'bạo_lực', 'què', 'mái', 'một_số', 'xứng_đáng', 'da_gà', 'tan', 'kế', 'xanh', 'hay_là', 'việc_làm', 'đàn', 'đứt', 'bật', 'con_nít', 'hay_ho', 'bó_tay', 'du_lịch', 'trường_hợp', 'bờ', 'tiếp_tục', 'vũ', 'thế_hệ', 'lượt', 'lý_do', 'cũg', 'yên_tâm', 'nhân_viên', 'chúa', 'nhịn', 'ứa', 'lờ', 'dại', 'bá', 'phán', 'nguyên_nhân', 'vẩy', 'múa', 'nhà_thờ', 'bẻ', 'thẳng', 'chào', 'hà_nội', 'vv', 'ấm_áp', 'ghế', 'muộn', 'lưu_luyến', 'hứa', 'biết_mấy', 'ngựa', 'trôi', 'anh_chị', 'móc', 'giới_tính', 'rời', 'kết_quả', 'ngó', 'ăn_trộm', 'kỷ_niệm', 'hói', 'trận', 'sút', 'ch', 'thời_buổi', 'lướt', 'tổ', 'vở', 'xung_quanh', 'bồi_thường', 'vắt', 'hành_nghề', 'đú', 'mặt_mày', 'cà_phê', 'vui_tính', 'khỏe', 'nền', 'cta', 'man', 'nghiêm_túc', 'gặm', 'ngắt', 'bảo_hiểm', 'loài', 'dịch_vụ', 'thái_độ', 'trailer', 'trọn', 'tan_nát', 'nyc', 'tả', 'mợ', 'haiz', 'khùng', 'trái_tim', 'đạt', 'củng', 'giải', 'khen', 'hứng', 'hên', 'yến', 'tài_xế', 'rẻ', 'rách', 'than', 'nhốt', 'khủng_khiếp', 'lực', 'tinh_thần', 'mỏ', 'im', 'quan_hệ', 'thần', 'trẻ_em', 'hạt', 'gánh', 'gãy', 'pr', 'lựa', 'chăn', 'ê', 'vịt', 'bức', 'hàm', 'cá_tính', 'trở_lại', 'ướt', 'trước_kia', 'ngọc', 'đỏ', 'tạm_biệt', 'chiếu_phim', 'gan', 'nể', 'bỏ_tù', 'bình_tĩnh', 'bực', 'cầu_hôn', 'hahahaha', 'lậy', 'cậy', 'nghệ_thuật', 'ngược', 'kha', 'buôn', 'đu', 'súc', 'vợ_chồng', 'tội_nghiệp', 'lầm', 'trải', 'đầu_tư', 'mảnh', 'mải', 'thực_phẩm', 'mầm_non', 'độc_ác', 'lợi_ích', 'top', 'nh', 'bà_già', 'quyết_tâm', 'cám_ơn', 'đào', 'sốc', 'lìn', 'đố', 'ngày_mai', 'nỡ', 'đực', 'tế', 'cái_trò', 'quần_áo', 'nghỉ_việc', 'đổi', 'cư_xử', 'giao', 'chuồng', 'chổi', 'quơ', 'dán', 'bịa', 'gắp', 'biến', 'leo', 'nón', 'chỉnh', 'đè', 'cải', 'đạo', 'đù', 'địt', 'phép', 'dở', 'đường_ray', 'cố_tình', 'che', 'lào', 'lead', 'bày', 'mă', 'sai_lầm', 'trắng_tay', 'cafe', 'thuốc', 'tuyển', 'vại', 'thuế', 'vietcombank', 'dư', 'thói', 'đáy', 'dt', 'cổng', 'giá_như', 'núi', 'dịch', 'tươi', 'lộn_ruột', 'giun', 'bút', 'băng', 'mai_mốt', 'tự_ái', 'trầm_cảm', 'quăng', 'hoàn_toàn', 'sự_việc', 'cảnh_cáo', 'xe_máy', 'ơn', 'đói', 'chính_xác', 'an_ủi', 'đếu', 'lá', 'aeon', 'tồi', 'ninja', 'thốn', 'nhân_văn', 'xoài', 'vác', 'dao', 'người_nhà', 'gu', 'tìm_hiểu', 'hạ', 'sức_khoẻ', 'bình_yên', 'đg', 'khung', 'phố', 'bãi', 'điểm_danh', 'ý_tưởng', 'oan', 'ngực', 'ngọt_ngào', 'thần_thái', 'khách_hàng', 'tắm', 'ảo', 'chừa', 'tật', 'trở', 'thơm', 'vật', 'nắm', 'đề_nghị', 'nội_dung', 'xịt', 'trở_thành', 'siêu', 'sót', 'cá', 'bất_chấp', 'dâm', 'cướp', 'thà', 'chạnh_lòng', 'mồ_hôi', 'khói', 'giường', 'bóng_đá', 'kỷ_nguyên', 'ngươ', 'mất_nết', 'thợ', 'tài_liệu', 'mặt_nạ', 'xui', 'bựa', 'lắp', 'buồi', 'chuyến', 'nghiện', 'chặt', 'biết_bao_nhiêu', 'một_mình', 'dựng', 'chảnh', 'dè', 'quả_báo', 'một_chút', 'chai', 'để_ý', 'cảm', 'tội_lỗi', 'văn_hóa', 'le', 'xây_dựng', 'kinh_tế', 'phẩm', 'bị_thịt', 'hồng', 'sử_dụng', 'bã', 'trái_đất', 'thiệc', 'kiện', 'thực_sự', 'nàng', 'nhất_định', 'kì_thị', 'vườn', 'đối_tượng', 'điều_kiện', 'thất_vọng', 'túi', 'dị', 'tờ', 'mút', 'lêu', 'chuối', 'chớp', 'cánh', 'chẹp', 'khốn', 'bóc', 'suýt', 'trog', 'cơ_quan_chức_năng', 'hiện', 'kĩ', 'link', 'chủ_yếu', 'dã', 'hén', 'dự_án', 'gióng', 'ad', 'ốm', 'lẹ', 'văn_minh', 'tạt', 'tàn', 'trụ', 'mở_cửa', 'mép', 'hít', 'tiên', 'lên_án', 'hoà', 'dép', 'ngây_thơ', 'dẻo', 'tham_lam', 'kiên_trì', 'ké', 'chứng', 'già_mồm', 'chay', 'g', 'em_trai', 'đồng_cảm', 'đào_tạo', 'căng', 'tướng', 'ga_lăng', 'hỡi', 'xem_thường', 'chả_bù', 'kiến_vàng', 'cứt_trâu', 'ok', 'trò_đùa', 'xưng', 'bóp', 'dần', 'tư_tưởng', 'học_bổng', 'q', 'sủa', 'hú', 'vỏ', 'dụ', 'lễ', 'kiến_đen', 'đắp', 'thang_máy', 'dồi', 'bầm', 'ngân', 'đợt', 'vcb', 'tiết', 'đối_xử', 'chủ_động', 'time', 'chiến_đấu', 'gạo', 'áo_mưa', 'đươ', 'chư', 'ghé', 'phọt', 'cốc', 'sạch_sẽ', 'thắng', 'xúc', 'không_thể_nào', 'hiên_ngang', 'khỉ', 'bầu', 'phèo', 'anh_chị_em', 'he', 'online', 'lợi_nhuận', 'chốt', 'phơi', 'thụt', 'đọ', 'lứa', 'vòng', 'phía', 'tô', 'nua', 'khoá', 'trong_sạch', 'ship', 'y_tế', 'sức_khỏe', 'thư', 'tiền_bạc', 'thái', 'sàn', 'ngu_ngốc', 'vô_dụng', 'ong', 'ổn_định', 'phi', 'cung_cấp', 'ranh_con', 'giời', 'tiên_sư', 'đau_đớn', 'coi_thường', 'đô', 'viê', 'ti', 'tra', 'nhiê', 'sống_chết', 'th', 'nhát', 'thắc_mắc', 'tư', 'rứa', 'làm_giàu', 'tiệm', 'thời_trang', 'tự_trọng', 'rẻ_mạt', 'ngồi_tù', 'đáp', 'kẹo', 'ngõ', 'rọ_mõm', 'thân_hình', 'đóng_cửa', 'loạn', 'quái', 'xuất', 'lãnh_đạo', 'lở', 'trồi', 'mù', 'cmm', 'học_hành', 'hoàn_hảo', 'thượng', 'thg', 'ích_kỉ', 'trọn_vẹn', 'tường', 'rổ', 'mặt_dày', 'cũ', 'bia', 'lý', 'xử_phạt', 'lãi', 'ngưng', 'hưởng', 'tháo', 'gầy', 'phù_hợp', 'bởi_vậy', 'theo_dõi', 'sức_mạnh', 'lớn_tuổi', 'có_học', 'dốt', 'lí', 'vẫy', 'lọt', 'biến_thái', 'vô_cùng', 'thẻ', 'ự', 'thèn', 'du', 'lấp', 'phận', 'sung_sướng', 'chính_sách', 'bậy', 'giận_dỗi', 'mạnh_khỏe', 'rung_động', 'vặt', 'cà', 'phát_triển', 'sài', 'hành_hạ', 'tợp', 'loài_người', 'truyền_hình', 'doi', 'cong', 'đơn_phương', 'gắn_bó', 'dần_dần', 'én', 'ngu_dốt', 'tiền_mặt', 'đèn', 'đắt', 'rep', 'đĩa_bay', 'ngứa', 'thiếu_nhi', 'mềm', 'thổi', 'khét', 'hoàng', 'tâm_lý', 'xe_ôm', 'làm_công', 'ngày_nay', 'sg', 'cuồng', 'chém', 'ngốc', 'ngán', 'giây', 'sư', 'me', 'cản', 'hot', 'tôm', 'người_thương', 'hình_sự', 'dị_đoan', 'trật_tự', 'xh', 'sập', 'ghen', 'bùi', 'linh_tinh', 'bự', 'cmt', 'xe_hơi', 'ctay', 'quá_đáng', 'khóc_lóc', 'tranh', 'nhăn', 'loa', 'đẩy', 'cụt', 'sâu', 'giải_thích', 'ắt', 'vương', 'ăn_uống', 'mốc', 'biết_đâu', 'thiện', 'lành', 'nick', 'nghịch', 'răng_khôn', 'gián', 'quan', 'chặn', 'sáng_mai', 'bấm', 'dội', 'cá_sấu', 'cuốn', 'tranh_luận', 'nhưg', 'khoẻ', 'thang', 'bám', 'gọn_gàng', 'trầm_trồ', 'châu', 'hót', 'hứng_thú', 'đồng_đội', 'vay', 'post', 'thai', 'day', 'mạng_nhện', 'kín', 'vid', 'trại', 'ấn_tượng', 'team', 'tồi_tệ', 'tào_lao', 'nguyện', 'chú_ý', 'vật_chất', 'trước_mắt', 'nộp', 'đồn', 'cáo', 'chiếu', 'trưởng_thành', 'xách', 'ăn_ở', 'oy', 'ruồi', 'sởn', 'nhập', 'đẳng_cấp', 'hẹn', 'eo', 'thỏ', 'lui', 'gào', 'men', 'tủ', 'nhiệm_vụ', 'dị_ứng', 'quận', 'rẽ', 'cai', 'chổ', 'hờ', 'trả_lời', 'rải', 'đinh', 'lập', 'thấm', 'mật', 'liên_tưởng', 'vũ_trụ', 'dự', 'tông', 'nhàm', 'hồn', 'tiếp_theo', 'quý', 'cực_khổ', 'bô', 'trump', 'thăm', 'thây', 'lịch_sử', 'nguyễn', 'tàn_nhẫn', 'khâm_phục', 'nhg', 'lạy', 'nho', 'lưu', 'hoá', 'chờ_đợi', 'hiền_lành', 'ngửi', 'nhét', 'hoá_ra', 'làm_khó', 'hàng_loạt', 'rể', 'nổi_tiếng', 'tà', 'sáng_suốt', 'cáu', 'hư_hỏng', 'nóc', 'làm_trò', 'thành_phố', 'máu_me', 'sự_thật', 'ngàn', 'mong_manh', 'như_chơi', 'edit', 'luôn_luôn', 'trời_đánh', 'mang_tiếng', 'csgt', 'nhặt', 'lòng_đường', 'thô', 'moi', 'tinh_tế', 'phóng_điện', 'ích_kỷ', 'chịu_khó', 'hiệu_trưởng', 'hèn', 'um', 'đầm', 'nông_dân', 'lùi', 'nao', 'quãng', 'kịch_bản', 'chùm', 'xi_nhan', 'sẻ', 'nhóc', 'gay', 'kỉ_lục', 'chiêu', 'thú', 'tánh', 'chóng_mặt', 'cap', 'tiệc', 'mũi', 'xăng', 'gáy', 'tan_vỡ', 'main', 'linh_hồn', 'nhiệt_tình', 'mò', 'cát', 'ồ', 'hì', 'sn', 'khép', 'đểu', 'thét', 'mắm_tôm', 'ổ', 'ngộ', 'hậu', 'pin', 'tuột', 'vì_sao', 'mà_lại', 'nhặng', 'tầng', 'háng', 'bón', 'vụn', 'vai', 'sách', 'láo_toét', 'lôi', 'học_sinh_học', 'tấn_công', 'gắt', 'nắng_nóng', 'ne', 'nhảm_nhí', 'há', 'ầm', 'vĩ_đại', 'mí', 'sgk', 'toa', 'tích_sự', 'haizzz', 'ô_uế', 'cạn_lời', 'tiêu_diệt', 'dù_sao', 'vã', 'vốn', 'mẫu', 'mỳ', 'trí_tuệ', 'gáo', 'truyền', 'đắng_cay', 'bàn_tay_trắng', 'hát_hò', 'thùng', 'trụi', 'dẽ', 'bố_láo', 'níu', 'biết_điều', 'tong', 'mấy_đời', 'tre', 'chóp_chép', 'xa_hoa', 'nhỏ_bé', 'đành', 'tất_nhiên', 'xinh_xinh', 'mai_sau', 'tin_tưởng', 'sứng', 'qua_đời', 'quang', 'tiền_kiếp', 'vé', 'ẻ', 'coi_bộ', 'max', 'làm_thuê', 'nhà_quê', 'túm', 'vời', 'một_cách', 'bóng_dáng', 'cho_nên', 'vẩn', 'mạnh_tay', 'nhất_là', 'mỉm', 'tiêu_đề', 'đi_đứng', 'dọc', 'or', 'bổ', 'đâm_đầu_vào', 'ngàn_thu', 'đàn_hồi', 'đánh_rơi', 'xa_vời', 'trộm_cắp', 'trào', 'thận', 'xoá', 'mỹ', 'xxx', 'hài_lòng', 'mơ_mộng', 'quẹo', 'ai_đời', 'tính_chuyện', 'lâu_dài', 'tiễn', 'đổ_vỡ', 'đùi', 'tím', 'giơ', 'năm_học', 'ngấm', 'đấu', 'hàg', 'hồi_hộp', 'trùn', 'giun_đất', 'tét', 'ướp', 'trôi_sông', 'sản_phẩm', 'mới_lạ', 'kẻo', 'thúi', 'đanh', 'ngất', 'định_mệnh', 'hãi', 'trầu', 'y_như_rằng', 'mát_lòng', 'vờ', 'rờ', 'dâm_ô', 'gẫy', 'hiệp', 'tỉnh_táo', 'bao_cấp', 'agribank', 'phong', 'phì', 'đi_đêm', 'tủi', 'thầm', 'rừng', 'nì', 'khựa', 'bè_phái', 'gật', 'lắm_chuyện', 'bánh_chưng', 'tung', 'thở', 'gã', 'đón_nhận', 'giông_bão', 'combo', 'phe', 'shipper', 'thù', 'phù_du', 'ưng', 'bể_dâu', 'lót', 'bửa', 'làm_tới', 'nở', 'bít', 'xa_lạ', 'gieo', 'gặt', 'chung_thân', 'nghiệp_chướng', 'thức_ăn', 'úi', 'người_dưng', 'rớ', 'mong_muốn', 'thâ', 'nhâ', 'đương_nhiên', 'se', 'nê', 'nhân_cách', 'lẳng_lơ', 'mật_ong', 'trời_đất', 'bệnh_hoạn', 'mẻ', 'chôn', 'rảnh_rỗi', 'cũng_nên', 'mì', 'mần', 'mãn_nguyện', 'không_khí', 'nhằm', 'ngày_sinh_nhật', 'bịch', 'ai_bảo', 'ốm_nhom', 'cở', 'cởi', 'lắc_đầu', 'ngta', 'thách_thức', 'kỉ', 'bôi', 'che_chở', 'sấm', 'âm', 'hãng', 'quảng', 'shop', 'bao_xa', 'híc', 'xoắn', 'nhà_bếp', 'rùng', 'lồng', 'nhảm', 'cửa_hàng', 'wc', 'sánh_vai', 'bỗng_nhiên', 'la_hét', 'mất_mặt', 'bún', 'viên', 'tham_gia', 'cưỡng_hôn', 'dùm', 'ngữ_văn', 'độg', 'lùa', 'súng', 'ván', 'tàu_hoả', 'va_chạm', 'bth', 'ngang_trái', 'chấp_hành', 'kỉ_niệm', 'di', 'hột', 'kim_tuyến', 'bă', 'lạnh', 'phá_sản', 'khí_hậu', 'sớm_muộn', 'chén', 'bùn', 'gai', 'haa', 'chuc', 'dầy', 'mobile', 'nói_riêng', 'muôn_đời', 'thật_tình', 'đồi', 'xog', 'mốt', 'cóc', 'răn_đe', 'hoc', 'hố', 'tuyet', 'voi', 'xào', 'đụng_chạm', 'hức', 'châm', 'họ_hàng', 'lằm', 'lốn', 'hihii', 'bn', 'khoản', 'tri', 'cổ_động_viên', 'năng_khiếu', 'tục', 'pk', 'buồn_ngủ', 'khấc', 'trọc', 'te', 'câ', 'táng', 'dụng_cụ', 'vô_ý_thức', 'ghê_tởm', 'bà_cô', 'nhà_máy', 'tuấn', 'kiệt', 'đại_gia', 'trăng', 'beep', 'ngôi', 'chỉ_huy', 'cỡ', 'diệt', 'bởi_vì', 'muôn', 'đag', 'gia_phả', 'vcd', 'hành_chính', 'nhu_cầu', 'gỡ', 'tàu_hỏa', 'bung', 'lật', 'tố_chất', 'alo', 'chua_cay', 'chi_tiết', 'tay_chân', 'dầu_hôi', 'phủ_nhận', 'vai_trò', 'khập_khiễng', 'ngu_si', 'loạn_luân', 'điên_khùng', 'phiền', 'tay_trái', 'thẹo', 'rụi', 'bánh_bèo', 'đi_nữa', 'đi_ngoài', 'diệu', 'béo_tốt', 'bình_quân', 'vùng', 'nếp', 'năn', 'bịt', 'cùi', 'từ_thiện', 'chật', 'cư', 'điêu', 'ợ', 'chắn', 'gio', 'mét', 'anh_vũ', 'hã', 'cp', 'thiên_thần', 'kết_bạn', 'chịu_đựng', 'vợ_con', 'kí_ức', 'ép', 'uy_tín', 'lì_xì', 'sen', 'kết_hợp', 'sx', 'hư_cấu', 'free', 'thờ_ơ', 'phạm', 'cay_nghiệt', 'goodbye', 'bar', 'ngày_càng', 'héo', 'cớ_sao', 'sổ', 'khó_ở', 'mất_ngủ', 'tình_cờ', 'như_điên', 'hình_thức', 'vô_lý', 'bé_nhỏ', 'chứng_kiến', 'xời', 'môn', 'cành', 'sale', 'thất_đức', 'nhung', 'công_nghệ', 'mặt_trăng', 'đồng_ý', 'lao_công', 'dọn_dẹp', 'từ_bỏ', 'vênh', 'kêu_ca', 'khô', 'sán', 'xử_tử', 'loz', 'đu_đủ', 'thìa', 'nằm_mơ', 'thoáng', 'canxi', 'xuống_nước', 'đánh_đòn', 'kì', 'bù', 'giống_hệt', 'niêm_yết', 'trật', 'giải_pháp', 'sad', 'tóm_lại', 'mới_đây', 'net', 'nín', 'đoàn_viên', 'đồng_hồ', 'thuyết_phục', 'ối', 'lương_tâm', 'hậu_quả', 'thôi_thì', 'view', 'dơ_bẩn', 'quậy', 'vui_mừng', 'đụng', 'công_bằng', 'gv', 'cầu_mong', 'khớp', 'ăn_không', 'sâu_sắc', 'lượn', 'nửa_vời', 'chã', 'vội', 'sảnh', 'tòa', 'râu', 'trang', 'ăn_cắp', 'mua_sắm', 'hj', 'lời_nói', 'thối_nát', 'thế_gian', 'tình_ái', 'dở_người', 'kêu_trời', 'giàu_có', 'ăn_hàng', 'khó_tính', 'dịp', 'ánh_sáng', 'phóng', 'uầy', 'ăn_học', 'li', 'dấu', 'đệ', 'thực_tập', 'cảm_nhận', 'vé_số', 'chj', 'nhân_ái', 'nhớ_đời', 'hẹn_hò', 'iq', 'quài', 'ngẩng', 'an', 'ngậm', 'vụt', 'nghiêm_khắc', 'hoành_tráng', 'ngân_hàng', 'giáo_dưỡng', 'dkm', 'cung', 'nỗi_lòng', 'tiện', 'quạt', 'the', 'bảo_thủ', 'thừa', 'thực', 'đồng_lòng', 'gối', 'sẵn_sàng', 'đúi', 'gạch', 'như_ý', 'lĩnh_vực', 'văn_học', 'cống_hiến', 'cạch', 'xuất_sắc', 'hoàn_thành', 'điệu', 'lít', 'tùy', 'động_viên', 'fake', 'bền', 'oke', 'chín', 'lây', 'bạt_tai', 'cau', 'tốc_độ', 'vụ_việc', 'make', 'cúp', 'van_xin', 'làm_phiền', 'nhiu', 'ác_ôn', 'ngon_lành', 'mục_đích', 'gd', 'ngọng', 'hình_phạt', 'gào_thét', 'nghiệt_ngã', 'mé', 'lằn', 'cảnh_sát', 'đọan', 'phương_tiện', 'tau', 'lách', 'nhãn', 'đầu_óc', 'tt', 'vâ', 'nhân_vật', 'sảy', 'người_làm', 'cật_lực', 'tới_tấp', 'mỉa_mai', 'vui_sướng', 'ít_nhất', 'kịch', 'qué', 'niềng', 'phục', 'thật_thà', 'cm', 'lém', 'meo', 'lẽ', 'ôi_thôi', 'múc', 'quá_thể', 'trao', 'tiến_bộ', 'ưu_tú', 'mất_lòng', 'long', 'mỡ', 'tks', 'điếc', 'trộn', 'khắp', 'ớn', 'giờ_đây', 'ngờ', 'bit', 'vi_phạm', 'đổ_thừa', 'quốc', 'khinh', 'hâm', 'phiêu', 'phong_trào', 'cặn_bã', 'kỳ', 'hack', 'trùm', 'giả_bộ', 'lén', 'cà_rốt', 'mụn', 'nghiêm_trọng', 'nghịch_ngợm', 'cún', 'lối', 'đặc_vụ', 'tuyệt_đối', 'tiếp_tay', 'ẩu', 'tuyển_dụng', 'phá_giá', 'gốc', 'mớ', 'cống', 'chân_chính', 'hoan_hô', 'hêt', 'thặc', 'khu', 'sợi', 'hả_dạ', 'kèo', 'ngọn', 'cổ_họng', 'cực_kì', 'bét', 'quản_lý', 'vén', 'áo_dài', 'tiền_túi', 'ác_mộng', 'vần', 'lm', 'phản_ứng', 'đấu_giá', 'giòi', 'dạy_dỗ', 'dột', 'khan', 'dũng_cảm', 'mót', 'chia_chác', 'xoạc', 'stk', 'từ_chối', 'gg', 'nhẽ', 'hàn_quốc', 'bốn', 'trọng_dụng', 'thói_quen', 'thực_trạng', 'ngóng', 'đấu_tranh', 'bừa_bãi', 'nhà_ăn', 'thiệp', 'tư_cách', 'vlog', 'xì', 'trắng', 'khẩu', 'hê', 'đối_thủ', 'toán', 'núp', 'có_mặt', 'kill', 'ka', 'lên_cơn', 'ghẹo', 'chúng_mình', 'chan', 'khía_cạnh', 'kp', 'thần_thánh', 'lạng', 'phản_đối', 'uổng_phí', 'ngắn_ngủi', 'ngoài_ra', 'kiện_tụng', 'tháng_ngày', 'kĩ_thuật', 'tra_tấn', 'àh', 'ơiiii', 'khẩu_trang', 'vì_vậy', 'bụi', 'xao_xuyến', 'trích', 'chứa', 'thông_điệp', 'chân_mày', 'tuỳ', 'yêu_tinh', 'ngan', 'chách', 'cay_đắng', 'trị', 'bắt_cóc', 'thị', 'ghệ', 'lộ', 'trò_cười', 'hó_hé', 'dể', 'chia_ly', 'cắm_sừng', 'drama', 'phấn', 'học_hỏi', 'chuyên_nghiệp', 'copy', 'in', 'tạo_hóa', 'ló', 'hận', 'dang_dở', 'nai', 'xóm', 'nhòm', 'định_nghĩa', 'kề', 'đồ_chơi', 'xấu_hổ', 'khóa', 'thông', 'đau_đầu', 'nhãm', 'dọa', 'banh', 'list', 'nũa', 'nhóm', 'dĩa', 'vô_học', 'thênh_thang', 'mua_vui', 'miễn_phí', 'bế', 'tẩm', 'im_lặng', 'thấu', 'xé', 'bro', 'tít', 'het', 'rốt', 'uất', 'ghiền', 'mxh', 'khung_cảnh', 'thân_thương', 'non', 'quy_định', 'que', 'ấu_trĩ', 'qá', 'dẫu', 'tấn', 'đánh_bại', 'phần_nào', 'bất_cần', 'khí', 'ngạc_nhiên', 'lịch', 'tình_hình', 'thât', 'hốc', 'con_nuôi', 'tải', 'rợn', 'chuyên_gia', 'đuợc', 'tởn', 'lụm', 'hưởng_thụ', 'thuận', 'bận', 'tâm_trạng', 'chủ_nhật', 'bim', 'liệt_kê', 'đèo', 'tủi_thân', 'ib', 'xắm', 'quát', 'hiện_đại', 'tiếc_nuối', 'dáng', 'truy_tố', 'tật_nguyền', 'phân', 'nhỏ_nhen', 'cừu', 'nhuộm', 'ròi', 'vĩnh_viễn', 'you', 'thanh_thản', 'diễn_xuất', 'bg', 'xí', 'yếu', 'ẻm', 'hổng', 'xịu', 'vất', 'ny', 'ủ', 'kí', 'cực_kỳ', 'chiếm', 'đóa', 'đanh_đá', 'nghề_nghiệp', 'suýt_nữa', 'con_số', 'đúg', 'lăn', 'hạp', 'làn', 'yếu_đuối', 'vị_trí', 'ngày_ngày', 'mỏng_manh', 'trọ', 'đâu_đây', 'ngắn_gọn', 'hất', 'xót', 'nặng_lời', 'bọ', 'thik', 'võ_thuật', 'thằn_lằn', 'bốp', 'ỉ', 'so_sánh', 'số_phận', 'theo_đuổi', 'mâm', 'ôtô', 'loi_choi', 'galang', 'dỗ_dành', 'sinh_vật', 'ốc_bươu_vàng', 'liêm_sỉ', 'vất_vả', 'tình_nguyện', 'sổ_đỏ', 'riềng', 'thông_tin', 'nuôn', 'thể_thao', 'độc_thân', 'khoa', 'cũn', 'truyền_thuyết', 'trả_thù', 'cường_lực', 'truyền_bá', 'thảm_họa', 'tùm_lum', 'kiến_thức', 'síu', 'kích_thích', 'riêng_tư', 'king', 'oai', 'báo_hiếu', 'nhà_đá', 'y_như', 'chăng_nữa', 'giặt', 'bỏ_rơi', 'hạn', 'có_hạn', 'lát', 'giấy_tờ', 'chết_đuối', 'nhường', 'trĩ', 'tâm_sự', 'check', 'thuong', 'khac', 'câng', 'ae', 'chọp', 'ánh', 'đáng_đời', 'uớc', 'muôn_vàn', 'huống', 'chậm_trễ', 'gồng', 'bán_nước', 'lơ', 'phức_tạp', 'chinh_phục', 'bây_chừ', 'trất', 'hs', 'mẩu', 'tổng_kết', 'miết', 'đầy_đủ', 'bài_tập', 'cv', 'múa_lân', 'thiệt_hại', 'trầy_xước', 'bộn', 'kiệt_sức_khỏe', 'chế_độ', 'tự_nguyện', 'kq', 'lừa_gạt', 'coi_chừng', 'mj', 'phá_hủy', 'phật_giáo', 'đời_sống', 'tâm_linh', 'rẻ_rúng', 'giang', 'thy', 'ngẫm_nghĩ', 'sọ_dừa', 'lạ_lùng', 'nghệ_an', 'huề', 'sái', 'quai_hàm', 'phát_hiện', 'bép_xép', 'lạ_mắt', 'khoé', 'khoa_học', 'nước_lạnh', 'ks', 'quà_cáp', 'ngón', 'phàm_ăn', 'ưu_đãi', 'dịu_dàng', 'cup', 'nhỏ_nhặt', 'giở_trò', 'thời_sự', 'tổ_sư', 'the_thé', 'cơ_bắp', 'kì_lạ', 'thằng_cha', 'zi', 'lộng_lẫy', 'đong', 'ngông', 'trễ', 'vô_số', 'phần_lớn', 'ngoại_lệ', 'bước_tiến', 'thuở', 'thiếu_thời', 'chẳn', 'bốc_đồng', 'đe', 'cận_cảnh', 'nước_lèo', 'hao', 'bản_chất', 'ưa', 'chú_rể', 'socola', 'of', 'mun', 'kip', 'cúng', 'âm_binh', 'volum', 'cast', 'người_thân_quen', 'dlm', 'tụm', 'mờ', 'gane', 'stt', 'cài', 'úng', 'suy_đồi', 'công_lao', 'đền_đáp', 'ngoác', 'gấu_trúc', 'trúc', 'vtv', 'vợ_bé', 'ngây_ngô', 'fải', 'tràn_ngập', 'ngỡ', 'thóc', 'ay', 'mọt_gông', 'bon', 'ròng_rã', 'lưu_lạc', 'kiến_lửa', 'zời', 'chìm', 'nóng_tính', 'cương_quyết', 'trân_châu', 'huy_hoàng', 'le_lói', 'đạo_cụ', 'nồng', 'khóe', 'cào', 'phím', 'chê_bai', 'am_hiểu', 'giớ', 'giây_phút', 'láp', 'xược', 'nệm', 'vụng_về', 'phát_huy', 'zo', 'hoàn_chỉnh', 'hee', 'sóc', 'gõ', 'đêm_đêm', 'hắn', 'cay_cú', 'hàng_không', 'nhồi', 'gián_tiếp', 'cấp_độ', 'tai_nghe', 'viển_vông', 'kì_cục', 'chớt', 'bước_đầu', 'rài', 'nhớp', 'cư_dân', 'phập', 'tươ', 'tốt_nghiệp', 'phen', 'ri', 'đa_phần', 'đông_lạnh', 'bỉm', 'đậm_chất', 'phân_khối', 'mink', 'nhà_cửa', 'ma_quỷ', 'đi_lại', 'mất_gốc', 'lag', 'đẹp_đôi', 'tơi', 'chùi', 'trung_quốc', 'tai_nạn', 'ngừng_nghỉ', 'èo', 'tàn_phá', 'vá', 'la_làng', 'tự_vấn', 'cô_hồn', 'nghèo_rớt', 'mồng_tơi', 'oi', 'troi', 'nhập_khẩu', 'rả', 'khinh_thường', 'làm_gương', 'đối_phương', 'khôi_phục', 'hận_thù', 'cập_nhật', 'bất_động_sản', 'hó', 'dự_định', 'đổ_xô', 'hiếu_kỳ', 'loai', 'xấu_xa', 'canh_bạc', 'tự_sát', 'bọ_xít', 'thì_chớ', 'ngoạc', 'hễ', 'bợt', 'phổi', 'dõ', 'ô_nhiễm', 'rộ', 'quả_quyết', 'kể_ra', 'móc_túi', 'hàm_răng', 'chinh_chiến', 'nhem_nhẻm', 'cả_thể', 'ná', 'tác_phẩm', 'hiếm_hoi', 'điện_ảnh', 'công_chúng', 'đạn', 'đau_điếng', 'nhắm_mắt', 'nắm_bắt', 'kéo_theo', 'ẩu_tả', 'thuoc', 'bat', 'kiem', 'diễm', 'nhăn_nhó', 'sạn', 'cánh_tay', 'độn', 'lộn', 'la_liếm', 'làm_loạn', 'định_hướng', 'vậy_sao', 'khởi_động', 'tay_nghề', 'nấu_nướng', 'ương', 'ben', 'nhiêu', 'mặc_cả', 'quần_lót', 'ki', 'gơ', 'thành_quả', 'del', 'xoắn_ốc', 'quy_luật', 'cày', 'cơ_ngơi', 'r', 'hối_hận', 'tpbank', 'giấu', 'bòn', 'căng_thẳng', 'mức_độ', 'nói_xấu', 'hầu_như_ai', 'bao_dung', 'người_thân', 'khuyết_điểm', 'hoạ', 'dàn', 'bật_lửa', 'vinmec', 'nghê', 'â', 'lung_lay', 'lắng', 'nàn', 'công_nghiệp', 'đại_trà', 'đun', 'chơi_bời', 'làm_biếng', 'nhang', 'khấn_vái', 'tài_lộc', 'tóc_sâu', 'đ', 'phiền_hà', 'chắt', 'tâm_hồn', 'rông', 'tội_ác', 'hoàn_mĩ', 'gan_dạ', 'chân_kính', 'hồi_xuân', 'rần_rật', 'cắt_cử', 'giềng', 'quy_trình', 'đợi_chờ', 'tiến_triển', 'hơn_nữa', 'hư_đốn', 'dị_nghị', 'chì_chiết', 'phia', 'danh_ngôn', 'bột', 'chiên', 'huhuhu', 'checkin', 'tình_trạng', 'bất_kì', 'km', 'mặc_kệ', 'sapa', 'dụi', 'pv', 'toilet', 'troll', 'dưa', 'cf', 'quàng', 'hiếp_dâm', 'ngửa', 'thấy_kinh', 'suy_thoái', 'khuôn', 'đúc', 'bắt_chuyện', 'tỉ_mỉ', 'ac', 'tín_ngưỡng', 'xem_chừng', 'đét', 'quát_tháo', 'nhố_nhăng', 'khu_phố', 'đựoc', 'đích', 'thiu', 'giám_đốc', 'đậm', 'zay', 'sỉ_nhục', 'lăng_mạ', 'kẻ_thù', 'xám', 'thục_mạng', 'đắn_đo', 'ù', 'tào', 'chòi', 'môi', 'zoe', 'khôn_lớn', 'chồn', 'sắp_sửa', 'vòng_vòng', 'tơ', 'đua', 'diển', 'khuyến_mại', 'chột_dạ', 'hlv', 'pogba', 'mu', 'thời_tiết', 'thông_báo', 'cấy', 'giải_phóng', 'chiếm_đoạt', 'nhằng', 'tno', 'cử', 'tép', 'hùm', 'cs', 'mơ_ước', 'mòn', 'nha_nha', 'cóng', 'hp', 'thầu', 'nấu_ăn', 'bư', 'sư_tử', 'phúc_đức', 'thiết_bị', 'cẩng', 'ớ', 'ăn_vạ', 'bonus', 'ven', 'máy_chém', 'chân_thực', 'vững', 'quan_điểm', 'kara', 'trang_trí', 'đèn_cầy', 'lòa', 'nhà_thơ', 'ẩn_dụ', 'chơi_chữ', 'phân_tích', 'nươ', 'ninh', 'tiê', 'giu', 'đơ', 'be', 'giẻ', 'mừn', 'nhíp', 'sưởi', 'thủy_lực', 'luyến', 'khởi_nghiệp', 'tsb', 'cao_nguyên', 'nhiệt_đới', 'lạnh_giá', 'sương_muối', 'sinh_trưởng', 'biên', 'haizzzz', 'nhâm_nhi', 'phì_phèo', 'điếu', 'boxing', 'ra_đời', 'dụ_dỗ', 'nết_na', 'euro', 'rực', 'toà', 'phủ', 'sĩ_diện', 'inter', 'banking', 'kau', 'vàng_đen', 'hồ_tiêu', 'tứ_xứ', 'nhớp_nhúa', 'khía', 'nạn', 'rồi_ra', 'nhĩ', 'ào', 'son', 'báo_đáp', 'giúp_việc', 'phức', 'sấm_sét', 'doạ', 'dg', 'rap', 'quên_mình', 'dap', 'rat', 'vu', 'nhanh_trí', 'ớt', 'cú_mèo', 'tự_ý', 'nhẹ_tay', 'chẳng_bù', 'gặp_mặt', 'bất_lương', 'my', 'hoang_tưởng', 'thâm_niên', 'kiềm_chế', 'khắc_phục', 'vũ_lực', 'giải_lao', 'quá_khích', 'trá', 'bằng_chứng', 'tiêu_cực', 'sun', 'công_chúa', 'đời_thường', 'sầu_riêng', 'lanh', 'tay_đôi', 'biết_ơn', 'hổ', 'đi_bụi', 'xen', 'lô', 'lz', 'camera', 'không_đâu', 'iêu', 'bờm', 'khuyến_cáo', 'thủng', 'nhân_hậu', 'ghe', 'vung', 'sặc', 'đành_rằng', 'ăn_xin', 'đoàng', 'víu', 'ukm', 'nhồn', 'màu_mè', 'khẽ', 'lệ', 'hí_hửng', 'tụ_họp', 'khắn', 'sáng_lập', 'công_thức', 'hợp_lý', 'mổi', 'ăn_nhậu', 'ngà_ngà', 'giang_hồ', 'tưởng_chừng_như', 'dâu_tằm', 'biến_dạng', 'địch', 'cầu_thang', 'dựt', 'đoàn_kết', 'manga', 'bản_địa', 'rmit', 'an_ninh', 'thèm_khát', 'bỉu', 'singapore', 'hành_lý', 'hù', 'công_tác', 'cô_dâu', 'liên_đoàn', 'liên_hệ', 'chơi_khăm', 'huống_gì', 'điệu_đà', 'trầy', 'rớt_giá', 'kinh_khủng_khiếp', 'aw', 'công_ích', 'nhà_tù', 'giúp_ích', 'mall', 'hủy_hoại', 'bé_con', 'mịa', 'tuôi', 'lạc_quan', 'ứng', 'ồn', 'sống_lưng', 'sài_gòn', 'bí_quyết', 'agri', 'hách', 'đũa', 'con_cả', 'thân_ái', 'tích_cực', 'rạch', 'tại_chỗ', 'sưng', 'triệt_sản', 'nghén', 'âm_nhạc', 'tưng', 'hu_hu', 'xóa_bỏ', 'láng', 'mịn', 'tam_kì', 'ds', 'làm_luật', 'tay_trắng', 'chen', 'xơi', 'trỏ', 'lành_lặn', 'vác_mặt', 'đầu_gấu', 'chí_ít', 'hiện_giờ', 'đa_số', 'phàm', 'hỏi_vợ', 'gươm', 'nguồn_lực', 'dân_tộc', 'luật_định', 'cách_ly', 'vote', 'nhục_nhã', 'crazy', 'xác_nhận_lời', 'thái_lan', 'saoooo', 'tưng_tưng', 'vi_khuẩn', 'vi_trùng', 'nấp', 'hiccc', 'hao_mòn', 'nhan_sắc', 'thương_yêu', 'ghê_á', 'ăn_bám', 'khá_giả', 'áy_náy', 'góp_ý_kiến', 'tằm', 'pg', 'hoả', 'cảnh_báo', 'nhẫn_nhịn', 'hơm', 'bài_học', 'tuốt', 'cận', 'mở_mắt', 'lien', 'rưng_rưng', 'quyền_lực', 'ngột', 'ngôn_ngữ', 'điểm_mù', 'vô_cảm', 'said', 'nôn', 'phong_thuỷ', 'nhọt', 'đíu', 'hỉu', 'triều_tiên', 'dòm', 'husky', 'lờ_đờ', 'phấn_đấu', 'toang_toác', 'ây', 'nháo_nhào', 'khà_khà', 'vi_vu', 'quyển', 'ngải_cứu', 'tác_dụng', 'truyện_cổ_tích', 'chua_lè', 'chua_loét', 'cơ_thể', 'đánh_đổi', 'kỳ_lạ', 'ez', 'danh_dự', 'nhân_phẩm', 'dme', 'ăn_theo', 'đột_nhiên', 'xôi', 'giản_dị', 'yêu_mến', 'sọt', 'đổi_thay', 'vuông', 'chung_quy', 'nịnh_nọt', 'ầm_ầm', 'niếm', 'con_heo', 'chịu_thua', 'giao_lưu', 'càn', 'cốt_lõi', 'then_chốt', 'thúc_đẩy', 'tiển', 'sách_lược', 'nỏ', 'thun', 'thẹn', 'đầu_lâu', 'cõng', 'đồng_bằng', 'bác_học', 'sàm_sỡ', 'bết', 'quì', 'trực_tiếp', 'miệt_thị', 'mặt_đường', 'hoài_niệm', 'bộ_đội', 'yếu_ớt', 'kiềm', 'hỉ', 'phò', 'ố', 'rùng_mình', 'lồng_lộng', 'bổ_sung', 'ngang_ngược', 'giám_khảo', 'tưong', 'chó_chết', 'tiếp_xúc', 'chắc_ăn', 'tê', 'chôm', 'ngàng', 'lập_luận', 'thú_y', 'dây_chằng', 'giòn', 'xuất_viện', 'sug', 'nhà_trẻ', 'túi_tiền', 'họa', 'grab', 'thơm_phức', 'hem', 'lám', 'ám', 'lạ_kì', 'vẫ', 'lợi_hại', 'nhũng', 'bản', 'quyết', 'ngăn', 'tiệt', 'kiệm', 'khai_sinh', 'bình_dị', 'thảo_nào', 'mõi', 'thích_thú', 'được_cái', 'lười_biếng', 'can', 'chinh', 'chính_quyền', 'bai', 'kỉu', 'chấy', 'chọc_tức', 'thử_nghiệm', 'nới', 'xò', 'live', 'stream', 'núc', 'bơm', 'dma', 'gă', 'lân', 'avenger', 'hehee', 'mỏi_mệt', 'tranh_cãi', 'cigar', 'am', 'thiền_định', 'tiếp_quản', 'thường_tình', 'giới', 'đại_tu', 'hỏi_han', 'ní', 'gãi', 'ứ', 'cơ_cực', 'dứt_khoát', 'nhận_diện', 'khí_chất', 'bão', 'giông', 'trợ_giúp', 'nhân_dân', 'mệ', 'fail', 'không_chừng', 'ca_sĩ', 'xáng', 'noi', 'hàn_gắn', 'bịa_đặt', 'bú', 'phũ', 'thiểu_năng', 'năng_lực', 'spider', 'bình_phục', 'căn_bản', 'dương', 'hoang_mang', 'rung', 'đôi_lứa', 'đạo_lý', 'có_thể_loại', 'xẩy', 'giáp', 'cổ_hủ', 'xiền', 'nguy_cơ', 'giáo_sư', 'giáo_trình', 'đai', 'giảm_tốc_độ', 'thạ', 'thế_ra', 'động_dục', 'vớ', 'halo', 'mua_bán', 'lồi_lõm', 'vòi', 'hoy', 'địa_phương', 'hụt', 'cũnh', 'chông', 'mộc', 'xử_lí', 'hèm', 'tắt_thở', 'huynh', 'không_lẽ', 'kím', 'ce', 'dược', 'mồi', 'mộ', 'thấp_thỏm', 'cứu_vớt', 'mặt_bằng', 'chíp', 'đuôi', 'input', 'thi_thoảng', 'lườm', 'mô_tả', 'vực', 'bao_biện', 'chửi_rủa', 'romantic', 'kiểm_soát', 'dắm', 'kiểm_điểm', 'gia_vị', 'pê', 'đài', 'táo', 'imdb', 'thời_đại', 'dây_điện', 'dăm', 'rê', 'bệnh_nhân', 'tía', 'thần_tượng', 'uoc', 'duoc', 'nhu', 'ngộ_nghĩnh', 'biến_động', 'thăng_trầm', 'chả_viên', 'hệ_thống', 'bật_tường', 'gắn', 'miên_man', 'báo_ứng', 'tẩy', 'hô_hào', 'nun', 'định_kì', 'mat', 'quân_nhân', 'tập_trận', 'pccc', 'thao_trường', 'chiến_trường', 'đổ_máu', 'bà_thảo', 'chăm_lo', 'gia_trưởng', 'vũ_phu', 'sát_cánh', 'ấp', 'tâm_trí', 'con_buôn', 'bọ_chét', 'cớ', 'hẩy', 'woa', 'kẹp', 'hịt', 'khênh', 'thế_chân', 'đạo_diễn', 'tài_ba', 'tk', 'vạn', 'để_dành', 'toán_học', 'single', 'mum', 'sức_lực', 'hành_xác', 'vẹo', 'hoàn_thiện', 'che_kín', 'quan_sát', 'xành', 'bàn_thờ', 'power', 'siêng_năng', 'tớn', 'phát_biểu', 'thực_dụng', 'nghìn_tỷ', 'rau', 'comt', 'vietsub', 'lồng_tiếng', 'ráo', 'ntmk', 'san', 'vấp_ngã', 'nước_hoa', 'real', 'vạch_mặt', 'block', 'xd', 'kỉ_yếu', 'ngói', 'sống_động', 'chừng', 'bảy', 'bưởi', 'cự', 'thoại', 'xãy', 'đâ', 'mo', 'thừa_thế', 'từ_bỏ_quá', 'dìm', 'ngư_dân', 'mách_lẻo', 'học_tập', 'photoshop', 'quy', 'thi_hành', 'công_vụ', 'khu_vực', 'loc', 'lõi', 'nguyên_chất', 'xã_giao', 'sự_tích', 'sát_hại', 'tu_hành', 'nhât', 'hoan_hỉ', 'lộc', 'tác_hại', 'cần_câu', 'chế_tạo', 'honda', 'sục', 'bình_xịt', 'xà', 'phồng', 'hô', 'đặng', 'đơn_thuần', 'mã', 'kinhh', 'liên_lạc', 'phảu', 'chứa_đựng', 'bí_mật', 'vùi', 'mứt', 'nhó', 'bê', 'daklak', 'khủng', 'né_tránh', 'chuyên_cơ', 'chiêc', 'trơi', 'mạ', 'thầm_lặng', 'gia_nhập', 'quát_mắng', 'fire', 'té_ra', 'fine', 'đh', 'everywhere', 'nhễ', 'quâ', 'qa', 'đỡ_đẻ', 'sáu', 'đậu_phộng', 'đề_cương', 'án_mạng', 'giàu_sang', 'phú_quý', 'sòng_phẳng', 'công_cốc', 'kì_vọng', 'sat', 'chuyên', 'tụ_tập', 'ngự', 'nhàn', 'kiểm_kê', 'toà_án', 'nùi', 'một_hai', 'mầm', 'chớm', 'xẹp_lép', 'lặng_im', 'mọc_sừng', 'toại_nguyện', 'nghệt', 'thuật', 'làm_chủ', 'làm_mướn', 'tương_tự', 'dòng_họ', 'un', 'nt', 'nặng_tình', 'trí_khôn', 'tiến_hóa', 'đẹp_đẽ', 'giai_điệu', 'lãnh', 'mở_màn', 'chúg', 'ngổng', 'bồi', 'ngày_sinh', 'ré', 'hoảng', 'nhởn', 'kinh_phí', 'dell', 'tỷ_lệ', 'nữa_là', 'nói_dối', 'truyền_cảm_hứng', 'khoan_dung', 'khinh_bỉ', 'đâu_đó', 'ủng_hộ', 'vít', 'gỗ', 'chở', 'cửa_mở', 'nhân_duyên', 'quad', 'học_giả', 'rả_rích', 'đăm_đăm', 'rôm_rả', 'giáo', 'dấu_ấn', 'hình_tượng', 'trãi', 'biệt_tích', 'nước_gạo', 'đùa_cợt', 'ý_nghĩ', 'ts', 'tiền_nong', 'tạp_chất', 'sự_nghiệp', 'hăm_hở', 'thậm_chí', 'hương_vị', 'chuỗi', 'tủi_nhục', 'inh_ỏi', 'quan_tài', 'nức_nở', 'bánh_tráng', 'đầm_đìa', 'dưa_gang', 'dưa_hấu', 'phượng', 'chót_vót', 'lừa_dối', 'ra_rìa', 'dày', 'vào_sổ', 'gội', 'còm', 'phức_tạp_hóa', 'say_mê', 'hình_bóng', 'tripod', 'chèn', 'thích_đáng', 'vặn', 'hiển', 'công_cộng', 'không_lưu', 'nung', 'thí', 'phệ', 'tập_huấn', 'tưng_tửng', 'thanh_tra', 'dễ_dãi', 'hứ', 'dv', 'phát_tán', 'virut', 'chợ_đen', 'trêu_chọc', 'rặt', 'dốc', 'quật', 'máu_lửa', 'ss', 'ra_gì', 'sang_năm', 'nhãi', 'nhào', 'babe', 'hoi', 'nằm_vùng', 'rầu', 'rủi', 'nách', 'trơ', 'cọng', 'tân', 'quá_tội', 'trắng_bóc', 'thị_trường', 'gờ', 'giảm_tốc', 'trẩu', 'hôi', 'truy', 'xác_chết', 'pháp_y', 'kỹ_sư', 'trắc_địa', 'paris', 'cảm_thông', 'cảm_động_lòng', 'ông_địa', 'marketing', 'dăm_bảy', 'đười_ươi', 'đào_thải', 'cơ_chế', 'xỏ', 'phản_cảm', 'âm_lịch', 'tên_tuổi', 'nghỉ_hè', 'xõa', 'nhà_báo', 'dở_hơi', 'protein', 'gìn_giữ', 'bảo_tồn', 'lo_nghĩ', 'hàn', 'bất_cẩn', 'chăng', 'có_nhân_tính', 'đoạt', 'oscar', 'mừng_quýnh', 'đánh_thức', 'năn_nỉ', 'gò', 'vấp', 'rành_rành', 'lọt_tai', 'chỉ_đạo', 'gây_sự', 'nản', 'thụ_động', 'chặn_đứng', 'hiện_tượng', 'xuống_cấp', 'vật_liệu', 'chập', 'cộng', 'ăn_tạp', 'thcs', 'phát_âm', 'giao_tiếp', 'phật', 'đại_gia_đình', 'yếu_kém', 'triệu_phú', 'ổ_chuột', 'sơ_sài', 'choét', 'làm_bộ_mặt', 'nhãn_vở', 'mỹ_thuật', 'tình_nguyện_viên', 'hủy', 'vr', 'dục', 'ngoe_nguẩy', 'đáng_lẽ', 'cạ', 'duới', 'amir', 'vol', 'gdinh', 'tự_chủ', 'hươu', 'vượn', 'mưa_gió', 'rét_mướt', 'công_ơn', 'súp_lơ', 'chi_phí', 'kiểm_toán', 'thổ_lộ', 'nhọc', 'nước_nôi', 'be_bét', 'tu_luyện', 'góp_phần', 'nhiếu', 'đất_sét', 'đển', 'phượng_hoàng', 'trấn', 'hồ_sơ', 'thái_bình', 'dầu_lửa', 'nặng_tay', 'cân_treo', 'diễn_tả', 'hẻm', 'cà_khịa', 'ị', 'tình_yêu_thương', 'ngĩ', 'biên_chế', 'chuyên_môn', 'báo_chí', 'phóng_viên', 'nghiêm', 'rét', 'tuyệt_chủng', 'tq', 'nhờn', 'bừa', 'điềm', 'như_thường', 'noel', 'nguyên_xi', 'next', 'kiều', 'dung', 'yên_ổn', 'lén_lút', 'tổng_giám_đốc', 'hu', 'phi_', 'phỏng_vấn', 'idol', 'skill', 'cơ_quan', 'điều_tra', 'danh_tính', 'tấu', 'âm_thanh', 'chối', 'câu_đầu_tiên', 'thoả_đáng', 'định_giá', 'hi', 'noa', 'trung_bình', 'làm_khách', 'qua_lại', 'siêu_thị', 'ác_cảm', 'lùm', 'thỉnh_thoảng', 'tẩy_trang', 'nguyên_hình', 'song_song', 'tính_tình', 'thử_thách', 'first', 'blood', 'double', 'ý_tứ', 'nhẹp', 'gấp_bội', 'than_thở', 'replay', 'đứng_tim', 'nhấp', 'muỗng', 'bạc', 'nói_tục', 'bần_hàn', 'tinh_trùng', 'bán_lẻ', 'nháy_mắt', 'chấp', 'hịn', 'cổ_nhân', 'vọt', 'biểu_cảm', 'phét', 'có_ích', 'quý_báu', 'sinh_mạng', 'sắm', 'biết_nghĩ', 'đức_hạnh', 'cao_cả', 'on', 'nãn', 'suất', 'quấy_rối', 'mịe', 'khốn_kiếp', 'quả_lừa', 'bờ_rào', 'huỷ_hoại', 'mầm_mống', 'vồ', 'lù', 'unlike', 'yêu_cầu', 'sub', 'bt', 'lạng_lách', 'thíck', 'cã', 'đồng_thanh', 'lớ', 'nga', 'lớ_ngớ', 'tự_phát', 'tàn_nhang', 'bỗng', 'ập', 'thọ', 'smart', 'phone', 'idiots', 'tư_sản', 'mại_bản', 'đậu_xanh', 'giỡn', 'laptop', 'hình_vẽ', 'buồn_tẻ', 'bất_công', 'khai_giảng', 'sai_phạm', 'biện_pháp', 'chấm_dứt', 'tan_tành', 'tẹo', 'thẳng_tay', 'mưu_cầu', 'chết_tươi', 'ẹc', 'rược', 'sùm', 'hắt', 'nước_tiểu', 'bấy', 'bề', 'kiê', 'thọc', 'ung_thư', 'tinh', 'hung_ác', 'vơ', 'có_ăn', 'hướng_dẫn', 'rước', 'lún', 'bất', 'dì', 'quết', 'nuôi_dưỡng', 'unesco', 'kỳ_quan', 'chộm', 'chẳng_những', 'nhẹ_nhõm', 'cảnh_ngộ', 'dắt_mũi', 'au', 'trá_hình', 'khì', 'xinh_xắn', 'ngăn_chặn', 'lội', 'không_những', 'thổ', 'aumobile', 'sa_tế', 'bắt_gặp', 'bơ', 'luyện', 'sấp', 'quái_ác', 'ăn_chay', 'bống', 'axit', 'rồ', 'is', 'cổ_chân', 'năng', 'cại', 'chậy', 'giấc', 'ví_dụ', 'không_tưởng', 'bao_tay', 'nhân_đạo', 'cool', 'quí_trọng', 'hình_hài', 'khôn_ngoan', 'phắng', 'nói_thẳng', 'đồng_hành', 'học_trò', 'hồn_nhiên', 'hòm', 'lip', 'đi_cầu', 'từ_biệt', 'rướn', 'pizza', 'kv', 'bình_chánh', 'thành_phần_nào', 'ăn_hiếp', 'vi_sóng', 'hjhj', 'ngoại_tình', 'phàn_nàn', 'rành', 'full', 'đương_đầu', 'vạch', 'làm_nên', 'sốn', 'wao', 'đề_kháng', 'ct', 'nhay', 'ngưỡng', 'bùng_phát', 'phương', 'trường_học', 'chuyên_mục', 'đã_đành', 'sở', 'khanh', 'cẩn_trọng', 'giầy', 'thấu_hiểu', 'icon', 'bcs', 'sag', 'đánh_lộn', 'thuần_phong', 'mỹ_tục', 'ngoa', 'ống', 'tự_do', 'phịch', 'lang_thang', 'vô_nghĩa', 'mìh', 'khổ_tâm', 'bong', 'chó_đẻ', 'rao_giảng', 'nằm_xuống', 'thiên_thời', 'địa_lợi', 'văn_chương', 'thân_thiện', 'tiến_hoá', 'đút', 'lia_lịa', 'oanh_liệt', 'hình_học', 'xe_tải', 'rubic', 'kinh_ngạc', 'mười', 'đấu_trường', 'tứ_linh', 'đao', 'trán', 'làm_phước', 'dư_thừa', 'lò_xo', 'đi_tu', 'ngu_ngơ', 'quốc_khánh', 'bó', 'nhâu', 'tranh_thủ', 'đx', 'nhận_thức', 'thở_dài', 'kịch_tính', 'fr', 'mood', 'nhà_nghỉ', 'chau', 'say_đắm', 'nhói', 'nhích', 'thời_thế', 'đại_loại', 'trai_trẻ', 'đất_đai', 'helo', 'khuya', 'thưởng_thức', 'dống', 'bấy_nhiêu', 'bản_quyền', 'luyến_tiếc', 'ân_cần', 'vũ_khí', 'sinh_học', 'mini', 'giả_sử', 'bỏ_túi', 'lọ', 'never', 'muỗi', 'ăn_liền', 'thiệt_thân', 'trước_hết', 'neu', 'nết', 'nguoi', 'dòng_chảy', 'gạt', 'camry', 'hoang', 'cẩm_ly', 'thành_tâm', 'ghẻ_lạnh', 'tiếp_cận', 'ex', 'bùng', 'nỗ', 'nén', 'cường_quốc', 'hung', 'chuyển_biến', 'cơm_bữa', 'véo', 'siro', 'tức_cười', 'dễ_thở', 'quét_dọn', 'đoá', 'xem_ra', 'giá_cả', 'ẳm', 'sấu', 'tử', 'bình_an', 'làm_chi', 'nờ', 'nện', 'giúp_đỡ', 'nhen', 'phìm', 'hướng_nội', 'cao_thế', 'chạp', 'bh', 'trao_đổi', 'chà_đạp', 'giãy_nảy', 'đỉa', 'vôi', 'trọng_đại', 'phan', 'suy_ngẫm', 'nghia', 'chưng', 'liết', 'khẳng_định', 'chứng_tỏ', 'anh_hùng', 'lưu_ý', 'nhà_hàng', 'li_hôn', 'giảm_giá', 'rỉ', 'sét', 'đep', 'ỏ', 'lẻ', 'nầy', 'chăn_nuôi', 'gia_súc', 'pháo', 'bụt', 'sát_thương', 'bỏ_qua', 'sì', 'tàn_tật', 'tương_tác', 'đk', 'đượm', 'chg', 'bb', 'toàn_bộ', 'cảnh_vật', 'quen_thuộc', 'ngân_sách', 'sửa_sai_lầm', 'đơn_vị', 'tư_pháp', 'lên_tiếng', 'hám', 'thu_ngân', 'hầu_hết', 'karaok', 'phụ_thu', 'nước_ngọt', 'rát', 'thoy', 'tình_báo', 'mẹt', 'hờn_dỗi', 'huyện', 'nghiên_cứu_viên', 'cao_cấp', 'ốp', 'content', 'vk', 'bảo_bối', 'liều_lĩnh', 'lạc_hậu', 'nhịp', 'xl', 'thoa', 'chẳng_qua', 'hoàng_hôn', 'úa', 'justin', 'bieber', 'cừng', 'nguyen', 'liếc', 'boom', 'cá_chép', 'rồng', 'vẫy_vùng', 'hành_vi', 'nội_tâm', 'bong_bóng', 'phát_nổ', 'cia', 'nhy', 'tịnh', 'mác', 'tăm_tối', 'ava', 'pug', 'nghị', 'khởi_tố', 'thổ_nhưỡng', 'tung_hô', 'dải', 'qúa', 'chương', 'làm_bạn', 'nữ_sinh', 'cãi_lộn', 'xuân', 'đúng_đắn', 'follow', 'công_viên', 'nứng', 'con_một', 'niêm', 'ngài', 'lặp', 'thần_sắc', 'thiếu_điều', 'chủ_đề', 'incheon', 'tỉnh_giấc', 'xùm', 'thiêu', 'axít', 'đậm_đặc', 'nhựa', 'tạp_hoá', 'lúng', 'chậm', 'băng_keo', 'công_sức', 'ủi', 'đãi', 'đáng_giá', 'tha_hồ', 'rác_thải', 'nảy', 'mạnh_khoẻ', 'ăn_bớt', 'lả', 'chức_quyền', 'bánh_mì', 'chức', 'trieu', 'mục', 'gia_cầm', 'nhì', 'tẩm_bổ', 'huy', 'chứng_khoán', 'nghĩ_ngợi', 'nẩy', 'tâng_tâng', 'hố_xí', 'sàm', 'típ', 'hách_dịch', 'cõi_lòng', 'thượng_đế', 'cắt_tiết', 'kô', 'ngoan_ngoãn', 'okay', 'mở_miệng', 'vửa', 'phối', 'vô_địch', 'clm', 'võ_nghệ', 'cao_siêu', 'phụ_thuộc', 'hung_khí', 'câm', 'quân', 'triển_lãm', 'truy_cứu', 'căn', 'ngắm_nghía', 'rối_bời', 'all', 'hmm', 'xoè', 'xưa_nay', 'trả_góp', 'sặc_sụa', 'tg', 'quốc_hội', 'vẽ_chuyện', 'quy_mô', 'đối_tác', 'nham', 'toác', 'song', 'chẳng_thể', 'valungtung', 'tanh_bành', 'thủ', 'sẵn', 'hoạng', 'mủ', 'tiến_sĩ', 'thạc_sĩ', 'hình_như_ai', 'dối_trá', 'xanh_mắt', 'lap', 'áo_đầm', 'bất_lực', 'hk', 'động_chạm', 'nhò', 'lộng_hành', 'cuồng_si', 'đa_cấp', 'na_ná', 'why', 'nhắng_nhít', 'hệ', 'mặt_trời', 'tay_lái', 'trốn_tránh', 'đèn_đỏ', 'căm_thù', 'họng', 'lu_mờ', 'không_gian', 'ngập', 'thình_thịch', 'tàu_nhanh', 'clone', 'luộc', 'zombie', 'xúc_động', 'võ_công', 'đùng', 'nguy_hại', 'nghiêp', 'anh_minh', 'định_kiến', 'khắc_nghiệt', 'quẩn', 'tuyên_bố', 'ngơ', 'ju', 'jin', 'thân_thể', 'rán', 'có_khi', 'thu_hút', 'lóc', 'tắm_rửa', 'bản_gốc', 'bản_sao', 'nhè', 'nhường_nhịn', 'bòn_bon', 'good', 'doctor', 'chị_gái', 'nhật_ký', 'hũ', 'mắm_tép', 'and', 'đii', 'kinh_tởm', 'soái', 'cug', 'mây', 'nhè_nhẹ', 'hiu_hiu', 'bthg', 'đồng_chí', 'giã', 'rần_rần', 'tv', 'đồng_nghĩa', 'ghim', 'yên_bình', 'đáp_số', 'khoanh', 'sự_cố', 'kỷ_luật', 'vây', 'bằng_không', 'dong', 'mưu_mô', 'xảo_quyệt', 'vượt', 'sạc', 'sến', 'súa', 'cầu_kì', 'ô_nhục', 'ngon_ăn', 'hịu', 'sửu', 'nhi', 'couple', 'tần', 'lệnh', 'tạm', 'công_bố', 'léo_nhéo', 'hoạt_hình', 'xới', 'khét_lẹt', 'rún', 'kéo_lại', 'bằng_lòng', 'trg', 'vks', 'tận_tâm', 'tờ_rơi', 'skin', 'yasuo', 'bàn_luận', 'dữ_dội', 'vạy', 'xù', 'nhạo', 'đoan', 'nếu_như', 'nếm', 'đại_cao_thủ', 'xe_bò', 'mả', 'quây', 'cuộc_chơi', 'miss', 'mù_quáng', 'giao_phối', 'quẩy', 'viêm', 'màn', 'danh_hài', 'topic', 'anh_trai', 'khám_phá', 'bằng_cấp', 'ăn_tiêu', 'lu', 'miên', 'nl', 'lon', 'hoang_đường', 'cô_giáo_chủ_nhiệm', 'tráo_trở', 'thương_xót', 'zị', 'phạm_tội', 'ẩn', 'mũm_mĩm', 'dzậy', 'bị_gậy', 'đóng_dấu', 'lõi_đời', 'tạm_thời', 'ru', 'vua', 'phi_hành_gia', 'lăng_loàn', 'yếu_thế', 'khôg', 'tử_tế', 'kinh_hồn', 'đánh_rắm', 'tuổi_tác', 'cử_chỉ', 'tục_tĩu', 'ranh_giới', 'vãn', 'cố_chấp', 'tội_phạm', 'lì', 'úp', 'quánh', 'hết_hơi', 'đỏ_hỏn', 'nghiền', 'hành_lang', 'đường_sắt', 'liệt', 'tự_tử', 'tập_trung', 'giỗ', 'có_lí_do', 'thuyết', 'bầu_trời', 'một_hơi', 'lơ_lửng', 'thì_thầm', 'dượng', 'đứt_ruột', 'nhắm', 'dhs', 'style', 'yếu_tố', 'ph', 'bỏ_mình', 'lốp', 'kịp_thời', 'dưỡng', 'tập_thể', 'thành_viên', 'gvcn', 'vô_lí', 'có_lý', 'đưa_đón', 'hầu', 'đục_khoét', 'duyên_dáng', 'nặng_nề', 'xỉn', 'đầu_vào', 'vừa_mới', 'hqua', 'thực_lực', 'mật_vụ', 'điện_thế', 'thoả', 'để_tâm', 'thự', 'mv', 'phải_biết', 'tâm_thần', 'rắn_rết', 'đại_từ', 'lắc', 'hạ_cánh', 'lổi', 'kỹ_thuật', 'thừng', 'xẻ', 'ngậm_ngùi', 'tạ', 'nghiêm_chỉnh', 'đồ_đạc', 'hẳn_hoi', 'ngạt', 'xu', 'kếch_xù', 'sụp', 'téo', 'đường_thẳng', 'bịp', 'sms', 'cr', 'nhái', 'wtf', 'trỗ', 'của_cải', 'ý_chí', 'chí', 'tiến_thủ', 'quyến_rũ', 'cán', 'every', 'where', 'giằng_xé', 'điển_trai', 'máy_tính', 'húp', 'mới_đó', 'hòi', 'hun', 'nhéo', 'quỳnh', 'xiu', 'tiểu_thuyết', 'quan_niệm', 'hiến', 'chẳng_hạn', 'vui_chơi', 'thì_thôi', 'mua_chuộc', 'eo_ôi', 'rốt_cuộc', 'cồng', 'kền', 'tin_vui', 'bà_con', 'chuân', 'chiện', 'khẩn_cấp', 'hnao', 'nhằng_nhằng', 'khai_phá', 'vững_tâm', 'điều_độ', 'nửa_đêm', 'hò_hét', 'nỗ_lực', 'valentine', 'phượt', 'bữa_nay', 'vô_lăng', 'tỳ', 'mít_ướt', 'trót', 've_sầu', 'xinh_đẹp', 'bán_hoa', 'trổi', 'đẹp_lão', 'giay', 'đời_mới', 'nhập_viện', 'xong_đời', 'nthe', 'gia_công', 'sản_xuất', 'thương_hiệu', 'quốc_gia', 'khát_vọng', 'tua', 'vô_cực', 'gởi', 'phiêu_lưu', 'lạc_lõng', 'tềnh', 'lú', 'gạ', 'nốt_nhạc', 'trung_ương', 'đoi', 'run_rẩy', 'săn_sóc', 'bảo_kê', 'tán_loạn', 'vô_ơn', 'ba_má', 'kê', 'phong_độ', 'ăn_mặc', 'kia_mà', 'đôi_co', 'douma', 'nài_nỉ', 'vừa_rồi', 'ít_ra', 'êm', 're', 'quá_chừng', 'chà_bá', 'nhừ_tử', 'kìm_nén', 'huawei', 'nhân_tài', 'công_trình', 'năm_tuổi', 'không_khéo', 'toe_toét', 'trống_vắng', 'tôn', 'lợp', 'đẹo', 'yêu_quý', 'hiền_thục', 'tâm_tính', 'hiếu_thảo', 'tổ_quốc', 'dê', 'thọt', 'chiến_tích', 'bực_mình', 'ùa', 'vỗ_tay', 'thu_thập', 'trạng_thái', 'thế_kỷ', 'tiêu_tan', 'kĩ_lưỡng', 'tác_phong', 'ruộng', 'lạ_lẫm', 'khởi', 'song_hành', 'nasa', 'kênh', 'bắt_cái', 'nợ_nần', 'chồng_chất', 'đại_lý', 'phất', 'cọ', 'phiên_bản', 'lê', 'nước_mắm', 'ngư', 'súng_ống', 'chét', 'miễn_sao', 'bền_vững', 'gét', 'mất_hút', 'tê_tê', 'như_không', 'đẫy_đà', 'ngon_ngọt', 'chêu', 'khái_niệm', 'hello', 'thực_hiện', 'gian', 'âu', 'chấn_thương', 'xúm', 'hội_đồng', 'tài_nguyên', 'bộ_óc', 'tài_giỏi', 'ngắn_hạn', 'dẫn_dắt', 'giếng', 'huế', 'phẳng_lặng', 'nèo', 'phước', 'chủ_lực', 'bi_đát', 'tâm_sức', 'lòng_dạ', 'sỏi', 'khiếu_nại', 'bao_che', 'hàng_họ', 'nhạt_nhẽo', 'di_sản', 'chứng_tích', 'tích_tụ', 'sâu_lắng', 'ồ_ồ', 'kỷ', 'ngớ_ngẩn', 'rũ', 'chửa', 'ngoc', 'hen', 'chính_hiệu', 'giấc_ngủ', 'anime', 'buff', 'lộn_xộn', 'vô_giá', 'thay_thế', 'hicc', 'ốc', 'bạo', 'chắc_hẳn', 'guitar', 'bây_giờ_đây', 'tài_chính', 'dụng_võ', 'rồi_đây', 'chạm', 'youtuber', 'sảng_khoái', 'lồ', 'quằn', 'thiến', 'bắp_tay', 'hờn', 'polime', 'rụng_rời', 'đếch', 'giải_tán', 'hối_tiếc', 'nhu_nhược', 'mảng', 'tuyên_truyền', 'rủi_ro', 'ăn_cám', 'quen_biết', 'giùm', 'sất', 'mới_phải', 'soạn', 'hạn_hẹp', 'làm_ơn', 'có_tình', 'dân_chơi', 'mặc_niệm', 'vong_linh', 'sân_bay', 'mô', 'ngây', 'xâ', 'mario', 'zồi', 'tú', 'giáo_khoa', 'nâu', 'mừ', 'mưu_sinh', 'chửi_mắng', 'lắng_nghe', 'xấc_xược', 'tỏ_vẻ', 'ta_đây', 'chỉa', 'trym', 'khắm', 'adim', 'mớm', 'công_sở', 'khiếu', 'vui_tươi', 'khích_lệ', 'nhình', 'cảm_tình', 'coffee', 'chong_chóng', 'mượt', 'truyền_thống', 'tác', 'cổ_phần', 'lan', 'nk', 'thé', 'bổn', 'hihihi', 'loat', 'nhẫn_tâm', 'call', 'mất_tích', 'nhân_quả', 'cho_dù', 'kinh_điển', 'siêng', 'miễn_là', 'bảo_tàng', 'hc', 'nghiên_cứu', 'tê_giác', 'chữa', 'truy_nã', 'miến', 'kiêng_nể', 'rình_rập', 'trắc', 'bệnh_tật', 'nhập_nhằng', 'bẩn_thỉu', 'quê_quán', 'group', 'cuộn', 'keo', 'internet', 'ngốc_nghếch', 'cúi', 'sơ_hở', 'rón_rén', 'đớp', 'ngờ_nghệch', 'nấy', 'xã', 'quả_đất', 'nhà_lầu', 'đùn_đẩy', 'li_kì', 'sạt_nghiệp', 'mấu_chốt', 'ứng_dụng', 'hana', 'sát', 'đồng_tính', 'thượng_hạng', 'đục', 'ốm_đau', 'vỏn_vẹn', 'sáng_kiến', 'tiêu_hủy', 'tình_nghĩa', 'than_vãn', 'bon_chen', 'giành', 'con_trẻ', 'đớn_đau', 'đau_buồn', 'khát', 'cườ', 'lệch', 'tươi_cười', 'niềm_nở', 'đầu_thai', 'tháy', 'lo_lắng', 'cng', 'lâu_lắc', 'vừa_ý_nghĩa', 'gắng', 'lan_tỏa', 'masage', 'chạy_điện', 'choáng', 'mề', 'ngọai', 'nưa', 'khế', 'nhà_giáo', 'xoá_sổ', 'toàn_phần', 'cơ_sở', 'tiêm', 'thuốc_độc', 'binh', 'giám', 'tố_cáo', 'thẩm_phán', 'heheh', 'lồng_lộn', 'evn', 'lươn_lẹo', 'ông_tổ', 'đĩ_điếm', 'ỉn', 'chạ', 'tiếng_thế', 'thượt', 'chồi', 'trống_rỗng', 'sao_chép', 'phựt', 'cơ_bản', 'cảnh_tỉnh', 'hiện_nay', 'bỏ_bà', 'bục', 'giảng', 'sểnh', 'tỵ', 'lạm_dụng', 'tách', 'lỏng_lẻo', 'nhỡ', 'đn', 'địa_chỉ', 'treo', 'tiêu_chuẩn', 'tml', 'cất', 'tủi_hổ', 'hình_dạng', 'viết_tay', 'nhài', 'giả_dối', 'guru', 'rủa', 'lẩu', 'ấu', 'mất_giá', 'hợp_tác', 'chiến_lược', 'nam_tính', 'chi_tử', 'ngặt', 'ngăn_cản', 'kịch_liệt', 'ron', 'khích', 'vinh_quang', 'nicholas', 'liang', 'chyện', 'to_đùng', 'năng_lượng', 'chỉnh_hình', 'sườn', 'truất', 'tròn', 'ung_ủng', 'ngẵn', 'rau_má', 'về_vườn', 'hoan', 'hy', 'hả_hê', 'cửa_sổ', 'thõa', 'ghê_gớm', 'l', 'chìa_khoá', 'tự_tin', 'kịp_thời_đại', 'rựa', 'nhất_thiết', 'cầu_đường', 'lan_can', 'cây_cối', 'y_nguyên', 'ngần', 'khuất', 'chs', 'lạp_xưởng', 'buồn_bực', 'căm', 'xuýt', 'tự_động', 'độc_nhất', 'nhị', 'ghẻ', 'tạo_hoá', 'lố_lăng', 'truong', 'hop', 'su', 'lam', 'xua', 'sanh', 'khám', 'đàng', 'thoả_mãn', 'thực_đơn', 'suy_sụp', 'bảo_đảm', 'tiêu_chảy', 'kèm', 'chẳng_lẽ', 'sh', 'ngông_nghênh', 'sĩ', 'lợi', 'note', 'ghi_chú', 'ký_túc_xá', 'gắt_gỏng', 'trong_sáng', 'heee', 'riền', 'áo_quần', 'tóc_tai', 'lủng', 'hàng_rào', 'vê', 'nghiệm', 'lom', 'dom', 'nghe_ngóng', 'buồng_trứng', 'tình_nhân', 'biet', 'tiep', 'mới_đầu', 'hiếm', 'sáp', 'tnao', 'khỏe_mạnh', 'rú', 'lầm_lì', 'mợt', 'ngữ_khí', 'găng_tay', 'lết', 'balo', 'chững_chạc', 'vắng', 'vừa_qua', 'abcxyz', 'vật_lý', 'logic', 'mền', 'pải', 'mạnh_dạn', 'rv', 'bùa', 'ngải', 'nước_miếng', 'nhưnh', 'vương_miện', 'thix', 'ipx', 'ngơ_ngác', 'chết_cha', 'nước_đái', 'gơm', 'xồ', 'kakaka', 'cắp', 'quái_đản', 'găp', 'lơn', 'thất', 'nhảy_múa', 'ngất_xỉu', 'tĩnh', 'sau_cùng', 'trầm_trọng', 'ùi', 'suong', 'bjt', 'đuông', 'dừa', 'đư', 'queo', 'nhan', 'nhỏ_nhoi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjvoCKFAsKEK"
      },
      "source": [
        "# VI.Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oYeHeBL-wqO"
      },
      "source": [
        "def dot_product(x, kernel):\n",
        "\tif K.backend() == 'tensorflow':\n",
        "\t\treturn K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "\telse:\n",
        "\t\treturn K.dot(x, kernel)\n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "\tdef __init__(self,\n",
        "\t\t\t\t W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "\t\t\t\t W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "\t\t\t\t bias=True, **kwargs):\n",
        "\n",
        "\t\tself.supports_masking = True\n",
        "\t\tself.init = initializers.get('glorot_uniform')\n",
        "\n",
        "\t\tself.W_regularizer = regularizers.get(W_regularizer)\n",
        "\t\tself.u_regularizer = regularizers.get(u_regularizer)\n",
        "\t\tself.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "\t\tself.W_constraint = constraints.get(W_constraint)\n",
        "\t\tself.u_constraint = constraints.get(u_constraint)\n",
        "\t\tself.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "\t\tself.bias = bias\n",
        "\t\tsuper(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "\tdef build(self, input_shape):\n",
        "\t\tassert len(input_shape) == 3\n",
        "\n",
        "\t\tself.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "\t\t\t\t\t\t\t\t initializer=self.init,\n",
        "\t\t\t\t\t\t\t\t name='{}_W'.format(self.name),\n",
        "\t\t\t\t\t\t\t\t regularizer=self.W_regularizer,\n",
        "\t\t\t\t\t\t\t\t constraint=self.W_constraint)\n",
        "\t\tif self.bias:\n",
        "\t\t\tself.b = self.add_weight((input_shape[-1],),\n",
        "\t\t\t\t\t\t\t\t\t initializer='zero',\n",
        "\t\t\t\t\t\t\t\t\t name='{}_b'.format(self.name),\n",
        "\t\t\t\t\t\t\t\t\t regularizer=self.b_regularizer,\n",
        "\t\t\t\t\t\t\t\t\t constraint=self.b_constraint)\n",
        "\n",
        "\t\tself.u = self.add_weight((input_shape[-1],),\n",
        "\t\t\t\t\t\t\t\t initializer=self.init,\n",
        "\t\t\t\t\t\t\t\t name='{}_u'.format(self.name),\n",
        "\t\t\t\t\t\t\t\t regularizer=self.u_regularizer,\n",
        "\t\t\t\t\t\t\t\t constraint=self.u_constraint)\n",
        "\n",
        "\t\tsuper(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "\tdef compute_mask(self, input, input_mask=None):\n",
        "\t\t# do not pass the mask to the next layers\n",
        "\t\treturn None\n",
        "\n",
        "\tdef call(self, x, mask=None):\n",
        "\t\tuit = dot_product(x, self.W)\n",
        "\n",
        "\t\tif self.bias:\n",
        "\t\t\tuit += self.b\n",
        "\n",
        "\t\tuit = K.tanh(uit)\n",
        "\t\tait = dot_product(uit, self.u)\n",
        "\n",
        "\t\ta = K.exp(ait)\n",
        "\n",
        "\t\tif mask is not None:\n",
        "\t\t\ta *= K.cast(mask, K.floatx())\n",
        "\t\ta /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "\t\ta = K.expand_dims(a)\n",
        "\t\tweighted_input = x * a\n",
        "\t\t\n",
        "\t\treturn weighted_input\n",
        "\n",
        "\tdef compute_output_shape(self, input_shape):\n",
        "\t\treturn input_shape[0], input_shape[1], input_shape[2]\n",
        "\t\n",
        "class Addition(Layer):\n",
        "\tdef __init__(self, **kwargs):\n",
        "\t\tsuper(Addition, self).__init__(**kwargs)\n",
        "\n",
        "\tdef build(self, input_shape):\n",
        "\t\tself.output_dim = input_shape[-1]\n",
        "\t\tsuper(Addition, self).build(input_shape)\n",
        "\n",
        "\tdef call(self, x):\n",
        "\t\treturn K.sum(x, axis=1)\n",
        "\n",
        "\tdef compute_output_shape(self, input_shape):\n",
        "\t\treturn (input_shape[0], self.output_dim)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrCQ522csUQ0"
      },
      "source": [
        "## 1.Build mode LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b-4SQdfzFQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c51473f-1c4b-49f6-fcfe-84a13e0f20b9"
      },
      "source": [
        "filter_nums = 128\n",
        "def build_model():\n",
        "        inputs  = Input(shape=(maxLength, ), dtype='float64', name='inputs')    \n",
        "        embedding_layer = Embedding(input_vocab_size,EMBEDDING_DIM,weights=[embedding_matrix], input_length=maxLength, trainable=True,name = 'word_emb')(inputs)\n",
        "        embedding_layer = SpatialDropout1D(0.75)(embedding_layer)\n",
        "                \n",
        "              \n",
        "        lstm_feature1 = CuDNNLSTM(filter_nums, return_sequences=True)(embedding_layer)\n",
        "\n",
        "        att1 = AttentionWithContext()(lstm_feature1)\n",
        "        att1 = Addition()(att1)\n",
        "\n",
        "        fc1 = Dropout(0.5)(Dense(256, name = 'dense_1')(att1))\n",
        "        output1 = Dense(len(classes),name=\"output1\", activation='softmax')(fc1)\n",
        "        # define optimizer\n",
        "        model = Model(inputs=inputs, outputs=output1)\n",
        "        tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
        "        model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        history = model.fit(X_train_encode, np.array(y_train_encode), validation_data = (X_val_encode,np.array(y_val_encode)) , batch_size=50, epochs=1000,callbacks=[tensorBoardCallback])\n",
        "        return model\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 5548 samples, validate on 686 samples\n",
            "Epoch 1/1000\n",
            "5548/5548 [==============================] - 2s 387us/step - loss: 1.7754 - acc: 0.2855 - val_loss: 1.6398 - val_acc: 0.3484\n",
            "Epoch 2/1000\n",
            "5548/5548 [==============================] - 2s 291us/step - loss: 1.6744 - acc: 0.3335 - val_loss: 1.4788 - val_acc: 0.4198\n",
            "Epoch 3/1000\n",
            "5548/5548 [==============================] - 2s 291us/step - loss: 1.5730 - acc: 0.3814 - val_loss: 1.4767 - val_acc: 0.4446\n",
            "Epoch 4/1000\n",
            "5548/5548 [==============================] - 2s 295us/step - loss: 1.5100 - acc: 0.4160 - val_loss: 1.3961 - val_acc: 0.4840\n",
            "Epoch 5/1000\n",
            "5548/5548 [==============================] - 2s 292us/step - loss: 1.4500 - acc: 0.4438 - val_loss: 1.3918 - val_acc: 0.4898\n",
            "Epoch 6/1000\n",
            "5548/5548 [==============================] - 2s 295us/step - loss: 1.3982 - acc: 0.4672 - val_loss: 1.3523 - val_acc: 0.5190\n",
            "Epoch 7/1000\n",
            "5548/5548 [==============================] - 2s 294us/step - loss: 1.3720 - acc: 0.4829 - val_loss: 1.3289 - val_acc: 0.4898\n",
            "Epoch 8/1000\n",
            "5548/5548 [==============================] - 2s 292us/step - loss: 1.3371 - acc: 0.4986 - val_loss: 1.3194 - val_acc: 0.5190\n",
            "Epoch 9/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 1.3004 - acc: 0.5072 - val_loss: 1.3556 - val_acc: 0.5219\n",
            "Epoch 10/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 1.2819 - acc: 0.5157 - val_loss: 1.3303 - val_acc: 0.5335\n",
            "Epoch 11/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 1.2463 - acc: 0.5269 - val_loss: 1.3239 - val_acc: 0.5292\n",
            "Epoch 12/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 1.2371 - acc: 0.5314 - val_loss: 1.3538 - val_acc: 0.5087\n",
            "Epoch 13/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 1.1970 - acc: 0.5546 - val_loss: 1.3381 - val_acc: 0.5190\n",
            "Epoch 14/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 1.1820 - acc: 0.5640 - val_loss: 1.2960 - val_acc: 0.5087\n",
            "Epoch 15/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 1.1595 - acc: 0.5606 - val_loss: 1.3127 - val_acc: 0.5277\n",
            "Epoch 16/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 1.1585 - acc: 0.5694 - val_loss: 1.3239 - val_acc: 0.5379\n",
            "Epoch 17/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 1.1172 - acc: 0.5869 - val_loss: 1.3259 - val_acc: 0.5335\n",
            "Epoch 18/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 1.1004 - acc: 0.5955 - val_loss: 1.3310 - val_acc: 0.5233\n",
            "Epoch 19/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 1.0868 - acc: 0.5914 - val_loss: 1.3222 - val_acc: 0.5262\n",
            "Epoch 20/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 1.0712 - acc: 0.6015 - val_loss: 1.3379 - val_acc: 0.5131\n",
            "Epoch 21/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 1.0396 - acc: 0.6112 - val_loss: 1.3550 - val_acc: 0.5190\n",
            "Epoch 22/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 1.0223 - acc: 0.6181 - val_loss: 1.3663 - val_acc: 0.5175\n",
            "Epoch 23/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 1.0075 - acc: 0.6301 - val_loss: 1.3417 - val_acc: 0.5335\n",
            "Epoch 24/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.9680 - acc: 0.6476 - val_loss: 1.3862 - val_acc: 0.5248\n",
            "Epoch 25/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.9821 - acc: 0.6336 - val_loss: 1.3996 - val_acc: 0.5321\n",
            "Epoch 26/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.9683 - acc: 0.6424 - val_loss: 1.4013 - val_acc: 0.5131\n",
            "Epoch 27/1000\n",
            "5548/5548 [==============================] - 2s 295us/step - loss: 0.9305 - acc: 0.6565 - val_loss: 1.4071 - val_acc: 0.5029\n",
            "Epoch 28/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.9231 - acc: 0.6694 - val_loss: 1.4810 - val_acc: 0.5160\n",
            "Epoch 29/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.9073 - acc: 0.6647 - val_loss: 1.4557 - val_acc: 0.5160\n",
            "Epoch 30/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.9047 - acc: 0.6658 - val_loss: 1.4082 - val_acc: 0.5219\n",
            "Epoch 31/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.9036 - acc: 0.6619 - val_loss: 1.4499 - val_acc: 0.5248\n",
            "Epoch 32/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.8853 - acc: 0.6757 - val_loss: 1.4594 - val_acc: 0.5131\n",
            "Epoch 33/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.8731 - acc: 0.6862 - val_loss: 1.4792 - val_acc: 0.5204\n",
            "Epoch 34/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.8584 - acc: 0.6876 - val_loss: 1.4656 - val_acc: 0.5262\n",
            "Epoch 35/1000\n",
            "5548/5548 [==============================] - 2s 294us/step - loss: 0.8451 - acc: 0.6916 - val_loss: 1.4758 - val_acc: 0.5102\n",
            "Epoch 36/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.8516 - acc: 0.6936 - val_loss: 1.5205 - val_acc: 0.5044\n",
            "Epoch 37/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.8237 - acc: 0.7033 - val_loss: 1.5481 - val_acc: 0.5131\n",
            "Epoch 38/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.8223 - acc: 0.6984 - val_loss: 1.5154 - val_acc: 0.5131\n",
            "Epoch 39/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.7915 - acc: 0.7087 - val_loss: 1.5390 - val_acc: 0.5321\n",
            "Epoch 40/1000\n",
            "5548/5548 [==============================] - 2s 293us/step - loss: 0.8120 - acc: 0.6975 - val_loss: 1.5283 - val_acc: 0.5175\n",
            "Epoch 41/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.7970 - acc: 0.7116 - val_loss: 1.5380 - val_acc: 0.5117\n",
            "Epoch 42/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.7700 - acc: 0.7264 - val_loss: 1.4865 - val_acc: 0.5102\n",
            "Epoch 43/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.7887 - acc: 0.7185 - val_loss: 1.4952 - val_acc: 0.5087\n",
            "Epoch 44/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.7773 - acc: 0.7167 - val_loss: 1.5328 - val_acc: 0.5277\n",
            "Epoch 45/1000\n",
            "5548/5548 [==============================] - 2s 292us/step - loss: 0.7609 - acc: 0.7179 - val_loss: 1.4902 - val_acc: 0.5190\n",
            "Epoch 46/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.7345 - acc: 0.7374 - val_loss: 1.5380 - val_acc: 0.5248\n",
            "Epoch 47/1000\n",
            "5548/5548 [==============================] - 2s 294us/step - loss: 0.7319 - acc: 0.7327 - val_loss: 1.4977 - val_acc: 0.5306\n",
            "Epoch 48/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.7199 - acc: 0.7365 - val_loss: 1.5293 - val_acc: 0.5364\n",
            "Epoch 49/1000\n",
            "5548/5548 [==============================] - 2s 295us/step - loss: 0.7370 - acc: 0.7291 - val_loss: 1.5379 - val_acc: 0.5350\n",
            "Epoch 50/1000\n",
            "5548/5548 [==============================] - 2s 294us/step - loss: 0.7317 - acc: 0.7307 - val_loss: 1.5058 - val_acc: 0.5350\n",
            "Epoch 51/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.7240 - acc: 0.7291 - val_loss: 1.5350 - val_acc: 0.5335\n",
            "Epoch 52/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.7027 - acc: 0.7511 - val_loss: 1.5516 - val_acc: 0.5364\n",
            "Epoch 53/1000\n",
            "5548/5548 [==============================] - 2s 294us/step - loss: 0.6976 - acc: 0.7518 - val_loss: 1.6139 - val_acc: 0.5175\n",
            "Epoch 54/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.6935 - acc: 0.7478 - val_loss: 1.5437 - val_acc: 0.5379\n",
            "Epoch 55/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.6904 - acc: 0.7468 - val_loss: 1.5939 - val_acc: 0.5394\n",
            "Epoch 56/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.6806 - acc: 0.7430 - val_loss: 1.6336 - val_acc: 0.5175\n",
            "Epoch 57/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.7028 - acc: 0.7469 - val_loss: 1.5324 - val_acc: 0.5262\n",
            "Epoch 58/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.6713 - acc: 0.7536 - val_loss: 1.5715 - val_acc: 0.5321\n",
            "Epoch 59/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.6676 - acc: 0.7514 - val_loss: 1.5980 - val_acc: 0.5160\n",
            "Epoch 60/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.6671 - acc: 0.7563 - val_loss: 1.5809 - val_acc: 0.5262\n",
            "Epoch 61/1000\n",
            "5548/5548 [==============================] - 2s 295us/step - loss: 0.6680 - acc: 0.7525 - val_loss: 1.6181 - val_acc: 0.5190\n",
            "Epoch 62/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.6532 - acc: 0.7677 - val_loss: 1.5787 - val_acc: 0.5292\n",
            "Epoch 63/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.6619 - acc: 0.7594 - val_loss: 1.6202 - val_acc: 0.5233\n",
            "Epoch 64/1000\n",
            "5548/5548 [==============================] - 2s 295us/step - loss: 0.6401 - acc: 0.7684 - val_loss: 1.6621 - val_acc: 0.5262\n",
            "Epoch 65/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.6232 - acc: 0.7727 - val_loss: 1.6207 - val_acc: 0.5204\n",
            "Epoch 66/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.6263 - acc: 0.7693 - val_loss: 1.6745 - val_acc: 0.5321\n",
            "Epoch 67/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.6128 - acc: 0.7781 - val_loss: 1.6715 - val_acc: 0.5175\n",
            "Epoch 68/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.6284 - acc: 0.7731 - val_loss: 1.6804 - val_acc: 0.5379\n",
            "Epoch 69/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.6144 - acc: 0.7774 - val_loss: 1.6391 - val_acc: 0.5190\n",
            "Epoch 70/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.6095 - acc: 0.7714 - val_loss: 1.7156 - val_acc: 0.5175\n",
            "Epoch 71/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.6097 - acc: 0.7714 - val_loss: 1.7110 - val_acc: 0.5015\n",
            "Epoch 72/1000\n",
            "5548/5548 [==============================] - 2s 295us/step - loss: 0.5835 - acc: 0.7864 - val_loss: 1.7297 - val_acc: 0.5219\n",
            "Epoch 73/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.6017 - acc: 0.7835 - val_loss: 1.7340 - val_acc: 0.5190\n",
            "Epoch 74/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.6002 - acc: 0.7792 - val_loss: 1.7125 - val_acc: 0.5087\n",
            "Epoch 75/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.6103 - acc: 0.7758 - val_loss: 1.7040 - val_acc: 0.5175\n",
            "Epoch 76/1000\n",
            "5548/5548 [==============================] - 2s 294us/step - loss: 0.5866 - acc: 0.7817 - val_loss: 1.7829 - val_acc: 0.5087\n",
            "Epoch 77/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.5775 - acc: 0.7851 - val_loss: 1.7214 - val_acc: 0.5058\n",
            "Epoch 78/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.5769 - acc: 0.7956 - val_loss: 1.6863 - val_acc: 0.5233\n",
            "Epoch 79/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.5626 - acc: 0.7972 - val_loss: 1.7660 - val_acc: 0.5219\n",
            "Epoch 80/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.5850 - acc: 0.7841 - val_loss: 1.7034 - val_acc: 0.5175\n",
            "Epoch 81/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.5759 - acc: 0.7924 - val_loss: 1.6806 - val_acc: 0.5146\n",
            "Epoch 82/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.5600 - acc: 0.7938 - val_loss: 1.7631 - val_acc: 0.5219\n",
            "Epoch 83/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.5511 - acc: 0.7961 - val_loss: 1.8169 - val_acc: 0.5117\n",
            "Epoch 84/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.5523 - acc: 0.7970 - val_loss: 1.7319 - val_acc: 0.5087\n",
            "Epoch 85/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.5387 - acc: 0.8014 - val_loss: 1.8380 - val_acc: 0.5146\n",
            "Epoch 86/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.5636 - acc: 0.7891 - val_loss: 1.8003 - val_acc: 0.5233\n",
            "Epoch 87/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.5394 - acc: 0.8034 - val_loss: 1.8024 - val_acc: 0.5204\n",
            "Epoch 88/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.5264 - acc: 0.8095 - val_loss: 1.7989 - val_acc: 0.5277\n",
            "Epoch 89/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.5283 - acc: 0.8084 - val_loss: 1.8361 - val_acc: 0.5219\n",
            "Epoch 90/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.5216 - acc: 0.8059 - val_loss: 1.8271 - val_acc: 0.5190\n",
            "Epoch 91/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.5267 - acc: 0.8095 - val_loss: 1.8554 - val_acc: 0.5131\n",
            "Epoch 92/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.5107 - acc: 0.8097 - val_loss: 1.9256 - val_acc: 0.5000\n",
            "Epoch 93/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.5200 - acc: 0.8124 - val_loss: 1.8446 - val_acc: 0.5175\n",
            "Epoch 94/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.5133 - acc: 0.8152 - val_loss: 1.8396 - val_acc: 0.5306\n",
            "Epoch 95/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.5237 - acc: 0.8125 - val_loss: 1.8010 - val_acc: 0.5219\n",
            "Epoch 96/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.5242 - acc: 0.8061 - val_loss: 1.8537 - val_acc: 0.5175\n",
            "Epoch 97/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.5066 - acc: 0.8176 - val_loss: 1.9136 - val_acc: 0.5087\n",
            "Epoch 98/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.4991 - acc: 0.8129 - val_loss: 1.9196 - val_acc: 0.5277\n",
            "Epoch 99/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.4944 - acc: 0.8198 - val_loss: 1.9007 - val_acc: 0.5146\n",
            "Epoch 100/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.4973 - acc: 0.8225 - val_loss: 1.8342 - val_acc: 0.4985\n",
            "Epoch 101/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.5064 - acc: 0.8156 - val_loss: 1.7564 - val_acc: 0.5233\n",
            "Epoch 102/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.4851 - acc: 0.8185 - val_loss: 1.8861 - val_acc: 0.5233\n",
            "Epoch 103/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.4883 - acc: 0.8244 - val_loss: 1.8835 - val_acc: 0.5117\n",
            "Epoch 104/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.4827 - acc: 0.8244 - val_loss: 1.9711 - val_acc: 0.4942\n",
            "Epoch 105/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.4659 - acc: 0.8289 - val_loss: 1.9554 - val_acc: 0.5015\n",
            "Epoch 106/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.4792 - acc: 0.8198 - val_loss: 1.9031 - val_acc: 0.4942\n",
            "Epoch 107/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.4802 - acc: 0.8194 - val_loss: 1.9279 - val_acc: 0.4927\n",
            "Epoch 108/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.4759 - acc: 0.8257 - val_loss: 1.8988 - val_acc: 0.5044\n",
            "Epoch 109/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.4701 - acc: 0.8253 - val_loss: 1.8463 - val_acc: 0.5044\n",
            "Epoch 110/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.4591 - acc: 0.8338 - val_loss: 1.9001 - val_acc: 0.5073\n",
            "Epoch 111/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.4614 - acc: 0.8293 - val_loss: 1.9551 - val_acc: 0.5102\n",
            "Epoch 112/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.4371 - acc: 0.8390 - val_loss: 1.9431 - val_acc: 0.5087\n",
            "Epoch 113/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.4577 - acc: 0.8362 - val_loss: 1.9683 - val_acc: 0.5073\n",
            "Epoch 114/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.4822 - acc: 0.8250 - val_loss: 1.8618 - val_acc: 0.5102\n",
            "Epoch 115/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.4464 - acc: 0.8407 - val_loss: 1.8997 - val_acc: 0.5117\n",
            "Epoch 116/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.4301 - acc: 0.8453 - val_loss: 1.9936 - val_acc: 0.5190\n",
            "Epoch 117/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.4381 - acc: 0.8396 - val_loss: 1.9963 - val_acc: 0.5117\n",
            "Epoch 118/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.4517 - acc: 0.8320 - val_loss: 1.9662 - val_acc: 0.5160\n",
            "Epoch 119/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.4391 - acc: 0.8405 - val_loss: 1.9420 - val_acc: 0.5219\n",
            "Epoch 120/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.4380 - acc: 0.8403 - val_loss: 1.9444 - val_acc: 0.5248\n",
            "Epoch 121/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.4370 - acc: 0.8383 - val_loss: 1.9977 - val_acc: 0.5102\n",
            "Epoch 122/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.4187 - acc: 0.8508 - val_loss: 2.0129 - val_acc: 0.5233\n",
            "Epoch 123/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.4257 - acc: 0.8463 - val_loss: 1.9632 - val_acc: 0.5364\n",
            "Epoch 124/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.4404 - acc: 0.8399 - val_loss: 1.9048 - val_acc: 0.5248\n",
            "Epoch 125/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.4194 - acc: 0.8444 - val_loss: 1.9470 - val_acc: 0.5219\n",
            "Epoch 126/1000\n",
            "5548/5548 [==============================] - 2s 296us/step - loss: 0.4479 - acc: 0.8416 - val_loss: 1.9343 - val_acc: 0.5364\n",
            "Epoch 127/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.4260 - acc: 0.8435 - val_loss: 1.9200 - val_acc: 0.5146\n",
            "Epoch 128/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.4199 - acc: 0.8446 - val_loss: 2.0199 - val_acc: 0.5131\n",
            "Epoch 129/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.4174 - acc: 0.8477 - val_loss: 1.8973 - val_acc: 0.4956\n",
            "Epoch 130/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.4147 - acc: 0.8468 - val_loss: 2.0582 - val_acc: 0.5087\n",
            "Epoch 131/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.4199 - acc: 0.8481 - val_loss: 1.9505 - val_acc: 0.5160\n",
            "Epoch 132/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.3957 - acc: 0.8583 - val_loss: 2.0180 - val_acc: 0.5087\n",
            "Epoch 133/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3892 - acc: 0.8522 - val_loss: 2.0592 - val_acc: 0.5117\n",
            "Epoch 134/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.4170 - acc: 0.8482 - val_loss: 1.8878 - val_acc: 0.5044\n",
            "Epoch 135/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.4004 - acc: 0.8531 - val_loss: 2.0177 - val_acc: 0.5117\n",
            "Epoch 136/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.4109 - acc: 0.8538 - val_loss: 2.0260 - val_acc: 0.5073\n",
            "Epoch 137/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.3807 - acc: 0.8589 - val_loss: 2.0417 - val_acc: 0.5146\n",
            "Epoch 138/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3961 - acc: 0.8560 - val_loss: 2.0865 - val_acc: 0.5073\n",
            "Epoch 139/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3943 - acc: 0.8524 - val_loss: 2.1713 - val_acc: 0.5087\n",
            "Epoch 140/1000\n",
            "5548/5548 [==============================] - 2s 297us/step - loss: 0.3912 - acc: 0.8569 - val_loss: 2.0589 - val_acc: 0.5292\n",
            "Epoch 141/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.4010 - acc: 0.8580 - val_loss: 2.0471 - val_acc: 0.5219\n",
            "Epoch 142/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3996 - acc: 0.8513 - val_loss: 2.1454 - val_acc: 0.5160\n",
            "Epoch 143/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.3999 - acc: 0.8562 - val_loss: 2.1260 - val_acc: 0.5248\n",
            "Epoch 144/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.3918 - acc: 0.8574 - val_loss: 2.0979 - val_acc: 0.5248\n",
            "Epoch 145/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.3750 - acc: 0.8619 - val_loss: 2.0975 - val_acc: 0.5160\n",
            "Epoch 146/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3952 - acc: 0.8547 - val_loss: 2.0807 - val_acc: 0.5190\n",
            "Epoch 147/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3498 - acc: 0.8794 - val_loss: 2.2108 - val_acc: 0.5146\n",
            "Epoch 148/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3724 - acc: 0.8623 - val_loss: 2.2566 - val_acc: 0.5087\n",
            "Epoch 149/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.3683 - acc: 0.8672 - val_loss: 2.1301 - val_acc: 0.5248\n",
            "Epoch 150/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.3698 - acc: 0.8675 - val_loss: 2.2080 - val_acc: 0.5175\n",
            "Epoch 151/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.3684 - acc: 0.8686 - val_loss: 2.1904 - val_acc: 0.5190\n",
            "Epoch 152/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3753 - acc: 0.8648 - val_loss: 2.1284 - val_acc: 0.5087\n",
            "Epoch 153/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.3652 - acc: 0.8655 - val_loss: 2.2228 - val_acc: 0.5029\n",
            "Epoch 154/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.3510 - acc: 0.8731 - val_loss: 2.2677 - val_acc: 0.5029\n",
            "Epoch 155/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3663 - acc: 0.8625 - val_loss: 2.2129 - val_acc: 0.5029\n",
            "Epoch 156/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3626 - acc: 0.8699 - val_loss: 2.1710 - val_acc: 0.5044\n",
            "Epoch 157/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3538 - acc: 0.8744 - val_loss: 2.2395 - val_acc: 0.5015\n",
            "Epoch 158/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3530 - acc: 0.8686 - val_loss: 2.2546 - val_acc: 0.5102\n",
            "Epoch 159/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3619 - acc: 0.8718 - val_loss: 2.1938 - val_acc: 0.5190\n",
            "Epoch 160/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.3483 - acc: 0.8735 - val_loss: 2.2108 - val_acc: 0.5073\n",
            "Epoch 161/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3443 - acc: 0.8773 - val_loss: 2.2751 - val_acc: 0.4913\n",
            "Epoch 162/1000\n",
            "5548/5548 [==============================] - 2s 298us/step - loss: 0.3705 - acc: 0.8641 - val_loss: 2.2685 - val_acc: 0.5015\n",
            "Epoch 163/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3465 - acc: 0.8715 - val_loss: 2.2306 - val_acc: 0.5073\n",
            "Epoch 164/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3407 - acc: 0.8764 - val_loss: 2.2362 - val_acc: 0.4956\n",
            "Epoch 165/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3470 - acc: 0.8727 - val_loss: 2.3147 - val_acc: 0.4898\n",
            "Epoch 166/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3360 - acc: 0.8805 - val_loss: 2.1759 - val_acc: 0.5073\n",
            "Epoch 167/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3407 - acc: 0.8756 - val_loss: 2.1988 - val_acc: 0.5029\n",
            "Epoch 168/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3370 - acc: 0.8810 - val_loss: 2.2065 - val_acc: 0.4985\n",
            "Epoch 169/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3371 - acc: 0.8724 - val_loss: 2.2759 - val_acc: 0.5102\n",
            "Epoch 170/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3223 - acc: 0.8832 - val_loss: 2.2834 - val_acc: 0.5000\n",
            "Epoch 171/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3330 - acc: 0.8805 - val_loss: 2.3270 - val_acc: 0.4985\n",
            "Epoch 172/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3271 - acc: 0.8805 - val_loss: 2.2892 - val_acc: 0.5000\n",
            "Epoch 173/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3377 - acc: 0.8704 - val_loss: 2.3027 - val_acc: 0.5117\n",
            "Epoch 174/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3299 - acc: 0.8783 - val_loss: 2.2850 - val_acc: 0.5117\n",
            "Epoch 175/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.3333 - acc: 0.8771 - val_loss: 2.1649 - val_acc: 0.5146\n",
            "Epoch 176/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3301 - acc: 0.8776 - val_loss: 2.3531 - val_acc: 0.5117\n",
            "Epoch 177/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3149 - acc: 0.8866 - val_loss: 2.3245 - val_acc: 0.5175\n",
            "Epoch 178/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3159 - acc: 0.8821 - val_loss: 2.2811 - val_acc: 0.5087\n",
            "Epoch 179/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3121 - acc: 0.8879 - val_loss: 2.3199 - val_acc: 0.5190\n",
            "Epoch 180/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3341 - acc: 0.8774 - val_loss: 2.2182 - val_acc: 0.5175\n",
            "Epoch 181/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3218 - acc: 0.8877 - val_loss: 2.2476 - val_acc: 0.5190\n",
            "Epoch 182/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3003 - acc: 0.8938 - val_loss: 2.3329 - val_acc: 0.5087\n",
            "Epoch 183/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3240 - acc: 0.8825 - val_loss: 2.3075 - val_acc: 0.5058\n",
            "Epoch 184/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.2971 - acc: 0.8906 - val_loss: 2.2670 - val_acc: 0.5044\n",
            "Epoch 185/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3067 - acc: 0.8922 - val_loss: 2.2884 - val_acc: 0.5015\n",
            "Epoch 186/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3218 - acc: 0.8778 - val_loss: 2.2762 - val_acc: 0.5058\n",
            "Epoch 187/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.3101 - acc: 0.8879 - val_loss: 2.3625 - val_acc: 0.5219\n",
            "Epoch 188/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3145 - acc: 0.8882 - val_loss: 2.2816 - val_acc: 0.5029\n",
            "Epoch 189/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3092 - acc: 0.8884 - val_loss: 2.2787 - val_acc: 0.5087\n",
            "Epoch 190/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3039 - acc: 0.8946 - val_loss: 2.3463 - val_acc: 0.5044\n",
            "Epoch 191/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3026 - acc: 0.8884 - val_loss: 2.3098 - val_acc: 0.5044\n",
            "Epoch 192/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.2941 - acc: 0.8938 - val_loss: 2.4218 - val_acc: 0.4985\n",
            "Epoch 193/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.3098 - acc: 0.8881 - val_loss: 2.3954 - val_acc: 0.5015\n",
            "Epoch 194/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.3031 - acc: 0.8913 - val_loss: 2.3761 - val_acc: 0.5000\n",
            "Epoch 195/1000\n",
            "5548/5548 [==============================] - 2s 300us/step - loss: 0.2972 - acc: 0.8919 - val_loss: 2.4241 - val_acc: 0.5073\n",
            "Epoch 196/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.3110 - acc: 0.8866 - val_loss: 2.3908 - val_acc: 0.5102\n",
            "Epoch 197/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3005 - acc: 0.8953 - val_loss: 2.4694 - val_acc: 0.5146\n",
            "Epoch 198/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2889 - acc: 0.8956 - val_loss: 2.3762 - val_acc: 0.5131\n",
            "Epoch 199/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.3030 - acc: 0.8910 - val_loss: 2.3155 - val_acc: 0.5058\n",
            "Epoch 200/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.3099 - acc: 0.8879 - val_loss: 2.3170 - val_acc: 0.5102\n",
            "Epoch 201/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.2816 - acc: 0.8980 - val_loss: 2.2842 - val_acc: 0.5233\n",
            "Epoch 202/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2931 - acc: 0.8933 - val_loss: 2.3007 - val_acc: 0.5175\n",
            "Epoch 203/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2993 - acc: 0.8929 - val_loss: 2.3036 - val_acc: 0.5160\n",
            "Epoch 204/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2890 - acc: 0.9001 - val_loss: 2.2939 - val_acc: 0.4985\n",
            "Epoch 205/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2869 - acc: 0.8985 - val_loss: 2.4010 - val_acc: 0.5044\n",
            "Epoch 206/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2745 - acc: 0.9005 - val_loss: 2.4370 - val_acc: 0.5073\n",
            "Epoch 207/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2940 - acc: 0.8956 - val_loss: 2.3287 - val_acc: 0.5146\n",
            "Epoch 208/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.2947 - acc: 0.8902 - val_loss: 2.4378 - val_acc: 0.4956\n",
            "Epoch 209/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2820 - acc: 0.8964 - val_loss: 2.3463 - val_acc: 0.5160\n",
            "Epoch 210/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.2873 - acc: 0.8976 - val_loss: 2.4477 - val_acc: 0.5044\n",
            "Epoch 211/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2841 - acc: 0.9005 - val_loss: 2.3336 - val_acc: 0.4985\n",
            "Epoch 212/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.2711 - acc: 0.9001 - val_loss: 2.4286 - val_acc: 0.5058\n",
            "Epoch 213/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2890 - acc: 0.8958 - val_loss: 2.4575 - val_acc: 0.5044\n",
            "Epoch 214/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.2869 - acc: 0.8982 - val_loss: 2.3977 - val_acc: 0.5146\n",
            "Epoch 215/1000\n",
            "5548/5548 [==============================] - 2s 299us/step - loss: 0.2631 - acc: 0.9070 - val_loss: 2.4492 - val_acc: 0.5058\n",
            "Epoch 216/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2725 - acc: 0.9000 - val_loss: 2.3627 - val_acc: 0.5117\n",
            "Epoch 217/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.2695 - acc: 0.9018 - val_loss: 2.6149 - val_acc: 0.5117\n",
            "Epoch 218/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.2628 - acc: 0.9041 - val_loss: 2.3314 - val_acc: 0.5044\n",
            "Epoch 219/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2698 - acc: 0.9007 - val_loss: 2.4265 - val_acc: 0.5102\n",
            "Epoch 220/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2674 - acc: 0.9023 - val_loss: 2.4796 - val_acc: 0.5175\n",
            "Epoch 221/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2621 - acc: 0.9050 - val_loss: 2.4415 - val_acc: 0.5015\n",
            "Epoch 222/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2672 - acc: 0.9041 - val_loss: 2.5291 - val_acc: 0.4985\n",
            "Epoch 223/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2727 - acc: 0.9016 - val_loss: 2.4596 - val_acc: 0.5029\n",
            "Epoch 224/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2626 - acc: 0.9063 - val_loss: 2.5139 - val_acc: 0.4971\n",
            "Epoch 225/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.2527 - acc: 0.9093 - val_loss: 2.5779 - val_acc: 0.4942\n",
            "Epoch 226/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2694 - acc: 0.9039 - val_loss: 2.5310 - val_acc: 0.5044\n",
            "Epoch 227/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2562 - acc: 0.9039 - val_loss: 2.5877 - val_acc: 0.5029\n",
            "Epoch 228/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2625 - acc: 0.9056 - val_loss: 2.4634 - val_acc: 0.5058\n",
            "Epoch 229/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.2533 - acc: 0.9095 - val_loss: 2.5779 - val_acc: 0.5087\n",
            "Epoch 230/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2541 - acc: 0.9093 - val_loss: 2.4897 - val_acc: 0.5117\n",
            "Epoch 231/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2570 - acc: 0.9072 - val_loss: 2.4985 - val_acc: 0.5015\n",
            "Epoch 232/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.2531 - acc: 0.9140 - val_loss: 2.5009 - val_acc: 0.5015\n",
            "Epoch 233/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2590 - acc: 0.9050 - val_loss: 2.4139 - val_acc: 0.5015\n",
            "Epoch 234/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2419 - acc: 0.9115 - val_loss: 2.5904 - val_acc: 0.5058\n",
            "Epoch 235/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2583 - acc: 0.9079 - val_loss: 2.4112 - val_acc: 0.5087\n",
            "Epoch 236/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2520 - acc: 0.9086 - val_loss: 2.5478 - val_acc: 0.5146\n",
            "Epoch 237/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.2702 - acc: 0.9056 - val_loss: 2.4306 - val_acc: 0.5233\n",
            "Epoch 238/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.2440 - acc: 0.9169 - val_loss: 2.5841 - val_acc: 0.4956\n",
            "Epoch 239/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2370 - acc: 0.9156 - val_loss: 2.5409 - val_acc: 0.5087\n",
            "Epoch 240/1000\n",
            "5548/5548 [==============================] - 2s 301us/step - loss: 0.2500 - acc: 0.9128 - val_loss: 2.4825 - val_acc: 0.5175\n",
            "Epoch 241/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2414 - acc: 0.9160 - val_loss: 2.5567 - val_acc: 0.5015\n",
            "Epoch 242/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2412 - acc: 0.9113 - val_loss: 2.5827 - val_acc: 0.5117\n",
            "Epoch 243/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2572 - acc: 0.9075 - val_loss: 2.4167 - val_acc: 0.5233\n",
            "Epoch 244/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2343 - acc: 0.9119 - val_loss: 2.6082 - val_acc: 0.5073\n",
            "Epoch 245/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.2508 - acc: 0.9115 - val_loss: 2.5052 - val_acc: 0.5029\n",
            "Epoch 246/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2473 - acc: 0.9164 - val_loss: 2.6108 - val_acc: 0.5000\n",
            "Epoch 247/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2398 - acc: 0.9151 - val_loss: 2.4856 - val_acc: 0.5058\n",
            "Epoch 248/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.2349 - acc: 0.9209 - val_loss: 2.6466 - val_acc: 0.5000\n",
            "Epoch 249/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2359 - acc: 0.9133 - val_loss: 2.6007 - val_acc: 0.5058\n",
            "Epoch 250/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.2349 - acc: 0.9187 - val_loss: 2.5826 - val_acc: 0.5117\n",
            "Epoch 251/1000\n",
            "5548/5548 [==============================] - 2s 303us/step - loss: 0.2200 - acc: 0.9205 - val_loss: 2.6718 - val_acc: 0.5044\n",
            "Epoch 252/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2378 - acc: 0.9113 - val_loss: 2.5767 - val_acc: 0.4942\n",
            "Epoch 253/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.2383 - acc: 0.9144 - val_loss: 2.5968 - val_acc: 0.4971\n",
            "Epoch 254/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2272 - acc: 0.9174 - val_loss: 2.6535 - val_acc: 0.5117\n",
            "Epoch 255/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2310 - acc: 0.9137 - val_loss: 2.5519 - val_acc: 0.5015\n",
            "Epoch 256/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2182 - acc: 0.9220 - val_loss: 2.5885 - val_acc: 0.5131\n",
            "Epoch 257/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2373 - acc: 0.9147 - val_loss: 2.5715 - val_acc: 0.5102\n",
            "Epoch 258/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2379 - acc: 0.9155 - val_loss: 2.6019 - val_acc: 0.4971\n",
            "Epoch 259/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.2338 - acc: 0.9189 - val_loss: 2.6252 - val_acc: 0.5029\n",
            "Epoch 260/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2311 - acc: 0.9180 - val_loss: 2.6622 - val_acc: 0.5015\n",
            "Epoch 261/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2333 - acc: 0.9176 - val_loss: 2.6409 - val_acc: 0.4942\n",
            "Epoch 262/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.2305 - acc: 0.9162 - val_loss: 2.6684 - val_acc: 0.4956\n",
            "Epoch 263/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2277 - acc: 0.9183 - val_loss: 2.6355 - val_acc: 0.5058\n",
            "Epoch 264/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2409 - acc: 0.9142 - val_loss: 2.4859 - val_acc: 0.4942\n",
            "Epoch 265/1000\n",
            "5548/5548 [==============================] - 2s 302us/step - loss: 0.2192 - acc: 0.9202 - val_loss: 2.7293 - val_acc: 0.4942\n",
            "Epoch 266/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2247 - acc: 0.9167 - val_loss: 2.6863 - val_acc: 0.4985\n",
            "Epoch 267/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.2221 - acc: 0.9230 - val_loss: 2.6417 - val_acc: 0.4883\n",
            "Epoch 268/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2173 - acc: 0.9194 - val_loss: 2.6376 - val_acc: 0.5015\n",
            "Epoch 269/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2150 - acc: 0.9214 - val_loss: 2.7364 - val_acc: 0.4840\n",
            "Epoch 270/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.2160 - acc: 0.9209 - val_loss: 2.7143 - val_acc: 0.4927\n",
            "Epoch 271/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2239 - acc: 0.9203 - val_loss: 2.6984 - val_acc: 0.4913\n",
            "Epoch 272/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2186 - acc: 0.9252 - val_loss: 2.6785 - val_acc: 0.5102\n",
            "Epoch 273/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.2088 - acc: 0.9241 - val_loss: 2.7054 - val_acc: 0.5015\n",
            "Epoch 274/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.2146 - acc: 0.9234 - val_loss: 2.7347 - val_acc: 0.4985\n",
            "Epoch 275/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.2203 - acc: 0.9200 - val_loss: 2.6996 - val_acc: 0.4825\n",
            "Epoch 276/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.2103 - acc: 0.9254 - val_loss: 2.8539 - val_acc: 0.4956\n",
            "Epoch 277/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.2133 - acc: 0.9247 - val_loss: 2.7457 - val_acc: 0.5000\n",
            "Epoch 278/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.2228 - acc: 0.9193 - val_loss: 2.7005 - val_acc: 0.4854\n",
            "Epoch 279/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.2109 - acc: 0.9232 - val_loss: 2.7204 - val_acc: 0.4898\n",
            "Epoch 280/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.2124 - acc: 0.9248 - val_loss: 2.5685 - val_acc: 0.4913\n",
            "Epoch 281/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.2081 - acc: 0.9238 - val_loss: 2.6402 - val_acc: 0.4927\n",
            "Epoch 282/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.2100 - acc: 0.9254 - val_loss: 2.7259 - val_acc: 0.4927\n",
            "Epoch 283/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.2062 - acc: 0.9241 - val_loss: 2.8161 - val_acc: 0.4971\n",
            "Epoch 284/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.2066 - acc: 0.9227 - val_loss: 2.6944 - val_acc: 0.4883\n",
            "Epoch 285/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.2042 - acc: 0.9292 - val_loss: 2.8054 - val_acc: 0.5058\n",
            "Epoch 286/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.2076 - acc: 0.9263 - val_loss: 2.7212 - val_acc: 0.4927\n",
            "Epoch 287/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.2012 - acc: 0.9279 - val_loss: 2.7803 - val_acc: 0.4913\n",
            "Epoch 288/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.2090 - acc: 0.9281 - val_loss: 2.6859 - val_acc: 0.4927\n",
            "Epoch 289/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.2057 - acc: 0.9257 - val_loss: 2.6624 - val_acc: 0.5058\n",
            "Epoch 290/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.2157 - acc: 0.9214 - val_loss: 2.6583 - val_acc: 0.4956\n",
            "Epoch 291/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2007 - acc: 0.9292 - val_loss: 2.8246 - val_acc: 0.4869\n",
            "Epoch 292/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2167 - acc: 0.9212 - val_loss: 2.6538 - val_acc: 0.5073\n",
            "Epoch 293/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2131 - acc: 0.9223 - val_loss: 2.8033 - val_acc: 0.4956\n",
            "Epoch 294/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2044 - acc: 0.9270 - val_loss: 2.7410 - val_acc: 0.4985\n",
            "Epoch 295/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.2010 - acc: 0.9297 - val_loss: 2.7374 - val_acc: 0.5087\n",
            "Epoch 296/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1938 - acc: 0.9340 - val_loss: 2.7156 - val_acc: 0.5044\n",
            "Epoch 297/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.1991 - acc: 0.9328 - val_loss: 2.7269 - val_acc: 0.5015\n",
            "Epoch 298/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1972 - acc: 0.9272 - val_loss: 2.7899 - val_acc: 0.4971\n",
            "Epoch 299/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1918 - acc: 0.9317 - val_loss: 2.8279 - val_acc: 0.5015\n",
            "Epoch 300/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1998 - acc: 0.9270 - val_loss: 2.6938 - val_acc: 0.5073\n",
            "Epoch 301/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1961 - acc: 0.9302 - val_loss: 2.8339 - val_acc: 0.4913\n",
            "Epoch 302/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1958 - acc: 0.9322 - val_loss: 2.7488 - val_acc: 0.5058\n",
            "Epoch 303/1000\n",
            "5548/5548 [==============================] - 2s 306us/step - loss: 0.2027 - acc: 0.9293 - val_loss: 2.7087 - val_acc: 0.5073\n",
            "Epoch 304/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.2034 - acc: 0.9306 - val_loss: 2.7617 - val_acc: 0.5102\n",
            "Epoch 305/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.1994 - acc: 0.9283 - val_loss: 2.7639 - val_acc: 0.4956\n",
            "Epoch 306/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1935 - acc: 0.9319 - val_loss: 2.8550 - val_acc: 0.5015\n",
            "Epoch 307/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.2056 - acc: 0.9270 - val_loss: 2.7441 - val_acc: 0.4985\n",
            "Epoch 308/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1961 - acc: 0.9317 - val_loss: 2.8029 - val_acc: 0.4956\n",
            "Epoch 309/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1844 - acc: 0.9358 - val_loss: 2.8258 - val_acc: 0.4927\n",
            "Epoch 310/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1825 - acc: 0.9348 - val_loss: 2.9628 - val_acc: 0.4985\n",
            "Epoch 311/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.2047 - acc: 0.9245 - val_loss: 2.9320 - val_acc: 0.5000\n",
            "Epoch 312/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.1895 - acc: 0.9295 - val_loss: 2.8430 - val_acc: 0.4985\n",
            "Epoch 313/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1866 - acc: 0.9382 - val_loss: 2.8741 - val_acc: 0.4985\n",
            "Epoch 314/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1777 - acc: 0.9364 - val_loss: 2.8197 - val_acc: 0.5015\n",
            "Epoch 315/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1934 - acc: 0.9295 - val_loss: 2.8607 - val_acc: 0.5029\n",
            "Epoch 316/1000\n",
            "5548/5548 [==============================] - 2s 304us/step - loss: 0.1878 - acc: 0.9357 - val_loss: 2.8070 - val_acc: 0.5029\n",
            "Epoch 317/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1837 - acc: 0.9355 - val_loss: 2.8730 - val_acc: 0.4956\n",
            "Epoch 318/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1719 - acc: 0.9369 - val_loss: 2.8816 - val_acc: 0.5029\n",
            "Epoch 319/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1939 - acc: 0.9333 - val_loss: 2.8300 - val_acc: 0.5029\n",
            "Epoch 320/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1923 - acc: 0.9324 - val_loss: 2.8807 - val_acc: 0.5000\n",
            "Epoch 321/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1853 - acc: 0.9306 - val_loss: 2.8250 - val_acc: 0.4971\n",
            "Epoch 322/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1818 - acc: 0.9351 - val_loss: 2.8701 - val_acc: 0.4942\n",
            "Epoch 323/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1879 - acc: 0.9322 - val_loss: 2.9090 - val_acc: 0.4913\n",
            "Epoch 324/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.1865 - acc: 0.9322 - val_loss: 2.8084 - val_acc: 0.5044\n",
            "Epoch 325/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.2069 - acc: 0.9281 - val_loss: 2.7738 - val_acc: 0.4985\n",
            "Epoch 326/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1865 - acc: 0.9340 - val_loss: 2.7715 - val_acc: 0.5102\n",
            "Epoch 327/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1866 - acc: 0.9348 - val_loss: 2.7618 - val_acc: 0.4985\n",
            "Epoch 328/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.1710 - acc: 0.9376 - val_loss: 2.9366 - val_acc: 0.4942\n",
            "Epoch 329/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1834 - acc: 0.9351 - val_loss: 2.8603 - val_acc: 0.4913\n",
            "Epoch 330/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1731 - acc: 0.9393 - val_loss: 2.9166 - val_acc: 0.5000\n",
            "Epoch 331/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1899 - acc: 0.9317 - val_loss: 2.7622 - val_acc: 0.5000\n",
            "Epoch 332/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1865 - acc: 0.9304 - val_loss: 2.9008 - val_acc: 0.4796\n",
            "Epoch 333/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1823 - acc: 0.9337 - val_loss: 2.9275 - val_acc: 0.4927\n",
            "Epoch 334/1000\n",
            "5548/5548 [==============================] - 2s 305us/step - loss: 0.1934 - acc: 0.9288 - val_loss: 2.9242 - val_acc: 0.4898\n",
            "Epoch 335/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.1788 - acc: 0.9351 - val_loss: 2.8805 - val_acc: 0.5073\n",
            "Epoch 336/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1622 - acc: 0.9421 - val_loss: 3.0035 - val_acc: 0.4869\n",
            "Epoch 337/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.1869 - acc: 0.9369 - val_loss: 2.9414 - val_acc: 0.4898\n",
            "Epoch 338/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1741 - acc: 0.9360 - val_loss: 2.8659 - val_acc: 0.4898\n",
            "Epoch 339/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1652 - acc: 0.9400 - val_loss: 2.9442 - val_acc: 0.5058\n",
            "Epoch 340/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.1799 - acc: 0.9344 - val_loss: 2.9297 - val_acc: 0.4927\n",
            "Epoch 341/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1615 - acc: 0.9427 - val_loss: 2.8782 - val_acc: 0.5073\n",
            "Epoch 342/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1596 - acc: 0.9420 - val_loss: 2.9770 - val_acc: 0.5117\n",
            "Epoch 343/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1619 - acc: 0.9432 - val_loss: 2.8901 - val_acc: 0.4956\n",
            "Epoch 344/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.1701 - acc: 0.9402 - val_loss: 3.0045 - val_acc: 0.4942\n",
            "Epoch 345/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1651 - acc: 0.9418 - val_loss: 2.9376 - val_acc: 0.4913\n",
            "Epoch 346/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.1889 - acc: 0.9353 - val_loss: 2.8147 - val_acc: 0.4869\n",
            "Epoch 347/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1801 - acc: 0.9357 - val_loss: 2.8407 - val_acc: 0.4854\n",
            "Epoch 348/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1703 - acc: 0.9391 - val_loss: 2.8846 - val_acc: 0.4927\n",
            "Epoch 349/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1752 - acc: 0.9380 - val_loss: 2.8976 - val_acc: 0.4913\n",
            "Epoch 350/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1639 - acc: 0.9402 - val_loss: 3.0373 - val_acc: 0.4898\n",
            "Epoch 351/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1706 - acc: 0.9414 - val_loss: 2.8587 - val_acc: 0.5000\n",
            "Epoch 352/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.1811 - acc: 0.9339 - val_loss: 2.8965 - val_acc: 0.4942\n",
            "Epoch 353/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1741 - acc: 0.9394 - val_loss: 2.9390 - val_acc: 0.4942\n",
            "Epoch 354/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1733 - acc: 0.9360 - val_loss: 2.8332 - val_acc: 0.4985\n",
            "Epoch 355/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.1626 - acc: 0.9382 - val_loss: 2.9696 - val_acc: 0.4971\n",
            "Epoch 356/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1603 - acc: 0.9402 - val_loss: 2.9911 - val_acc: 0.5015\n",
            "Epoch 357/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1521 - acc: 0.9432 - val_loss: 3.1090 - val_acc: 0.4985\n",
            "Epoch 358/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1665 - acc: 0.9387 - val_loss: 2.8605 - val_acc: 0.5058\n",
            "Epoch 359/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1725 - acc: 0.9360 - val_loss: 2.8975 - val_acc: 0.4942\n",
            "Epoch 360/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1678 - acc: 0.9423 - val_loss: 2.9605 - val_acc: 0.4883\n",
            "Epoch 361/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1675 - acc: 0.9405 - val_loss: 3.0317 - val_acc: 0.4883\n",
            "Epoch 362/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1652 - acc: 0.9432 - val_loss: 2.9890 - val_acc: 0.4956\n",
            "Epoch 363/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1647 - acc: 0.9407 - val_loss: 2.9878 - val_acc: 0.4942\n",
            "Epoch 364/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1650 - acc: 0.9371 - val_loss: 3.0354 - val_acc: 0.4898\n",
            "Epoch 365/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1601 - acc: 0.9468 - val_loss: 3.0589 - val_acc: 0.4825\n",
            "Epoch 366/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1700 - acc: 0.9396 - val_loss: 3.0770 - val_acc: 0.4898\n",
            "Epoch 367/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1662 - acc: 0.9411 - val_loss: 2.9991 - val_acc: 0.4956\n",
            "Epoch 368/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1539 - acc: 0.9441 - val_loss: 2.9971 - val_acc: 0.4883\n",
            "Epoch 369/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1701 - acc: 0.9412 - val_loss: 2.8865 - val_acc: 0.5029\n",
            "Epoch 370/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1510 - acc: 0.9466 - val_loss: 3.0836 - val_acc: 0.5000\n",
            "Epoch 371/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1691 - acc: 0.9387 - val_loss: 3.0357 - val_acc: 0.4985\n",
            "Epoch 372/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1451 - acc: 0.9512 - val_loss: 3.1797 - val_acc: 0.4796\n",
            "Epoch 373/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1549 - acc: 0.9461 - val_loss: 3.0962 - val_acc: 0.4956\n",
            "Epoch 374/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1505 - acc: 0.9436 - val_loss: 3.0172 - val_acc: 0.5015\n",
            "Epoch 375/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1681 - acc: 0.9398 - val_loss: 2.9223 - val_acc: 0.4985\n",
            "Epoch 376/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1551 - acc: 0.9439 - val_loss: 2.9742 - val_acc: 0.4913\n",
            "Epoch 377/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1720 - acc: 0.9366 - val_loss: 2.8885 - val_acc: 0.4840\n",
            "Epoch 378/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1598 - acc: 0.9432 - val_loss: 3.0272 - val_acc: 0.4825\n",
            "Epoch 379/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1591 - acc: 0.9420 - val_loss: 2.9081 - val_acc: 0.4927\n",
            "Epoch 380/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1638 - acc: 0.9443 - val_loss: 2.9763 - val_acc: 0.4971\n",
            "Epoch 381/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1460 - acc: 0.9492 - val_loss: 3.0740 - val_acc: 0.4840\n",
            "Epoch 382/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.1571 - acc: 0.9423 - val_loss: 3.1172 - val_acc: 0.4854\n",
            "Epoch 383/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1588 - acc: 0.9452 - val_loss: 2.9987 - val_acc: 0.4956\n",
            "Epoch 384/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1437 - acc: 0.9468 - val_loss: 3.0393 - val_acc: 0.5000\n",
            "Epoch 385/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1473 - acc: 0.9454 - val_loss: 3.1537 - val_acc: 0.4796\n",
            "Epoch 386/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1439 - acc: 0.9510 - val_loss: 3.0798 - val_acc: 0.4825\n",
            "Epoch 387/1000\n",
            "5548/5548 [==============================] - 2s 307us/step - loss: 0.1583 - acc: 0.9439 - val_loss: 2.9692 - val_acc: 0.4825\n",
            "Epoch 388/1000\n",
            "5548/5548 [==============================] - 2s 308us/step - loss: 0.1545 - acc: 0.9445 - val_loss: 3.0201 - val_acc: 0.4854\n",
            "Epoch 389/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1495 - acc: 0.9506 - val_loss: 2.9536 - val_acc: 0.4971\n",
            "Epoch 390/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1539 - acc: 0.9407 - val_loss: 2.9789 - val_acc: 0.4840\n",
            "Epoch 391/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1455 - acc: 0.9474 - val_loss: 2.9807 - val_acc: 0.4898\n",
            "Epoch 392/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1517 - acc: 0.9454 - val_loss: 3.0428 - val_acc: 0.4971\n",
            "Epoch 393/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1525 - acc: 0.9423 - val_loss: 3.0289 - val_acc: 0.4956\n",
            "Epoch 394/1000\n",
            "5548/5548 [==============================] - 2s 309us/step - loss: 0.1532 - acc: 0.9457 - val_loss: 2.9442 - val_acc: 0.5029\n",
            "Epoch 395/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1506 - acc: 0.9457 - val_loss: 2.9299 - val_acc: 0.4971\n",
            "Epoch 396/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1462 - acc: 0.9486 - val_loss: 3.0633 - val_acc: 0.4985\n",
            "Epoch 397/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1495 - acc: 0.9470 - val_loss: 3.0143 - val_acc: 0.4942\n",
            "Epoch 398/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1392 - acc: 0.9510 - val_loss: 3.1415 - val_acc: 0.4971\n",
            "Epoch 399/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1483 - acc: 0.9452 - val_loss: 3.1485 - val_acc: 0.4854\n",
            "Epoch 400/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1551 - acc: 0.9443 - val_loss: 2.9687 - val_acc: 0.5073\n",
            "Epoch 401/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1501 - acc: 0.9474 - val_loss: 3.0674 - val_acc: 0.4971\n",
            "Epoch 402/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1451 - acc: 0.9481 - val_loss: 3.0987 - val_acc: 0.5044\n",
            "Epoch 403/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1388 - acc: 0.9504 - val_loss: 3.0967 - val_acc: 0.4927\n",
            "Epoch 404/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1561 - acc: 0.9465 - val_loss: 3.0100 - val_acc: 0.4825\n",
            "Epoch 405/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1438 - acc: 0.9506 - val_loss: 2.9744 - val_acc: 0.4913\n",
            "Epoch 406/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1460 - acc: 0.9504 - val_loss: 3.0464 - val_acc: 0.4942\n",
            "Epoch 407/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1392 - acc: 0.9492 - val_loss: 3.1068 - val_acc: 0.4927\n",
            "Epoch 408/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1442 - acc: 0.9474 - val_loss: 2.9978 - val_acc: 0.4898\n",
            "Epoch 409/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1461 - acc: 0.9508 - val_loss: 2.9668 - val_acc: 0.4942\n",
            "Epoch 410/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1513 - acc: 0.9481 - val_loss: 3.0122 - val_acc: 0.4898\n",
            "Epoch 411/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1457 - acc: 0.9474 - val_loss: 3.1067 - val_acc: 0.4810\n",
            "Epoch 412/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1442 - acc: 0.9486 - val_loss: 3.0703 - val_acc: 0.4825\n",
            "Epoch 413/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1394 - acc: 0.9513 - val_loss: 3.0978 - val_acc: 0.4913\n",
            "Epoch 414/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1459 - acc: 0.9497 - val_loss: 3.1373 - val_acc: 0.5000\n",
            "Epoch 415/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1347 - acc: 0.9504 - val_loss: 3.0519 - val_acc: 0.4942\n",
            "Epoch 416/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1427 - acc: 0.9492 - val_loss: 2.9399 - val_acc: 0.5000\n",
            "Epoch 417/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1365 - acc: 0.9535 - val_loss: 3.0480 - val_acc: 0.4898\n",
            "Epoch 418/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1472 - acc: 0.9472 - val_loss: 2.9442 - val_acc: 0.4985\n",
            "Epoch 419/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1407 - acc: 0.9492 - val_loss: 2.9392 - val_acc: 0.5044\n",
            "Epoch 420/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1275 - acc: 0.9551 - val_loss: 3.1037 - val_acc: 0.4854\n",
            "Epoch 421/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1511 - acc: 0.9486 - val_loss: 2.9979 - val_acc: 0.4985\n",
            "Epoch 422/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1369 - acc: 0.9530 - val_loss: 3.1518 - val_acc: 0.4883\n",
            "Epoch 423/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1412 - acc: 0.9495 - val_loss: 3.0839 - val_acc: 0.4985\n",
            "Epoch 424/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1272 - acc: 0.9542 - val_loss: 3.1929 - val_acc: 0.4985\n",
            "Epoch 425/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1463 - acc: 0.9492 - val_loss: 3.0442 - val_acc: 0.5015\n",
            "Epoch 426/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1253 - acc: 0.9560 - val_loss: 3.0445 - val_acc: 0.5102\n",
            "Epoch 427/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1378 - acc: 0.9512 - val_loss: 3.0586 - val_acc: 0.5029\n",
            "Epoch 428/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1266 - acc: 0.9573 - val_loss: 3.1306 - val_acc: 0.5015\n",
            "Epoch 429/1000\n",
            "5548/5548 [==============================] - 2s 311us/step - loss: 0.1338 - acc: 0.9533 - val_loss: 3.1698 - val_acc: 0.4913\n",
            "Epoch 430/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1394 - acc: 0.9519 - val_loss: 3.1908 - val_acc: 0.5044\n",
            "Epoch 431/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1326 - acc: 0.9531 - val_loss: 3.0992 - val_acc: 0.4971\n",
            "Epoch 432/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1387 - acc: 0.9497 - val_loss: 3.2080 - val_acc: 0.4971\n",
            "Epoch 433/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1314 - acc: 0.9522 - val_loss: 3.1214 - val_acc: 0.5000\n",
            "Epoch 434/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1334 - acc: 0.9521 - val_loss: 3.0952 - val_acc: 0.5044\n",
            "Epoch 435/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1296 - acc: 0.9540 - val_loss: 3.0934 - val_acc: 0.4985\n",
            "Epoch 436/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1330 - acc: 0.9517 - val_loss: 3.1163 - val_acc: 0.4883\n",
            "Epoch 437/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1421 - acc: 0.9508 - val_loss: 3.1912 - val_acc: 0.5000\n",
            "Epoch 438/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1409 - acc: 0.9497 - val_loss: 3.0711 - val_acc: 0.5000\n",
            "Epoch 439/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1328 - acc: 0.9551 - val_loss: 3.1193 - val_acc: 0.5000\n",
            "Epoch 440/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1436 - acc: 0.9461 - val_loss: 3.0454 - val_acc: 0.4898\n",
            "Epoch 441/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1348 - acc: 0.9526 - val_loss: 3.0528 - val_acc: 0.5044\n",
            "Epoch 442/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1175 - acc: 0.9573 - val_loss: 3.3200 - val_acc: 0.4985\n",
            "Epoch 443/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1332 - acc: 0.9537 - val_loss: 3.2603 - val_acc: 0.4913\n",
            "Epoch 444/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1387 - acc: 0.9522 - val_loss: 3.1814 - val_acc: 0.4883\n",
            "Epoch 445/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1425 - acc: 0.9533 - val_loss: 3.1487 - val_acc: 0.5044\n",
            "Epoch 446/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1331 - acc: 0.9539 - val_loss: 3.2371 - val_acc: 0.4971\n",
            "Epoch 447/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1261 - acc: 0.9562 - val_loss: 3.0756 - val_acc: 0.5029\n",
            "Epoch 448/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1376 - acc: 0.9515 - val_loss: 3.1204 - val_acc: 0.5044\n",
            "Epoch 449/1000\n",
            "5548/5548 [==============================] - 2s 310us/step - loss: 0.1311 - acc: 0.9580 - val_loss: 3.1172 - val_acc: 0.4985\n",
            "Epoch 450/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1356 - acc: 0.9510 - val_loss: 3.0666 - val_acc: 0.5029\n",
            "Epoch 451/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1276 - acc: 0.9551 - val_loss: 3.1430 - val_acc: 0.4971\n",
            "Epoch 452/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1275 - acc: 0.9546 - val_loss: 3.1545 - val_acc: 0.4985\n",
            "Epoch 453/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1216 - acc: 0.9567 - val_loss: 3.1418 - val_acc: 0.4956\n",
            "Epoch 454/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1297 - acc: 0.9549 - val_loss: 3.1104 - val_acc: 0.4927\n",
            "Epoch 455/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1351 - acc: 0.9512 - val_loss: 3.1854 - val_acc: 0.5015\n",
            "Epoch 456/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1385 - acc: 0.9497 - val_loss: 3.0382 - val_acc: 0.5015\n",
            "Epoch 457/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1309 - acc: 0.9528 - val_loss: 2.9976 - val_acc: 0.5015\n",
            "Epoch 458/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1362 - acc: 0.9526 - val_loss: 3.0783 - val_acc: 0.4913\n",
            "Epoch 459/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1189 - acc: 0.9564 - val_loss: 3.1945 - val_acc: 0.5015\n",
            "Epoch 460/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1163 - acc: 0.9614 - val_loss: 3.1924 - val_acc: 0.5015\n",
            "Epoch 461/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1212 - acc: 0.9575 - val_loss: 3.0708 - val_acc: 0.4985\n",
            "Epoch 462/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1396 - acc: 0.9499 - val_loss: 3.0911 - val_acc: 0.4956\n",
            "Epoch 463/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1317 - acc: 0.9542 - val_loss: 3.1771 - val_acc: 0.4898\n",
            "Epoch 464/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1141 - acc: 0.9605 - val_loss: 3.2525 - val_acc: 0.4913\n",
            "Epoch 465/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1239 - acc: 0.9553 - val_loss: 3.2009 - val_acc: 0.4869\n",
            "Epoch 466/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1276 - acc: 0.9546 - val_loss: 3.3263 - val_acc: 0.4854\n",
            "Epoch 467/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1297 - acc: 0.9548 - val_loss: 3.1900 - val_acc: 0.4956\n",
            "Epoch 468/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1429 - acc: 0.9481 - val_loss: 3.1327 - val_acc: 0.4913\n",
            "Epoch 469/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1162 - acc: 0.9600 - val_loss: 3.2468 - val_acc: 0.4971\n",
            "Epoch 470/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.1345 - acc: 0.9531 - val_loss: 3.1445 - val_acc: 0.4971\n",
            "Epoch 471/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1101 - acc: 0.9600 - val_loss: 3.3045 - val_acc: 0.4913\n",
            "Epoch 472/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1247 - acc: 0.9555 - val_loss: 3.2745 - val_acc: 0.4796\n",
            "Epoch 473/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1177 - acc: 0.9612 - val_loss: 3.2789 - val_acc: 0.4971\n",
            "Epoch 474/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1127 - acc: 0.9580 - val_loss: 3.2661 - val_acc: 0.4854\n",
            "Epoch 475/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1267 - acc: 0.9546 - val_loss: 3.2242 - val_acc: 0.4927\n",
            "Epoch 476/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1293 - acc: 0.9546 - val_loss: 3.2110 - val_acc: 0.4883\n",
            "Epoch 477/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1259 - acc: 0.9573 - val_loss: 3.2750 - val_acc: 0.4781\n",
            "Epoch 478/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1281 - acc: 0.9528 - val_loss: 3.2504 - val_acc: 0.4913\n",
            "Epoch 479/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1299 - acc: 0.9557 - val_loss: 3.1915 - val_acc: 0.4913\n",
            "Epoch 480/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1200 - acc: 0.9602 - val_loss: 3.1927 - val_acc: 0.4913\n",
            "Epoch 481/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1196 - acc: 0.9582 - val_loss: 3.2247 - val_acc: 0.4810\n",
            "Epoch 482/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1236 - acc: 0.9549 - val_loss: 3.1524 - val_acc: 0.4825\n",
            "Epoch 483/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1248 - acc: 0.9535 - val_loss: 3.2934 - val_acc: 0.4883\n",
            "Epoch 484/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1337 - acc: 0.9517 - val_loss: 3.1276 - val_acc: 0.4781\n",
            "Epoch 485/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1231 - acc: 0.9587 - val_loss: 3.1841 - val_acc: 0.4913\n",
            "Epoch 486/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1263 - acc: 0.9546 - val_loss: 3.1816 - val_acc: 0.5058\n",
            "Epoch 487/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1249 - acc: 0.9530 - val_loss: 3.1971 - val_acc: 0.4913\n",
            "Epoch 488/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1328 - acc: 0.9542 - val_loss: 3.1734 - val_acc: 0.4927\n",
            "Epoch 489/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1143 - acc: 0.9582 - val_loss: 3.0514 - val_acc: 0.4985\n",
            "Epoch 490/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1255 - acc: 0.9575 - val_loss: 3.1907 - val_acc: 0.4898\n",
            "Epoch 491/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1139 - acc: 0.9587 - val_loss: 3.3435 - val_acc: 0.4956\n",
            "Epoch 492/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1306 - acc: 0.9539 - val_loss: 3.1642 - val_acc: 0.4898\n",
            "Epoch 493/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1176 - acc: 0.9553 - val_loss: 3.2305 - val_acc: 0.4956\n",
            "Epoch 494/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1196 - acc: 0.9558 - val_loss: 3.2397 - val_acc: 0.4942\n",
            "Epoch 495/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1171 - acc: 0.9587 - val_loss: 3.2006 - val_acc: 0.4985\n",
            "Epoch 496/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1154 - acc: 0.9594 - val_loss: 3.2322 - val_acc: 0.4913\n",
            "Epoch 497/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1043 - acc: 0.9643 - val_loss: 3.4726 - val_acc: 0.4985\n",
            "Epoch 498/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1160 - acc: 0.9602 - val_loss: 3.2724 - val_acc: 0.4971\n",
            "Epoch 499/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.1124 - acc: 0.9609 - val_loss: 3.4261 - val_acc: 0.5087\n",
            "Epoch 500/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1143 - acc: 0.9611 - val_loss: 3.3697 - val_acc: 0.5015\n",
            "Epoch 501/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1269 - acc: 0.9560 - val_loss: 3.1538 - val_acc: 0.4869\n",
            "Epoch 502/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1207 - acc: 0.9553 - val_loss: 3.3461 - val_acc: 0.5015\n",
            "Epoch 503/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1231 - acc: 0.9582 - val_loss: 3.2939 - val_acc: 0.5058\n",
            "Epoch 504/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1060 - acc: 0.9609 - val_loss: 3.4178 - val_acc: 0.5102\n",
            "Epoch 505/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1191 - acc: 0.9585 - val_loss: 3.2405 - val_acc: 0.4985\n",
            "Epoch 506/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1090 - acc: 0.9600 - val_loss: 3.3980 - val_acc: 0.4898\n",
            "Epoch 507/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1037 - acc: 0.9643 - val_loss: 3.4048 - val_acc: 0.5000\n",
            "Epoch 508/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1249 - acc: 0.9553 - val_loss: 3.2628 - val_acc: 0.4854\n",
            "Epoch 509/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.1209 - acc: 0.9580 - val_loss: 3.1115 - val_acc: 0.4927\n",
            "Epoch 510/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1085 - acc: 0.9605 - val_loss: 3.3529 - val_acc: 0.4810\n",
            "Epoch 511/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1121 - acc: 0.9629 - val_loss: 3.3616 - val_acc: 0.4869\n",
            "Epoch 512/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1162 - acc: 0.9585 - val_loss: 3.3553 - val_acc: 0.5000\n",
            "Epoch 513/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1066 - acc: 0.9616 - val_loss: 3.3478 - val_acc: 0.4956\n",
            "Epoch 514/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.1182 - acc: 0.9557 - val_loss: 3.3176 - val_acc: 0.5000\n",
            "Epoch 515/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1080 - acc: 0.9593 - val_loss: 3.3653 - val_acc: 0.4971\n",
            "Epoch 516/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1065 - acc: 0.9634 - val_loss: 3.3879 - val_acc: 0.4956\n",
            "Epoch 517/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1113 - acc: 0.9580 - val_loss: 3.4411 - val_acc: 0.4956\n",
            "Epoch 518/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.1175 - acc: 0.9607 - val_loss: 3.2946 - val_acc: 0.5015\n",
            "Epoch 519/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1207 - acc: 0.9578 - val_loss: 3.2592 - val_acc: 0.4927\n",
            "Epoch 520/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0991 - acc: 0.9679 - val_loss: 3.3821 - val_acc: 0.4971\n",
            "Epoch 521/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.1220 - acc: 0.9573 - val_loss: 3.2902 - val_acc: 0.5015\n",
            "Epoch 522/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1183 - acc: 0.9594 - val_loss: 3.3231 - val_acc: 0.4956\n",
            "Epoch 523/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1198 - acc: 0.9564 - val_loss: 3.3478 - val_acc: 0.4985\n",
            "Epoch 524/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1111 - acc: 0.9618 - val_loss: 3.3711 - val_acc: 0.4913\n",
            "Epoch 525/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0967 - acc: 0.9647 - val_loss: 3.3538 - val_acc: 0.5000\n",
            "Epoch 526/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1112 - acc: 0.9609 - val_loss: 3.3195 - val_acc: 0.5044\n",
            "Epoch 527/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.1173 - acc: 0.9560 - val_loss: 3.2867 - val_acc: 0.4985\n",
            "Epoch 528/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1051 - acc: 0.9612 - val_loss: 3.3654 - val_acc: 0.4956\n",
            "Epoch 529/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1057 - acc: 0.9609 - val_loss: 3.4217 - val_acc: 0.4913\n",
            "Epoch 530/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1195 - acc: 0.9567 - val_loss: 3.2752 - val_acc: 0.4971\n",
            "Epoch 531/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1027 - acc: 0.9616 - val_loss: 3.4045 - val_acc: 0.4898\n",
            "Epoch 532/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1085 - acc: 0.9609 - val_loss: 3.2864 - val_acc: 0.5073\n",
            "Epoch 533/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1040 - acc: 0.9625 - val_loss: 3.2734 - val_acc: 0.5029\n",
            "Epoch 534/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0998 - acc: 0.9645 - val_loss: 3.3346 - val_acc: 0.5131\n",
            "Epoch 535/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1120 - acc: 0.9602 - val_loss: 3.3128 - val_acc: 0.5000\n",
            "Epoch 536/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0997 - acc: 0.9667 - val_loss: 3.3586 - val_acc: 0.4956\n",
            "Epoch 537/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0979 - acc: 0.9656 - val_loss: 3.4435 - val_acc: 0.4927\n",
            "Epoch 538/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1053 - acc: 0.9630 - val_loss: 3.4309 - val_acc: 0.5087\n",
            "Epoch 539/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1068 - acc: 0.9605 - val_loss: 3.3910 - val_acc: 0.4913\n",
            "Epoch 540/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1076 - acc: 0.9640 - val_loss: 3.3664 - val_acc: 0.4971\n",
            "Epoch 541/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.1142 - acc: 0.9607 - val_loss: 3.2393 - val_acc: 0.5029\n",
            "Epoch 542/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1119 - acc: 0.9618 - val_loss: 3.2594 - val_acc: 0.5087\n",
            "Epoch 543/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1026 - acc: 0.9643 - val_loss: 3.3289 - val_acc: 0.4985\n",
            "Epoch 544/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1043 - acc: 0.9621 - val_loss: 3.3983 - val_acc: 0.4971\n",
            "Epoch 545/1000\n",
            "5548/5548 [==============================] - 2s 312us/step - loss: 0.0952 - acc: 0.9658 - val_loss: 3.3983 - val_acc: 0.4898\n",
            "Epoch 546/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1035 - acc: 0.9641 - val_loss: 3.1789 - val_acc: 0.4913\n",
            "Epoch 547/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1083 - acc: 0.9621 - val_loss: 3.4287 - val_acc: 0.4883\n",
            "Epoch 548/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1159 - acc: 0.9585 - val_loss: 3.3908 - val_acc: 0.4956\n",
            "Epoch 549/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1104 - acc: 0.9616 - val_loss: 3.4242 - val_acc: 0.4869\n",
            "Epoch 550/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1005 - acc: 0.9656 - val_loss: 3.5835 - val_acc: 0.4927\n",
            "Epoch 551/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1047 - acc: 0.9638 - val_loss: 3.4845 - val_acc: 0.4971\n",
            "Epoch 552/1000\n",
            "5548/5548 [==============================] - 2s 313us/step - loss: 0.1042 - acc: 0.9612 - val_loss: 3.3856 - val_acc: 0.4913\n",
            "Epoch 553/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1100 - acc: 0.9638 - val_loss: 3.3036 - val_acc: 0.4971\n",
            "Epoch 554/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1003 - acc: 0.9636 - val_loss: 3.3770 - val_acc: 0.4898\n",
            "Epoch 555/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1127 - acc: 0.9630 - val_loss: 3.4085 - val_acc: 0.4898\n",
            "Epoch 556/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.1091 - acc: 0.9636 - val_loss: 3.3239 - val_acc: 0.4883\n",
            "Epoch 557/1000\n",
            "5548/5548 [==============================] - 2s 315us/step - loss: 0.1024 - acc: 0.9609 - val_loss: 3.4143 - val_acc: 0.4913\n",
            "Epoch 558/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.1017 - acc: 0.9656 - val_loss: 3.3939 - val_acc: 0.4913\n",
            "Epoch 559/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.1034 - acc: 0.9636 - val_loss: 3.4288 - val_acc: 0.4927\n",
            "Epoch 560/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1116 - acc: 0.9593 - val_loss: 3.2949 - val_acc: 0.4913\n",
            "Epoch 561/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1102 - acc: 0.9627 - val_loss: 3.3163 - val_acc: 0.4927\n",
            "Epoch 562/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0917 - acc: 0.9650 - val_loss: 3.4710 - val_acc: 0.5015\n",
            "Epoch 563/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0964 - acc: 0.9640 - val_loss: 3.4301 - val_acc: 0.4898\n",
            "Epoch 564/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0892 - acc: 0.9676 - val_loss: 3.5394 - val_acc: 0.4840\n",
            "Epoch 565/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.1131 - acc: 0.9623 - val_loss: 3.4017 - val_acc: 0.4840\n",
            "Epoch 566/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.1107 - acc: 0.9612 - val_loss: 3.3494 - val_acc: 0.4913\n",
            "Epoch 567/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1074 - acc: 0.9623 - val_loss: 3.2681 - val_acc: 0.5044\n",
            "Epoch 568/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1102 - acc: 0.9627 - val_loss: 3.3584 - val_acc: 0.5000\n",
            "Epoch 569/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1062 - acc: 0.9627 - val_loss: 3.4543 - val_acc: 0.4942\n",
            "Epoch 570/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.1022 - acc: 0.9629 - val_loss: 3.4113 - val_acc: 0.4913\n",
            "Epoch 571/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.1072 - acc: 0.9625 - val_loss: 3.4643 - val_acc: 0.4985\n",
            "Epoch 572/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1067 - acc: 0.9620 - val_loss: 3.4059 - val_acc: 0.4854\n",
            "Epoch 573/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.1036 - acc: 0.9611 - val_loss: 3.4769 - val_acc: 0.4927\n",
            "Epoch 574/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1076 - acc: 0.9593 - val_loss: 3.4061 - val_acc: 0.4854\n",
            "Epoch 575/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0959 - acc: 0.9663 - val_loss: 3.5566 - val_acc: 0.4854\n",
            "Epoch 576/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0923 - acc: 0.9697 - val_loss: 3.4099 - val_acc: 0.4942\n",
            "Epoch 577/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1000 - acc: 0.9667 - val_loss: 3.3566 - val_acc: 0.4942\n",
            "Epoch 578/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.1075 - acc: 0.9643 - val_loss: 3.3953 - val_acc: 0.4985\n",
            "Epoch 579/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0986 - acc: 0.9656 - val_loss: 3.3823 - val_acc: 0.5000\n",
            "Epoch 580/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1021 - acc: 0.9634 - val_loss: 3.4044 - val_acc: 0.4869\n",
            "Epoch 581/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0998 - acc: 0.9672 - val_loss: 3.5117 - val_acc: 0.4913\n",
            "Epoch 582/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.1093 - acc: 0.9605 - val_loss: 3.4257 - val_acc: 0.5044\n",
            "Epoch 583/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1003 - acc: 0.9620 - val_loss: 3.4731 - val_acc: 0.5000\n",
            "Epoch 584/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.1018 - acc: 0.9658 - val_loss: 3.4138 - val_acc: 0.5073\n",
            "Epoch 585/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0980 - acc: 0.9636 - val_loss: 3.4677 - val_acc: 0.5029\n",
            "Epoch 586/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0948 - acc: 0.9676 - val_loss: 3.3989 - val_acc: 0.5102\n",
            "Epoch 587/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0973 - acc: 0.9670 - val_loss: 3.3680 - val_acc: 0.5117\n",
            "Epoch 588/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0949 - acc: 0.9677 - val_loss: 3.4609 - val_acc: 0.5160\n",
            "Epoch 589/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0927 - acc: 0.9686 - val_loss: 3.3775 - val_acc: 0.5058\n",
            "Epoch 590/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.1073 - acc: 0.9659 - val_loss: 3.3330 - val_acc: 0.5073\n",
            "Epoch 591/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0944 - acc: 0.9690 - val_loss: 3.4226 - val_acc: 0.4883\n",
            "Epoch 592/1000\n",
            "5548/5548 [==============================] - 2s 314us/step - loss: 0.0915 - acc: 0.9681 - val_loss: 3.4513 - val_acc: 0.5000\n",
            "Epoch 593/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.1009 - acc: 0.9672 - val_loss: 3.4472 - val_acc: 0.5058\n",
            "Epoch 594/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0969 - acc: 0.9656 - val_loss: 3.5139 - val_acc: 0.5044\n",
            "Epoch 595/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1037 - acc: 0.9665 - val_loss: 3.3639 - val_acc: 0.5073\n",
            "Epoch 596/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0889 - acc: 0.9697 - val_loss: 3.4932 - val_acc: 0.5044\n",
            "Epoch 597/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0888 - acc: 0.9672 - val_loss: 3.5318 - val_acc: 0.5190\n",
            "Epoch 598/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0874 - acc: 0.9694 - val_loss: 3.5282 - val_acc: 0.5102\n",
            "Epoch 599/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0937 - acc: 0.9681 - val_loss: 3.4736 - val_acc: 0.5073\n",
            "Epoch 600/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.1026 - acc: 0.9658 - val_loss: 3.3231 - val_acc: 0.5029\n",
            "Epoch 601/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0919 - acc: 0.9683 - val_loss: 3.4653 - val_acc: 0.4971\n",
            "Epoch 602/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0954 - acc: 0.9672 - val_loss: 3.5536 - val_acc: 0.5000\n",
            "Epoch 603/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0992 - acc: 0.9676 - val_loss: 3.5197 - val_acc: 0.5015\n",
            "Epoch 604/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0989 - acc: 0.9654 - val_loss: 3.5136 - val_acc: 0.4985\n",
            "Epoch 605/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0917 - acc: 0.9694 - val_loss: 3.4190 - val_acc: 0.5044\n",
            "Epoch 606/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0900 - acc: 0.9695 - val_loss: 3.5199 - val_acc: 0.5029\n",
            "Epoch 607/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0980 - acc: 0.9661 - val_loss: 3.3634 - val_acc: 0.5000\n",
            "Epoch 608/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0944 - acc: 0.9681 - val_loss: 3.3575 - val_acc: 0.5044\n",
            "Epoch 609/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0985 - acc: 0.9647 - val_loss: 3.4860 - val_acc: 0.5029\n",
            "Epoch 610/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0944 - acc: 0.9686 - val_loss: 3.5367 - val_acc: 0.5058\n",
            "Epoch 611/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0883 - acc: 0.9703 - val_loss: 3.5028 - val_acc: 0.5000\n",
            "Epoch 612/1000\n",
            "5548/5548 [==============================] - 2s 316us/step - loss: 0.0894 - acc: 0.9677 - val_loss: 3.5424 - val_acc: 0.4942\n",
            "Epoch 613/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0941 - acc: 0.9676 - val_loss: 3.4762 - val_acc: 0.5044\n",
            "Epoch 614/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0987 - acc: 0.9670 - val_loss: 3.4363 - val_acc: 0.5000\n",
            "Epoch 615/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.1004 - acc: 0.9649 - val_loss: 3.4067 - val_acc: 0.5015\n",
            "Epoch 616/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.1058 - acc: 0.9618 - val_loss: 3.4490 - val_acc: 0.5029\n",
            "Epoch 617/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0841 - acc: 0.9695 - val_loss: 3.5233 - val_acc: 0.5029\n",
            "Epoch 618/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0877 - acc: 0.9708 - val_loss: 3.4988 - val_acc: 0.4971\n",
            "Epoch 619/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0935 - acc: 0.9672 - val_loss: 3.4522 - val_acc: 0.5117\n",
            "Epoch 620/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0961 - acc: 0.9643 - val_loss: 3.6129 - val_acc: 0.5000\n",
            "Epoch 621/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0842 - acc: 0.9674 - val_loss: 3.6676 - val_acc: 0.4985\n",
            "Epoch 622/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0881 - acc: 0.9692 - val_loss: 3.6244 - val_acc: 0.5000\n",
            "Epoch 623/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0880 - acc: 0.9686 - val_loss: 3.6861 - val_acc: 0.4985\n",
            "Epoch 624/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.1032 - acc: 0.9667 - val_loss: 3.3562 - val_acc: 0.5029\n",
            "Epoch 625/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0857 - acc: 0.9697 - val_loss: 3.5608 - val_acc: 0.5029\n",
            "Epoch 626/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0939 - acc: 0.9674 - val_loss: 3.5538 - val_acc: 0.4971\n",
            "Epoch 627/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0943 - acc: 0.9697 - val_loss: 3.4543 - val_acc: 0.5015\n",
            "Epoch 628/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0910 - acc: 0.9676 - val_loss: 3.5323 - val_acc: 0.4927\n",
            "Epoch 629/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0905 - acc: 0.9699 - val_loss: 3.5507 - val_acc: 0.4927\n",
            "Epoch 630/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0852 - acc: 0.9697 - val_loss: 3.5152 - val_acc: 0.4927\n",
            "Epoch 631/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0921 - acc: 0.9677 - val_loss: 3.5181 - val_acc: 0.4956\n",
            "Epoch 632/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0928 - acc: 0.9699 - val_loss: 3.5034 - val_acc: 0.4913\n",
            "Epoch 633/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0908 - acc: 0.9699 - val_loss: 3.5134 - val_acc: 0.4810\n",
            "Epoch 634/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0898 - acc: 0.9688 - val_loss: 3.5386 - val_acc: 0.4927\n",
            "Epoch 635/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0885 - acc: 0.9692 - val_loss: 3.5502 - val_acc: 0.4985\n",
            "Epoch 636/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.1007 - acc: 0.9616 - val_loss: 3.5030 - val_acc: 0.5044\n",
            "Epoch 637/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.1009 - acc: 0.9645 - val_loss: 3.5204 - val_acc: 0.4913\n",
            "Epoch 638/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0827 - acc: 0.9724 - val_loss: 3.6120 - val_acc: 0.4956\n",
            "Epoch 639/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0892 - acc: 0.9681 - val_loss: 3.5212 - val_acc: 0.5058\n",
            "Epoch 640/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0952 - acc: 0.9685 - val_loss: 3.4862 - val_acc: 0.4927\n",
            "Epoch 641/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0928 - acc: 0.9688 - val_loss: 3.4387 - val_acc: 0.5160\n",
            "Epoch 642/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0912 - acc: 0.9690 - val_loss: 3.5356 - val_acc: 0.5015\n",
            "Epoch 643/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0926 - acc: 0.9681 - val_loss: 3.4654 - val_acc: 0.5029\n",
            "Epoch 644/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0926 - acc: 0.9670 - val_loss: 3.4493 - val_acc: 0.4985\n",
            "Epoch 645/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0891 - acc: 0.9697 - val_loss: 3.5819 - val_acc: 0.5000\n",
            "Epoch 646/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0944 - acc: 0.9679 - val_loss: 3.3809 - val_acc: 0.5044\n",
            "Epoch 647/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0947 - acc: 0.9663 - val_loss: 3.4969 - val_acc: 0.5029\n",
            "Epoch 648/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0998 - acc: 0.9643 - val_loss: 3.4552 - val_acc: 0.5073\n",
            "Epoch 649/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0938 - acc: 0.9685 - val_loss: 3.4780 - val_acc: 0.5117\n",
            "Epoch 650/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0871 - acc: 0.9726 - val_loss: 3.4108 - val_acc: 0.5058\n",
            "Epoch 651/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0932 - acc: 0.9690 - val_loss: 3.4284 - val_acc: 0.4971\n",
            "Epoch 652/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0835 - acc: 0.9733 - val_loss: 3.4600 - val_acc: 0.4971\n",
            "Epoch 653/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0978 - acc: 0.9677 - val_loss: 3.5766 - val_acc: 0.4942\n",
            "Epoch 654/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0985 - acc: 0.9683 - val_loss: 3.4563 - val_acc: 0.5029\n",
            "Epoch 655/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0932 - acc: 0.9676 - val_loss: 3.5844 - val_acc: 0.5000\n",
            "Epoch 656/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0905 - acc: 0.9710 - val_loss: 3.5053 - val_acc: 0.4942\n",
            "Epoch 657/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0814 - acc: 0.9690 - val_loss: 3.5775 - val_acc: 0.4927\n",
            "Epoch 658/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0861 - acc: 0.9703 - val_loss: 3.4052 - val_acc: 0.5058\n",
            "Epoch 659/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0877 - acc: 0.9728 - val_loss: 3.5093 - val_acc: 0.4883\n",
            "Epoch 660/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0857 - acc: 0.9717 - val_loss: 3.4768 - val_acc: 0.5000\n",
            "Epoch 661/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0953 - acc: 0.9663 - val_loss: 3.3787 - val_acc: 0.5015\n",
            "Epoch 662/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0891 - acc: 0.9694 - val_loss: 3.5077 - val_acc: 0.4942\n",
            "Epoch 663/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0970 - acc: 0.9659 - val_loss: 3.3346 - val_acc: 0.4956\n",
            "Epoch 664/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0821 - acc: 0.9703 - val_loss: 3.5151 - val_acc: 0.4942\n",
            "Epoch 665/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0845 - acc: 0.9699 - val_loss: 3.6421 - val_acc: 0.4956\n",
            "Epoch 666/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0974 - acc: 0.9665 - val_loss: 3.4074 - val_acc: 0.4956\n",
            "Epoch 667/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0808 - acc: 0.9724 - val_loss: 3.5486 - val_acc: 0.4898\n",
            "Epoch 668/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0876 - acc: 0.9710 - val_loss: 3.5709 - val_acc: 0.5058\n",
            "Epoch 669/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0906 - acc: 0.9690 - val_loss: 3.4024 - val_acc: 0.5000\n",
            "Epoch 670/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0885 - acc: 0.9713 - val_loss: 3.5267 - val_acc: 0.5000\n",
            "Epoch 671/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0841 - acc: 0.9742 - val_loss: 3.5422 - val_acc: 0.5087\n",
            "Epoch 672/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0897 - acc: 0.9699 - val_loss: 3.4841 - val_acc: 0.5029\n",
            "Epoch 673/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0830 - acc: 0.9695 - val_loss: 3.5504 - val_acc: 0.5131\n",
            "Epoch 674/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0822 - acc: 0.9731 - val_loss: 3.5304 - val_acc: 0.5058\n",
            "Epoch 675/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0752 - acc: 0.9746 - val_loss: 3.4604 - val_acc: 0.5073\n",
            "Epoch 676/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0818 - acc: 0.9694 - val_loss: 3.7525 - val_acc: 0.5073\n",
            "Epoch 677/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0832 - acc: 0.9699 - val_loss: 3.5583 - val_acc: 0.5160\n",
            "Epoch 678/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0802 - acc: 0.9706 - val_loss: 3.6724 - val_acc: 0.5146\n",
            "Epoch 679/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0817 - acc: 0.9688 - val_loss: 3.6531 - val_acc: 0.5204\n",
            "Epoch 680/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0761 - acc: 0.9728 - val_loss: 3.7303 - val_acc: 0.5131\n",
            "Epoch 681/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0945 - acc: 0.9670 - val_loss: 3.5376 - val_acc: 0.5233\n",
            "Epoch 682/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0771 - acc: 0.9712 - val_loss: 3.6723 - val_acc: 0.5131\n",
            "Epoch 683/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0843 - acc: 0.9728 - val_loss: 3.5451 - val_acc: 0.5087\n",
            "Epoch 684/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0796 - acc: 0.9740 - val_loss: 3.5669 - val_acc: 0.5058\n",
            "Epoch 685/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0853 - acc: 0.9699 - val_loss: 3.5508 - val_acc: 0.5175\n",
            "Epoch 686/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0873 - acc: 0.9692 - val_loss: 3.6395 - val_acc: 0.5146\n",
            "Epoch 687/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0857 - acc: 0.9701 - val_loss: 3.5506 - val_acc: 0.5087\n",
            "Epoch 688/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0888 - acc: 0.9697 - val_loss: 3.5715 - val_acc: 0.5087\n",
            "Epoch 689/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0846 - acc: 0.9730 - val_loss: 3.4475 - val_acc: 0.5175\n",
            "Epoch 690/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0843 - acc: 0.9704 - val_loss: 3.4938 - val_acc: 0.5248\n",
            "Epoch 691/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0878 - acc: 0.9712 - val_loss: 3.4194 - val_acc: 0.5029\n",
            "Epoch 692/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0863 - acc: 0.9713 - val_loss: 3.5340 - val_acc: 0.5262\n",
            "Epoch 693/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0835 - acc: 0.9699 - val_loss: 3.5207 - val_acc: 0.5029\n",
            "Epoch 694/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0796 - acc: 0.9704 - val_loss: 3.4298 - val_acc: 0.5058\n",
            "Epoch 695/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0899 - acc: 0.9685 - val_loss: 3.5832 - val_acc: 0.5000\n",
            "Epoch 696/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0931 - acc: 0.9685 - val_loss: 3.3958 - val_acc: 0.5117\n",
            "Epoch 697/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0894 - acc: 0.9688 - val_loss: 3.4747 - val_acc: 0.5117\n",
            "Epoch 698/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0813 - acc: 0.9722 - val_loss: 3.5352 - val_acc: 0.5087\n",
            "Epoch 699/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0874 - acc: 0.9706 - val_loss: 3.5741 - val_acc: 0.5087\n",
            "Epoch 700/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0834 - acc: 0.9713 - val_loss: 3.5017 - val_acc: 0.5087\n",
            "Epoch 701/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0936 - acc: 0.9685 - val_loss: 3.4885 - val_acc: 0.5087\n",
            "Epoch 702/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0844 - acc: 0.9685 - val_loss: 3.5866 - val_acc: 0.5117\n",
            "Epoch 703/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0838 - acc: 0.9717 - val_loss: 3.6091 - val_acc: 0.5175\n",
            "Epoch 704/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0820 - acc: 0.9710 - val_loss: 3.5347 - val_acc: 0.5146\n",
            "Epoch 705/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0824 - acc: 0.9708 - val_loss: 3.5055 - val_acc: 0.5073\n",
            "Epoch 706/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0870 - acc: 0.9706 - val_loss: 3.4595 - val_acc: 0.5073\n",
            "Epoch 707/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0772 - acc: 0.9742 - val_loss: 3.4671 - val_acc: 0.5044\n",
            "Epoch 708/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0778 - acc: 0.9730 - val_loss: 3.6896 - val_acc: 0.4956\n",
            "Epoch 709/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0893 - acc: 0.9715 - val_loss: 3.4690 - val_acc: 0.5073\n",
            "Epoch 710/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0647 - acc: 0.9769 - val_loss: 3.6518 - val_acc: 0.5160\n",
            "Epoch 711/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0825 - acc: 0.9721 - val_loss: 3.6033 - val_acc: 0.5233\n",
            "Epoch 712/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0721 - acc: 0.9748 - val_loss: 3.6484 - val_acc: 0.5204\n",
            "Epoch 713/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0820 - acc: 0.9721 - val_loss: 3.6957 - val_acc: 0.5029\n",
            "Epoch 714/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0787 - acc: 0.9730 - val_loss: 3.6554 - val_acc: 0.5102\n",
            "Epoch 715/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0828 - acc: 0.9740 - val_loss: 3.5519 - val_acc: 0.5058\n",
            "Epoch 716/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0872 - acc: 0.9710 - val_loss: 3.6708 - val_acc: 0.5015\n",
            "Epoch 717/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0869 - acc: 0.9719 - val_loss: 3.5850 - val_acc: 0.5117\n",
            "Epoch 718/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0764 - acc: 0.9724 - val_loss: 3.7680 - val_acc: 0.4971\n",
            "Epoch 719/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0830 - acc: 0.9726 - val_loss: 3.6192 - val_acc: 0.4942\n",
            "Epoch 720/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0825 - acc: 0.9730 - val_loss: 3.5861 - val_acc: 0.5015\n",
            "Epoch 721/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0702 - acc: 0.9760 - val_loss: 3.7928 - val_acc: 0.4942\n",
            "Epoch 722/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0812 - acc: 0.9722 - val_loss: 3.6705 - val_acc: 0.4956\n",
            "Epoch 723/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0821 - acc: 0.9710 - val_loss: 3.6302 - val_acc: 0.5073\n",
            "Epoch 724/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0806 - acc: 0.9697 - val_loss: 3.6207 - val_acc: 0.4985\n",
            "Epoch 725/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0789 - acc: 0.9722 - val_loss: 3.5440 - val_acc: 0.5087\n",
            "Epoch 726/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0796 - acc: 0.9715 - val_loss: 3.6454 - val_acc: 0.4971\n",
            "Epoch 727/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0702 - acc: 0.9749 - val_loss: 3.7190 - val_acc: 0.4840\n",
            "Epoch 728/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0745 - acc: 0.9710 - val_loss: 3.7489 - val_acc: 0.5015\n",
            "Epoch 729/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0969 - acc: 0.9677 - val_loss: 3.6749 - val_acc: 0.5015\n",
            "Epoch 730/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0722 - acc: 0.9758 - val_loss: 3.8181 - val_acc: 0.5015\n",
            "Epoch 731/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0927 - acc: 0.9685 - val_loss: 3.6729 - val_acc: 0.4971\n",
            "Epoch 732/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0787 - acc: 0.9733 - val_loss: 3.7257 - val_acc: 0.4869\n",
            "Epoch 733/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0823 - acc: 0.9742 - val_loss: 3.7526 - val_acc: 0.4913\n",
            "Epoch 734/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0890 - acc: 0.9710 - val_loss: 3.6967 - val_acc: 0.4971\n",
            "Epoch 735/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0769 - acc: 0.9742 - val_loss: 3.6358 - val_acc: 0.4913\n",
            "Epoch 736/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0801 - acc: 0.9733 - val_loss: 3.7280 - val_acc: 0.5102\n",
            "Epoch 737/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0874 - acc: 0.9712 - val_loss: 3.5057 - val_acc: 0.5000\n",
            "Epoch 738/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0758 - acc: 0.9733 - val_loss: 3.7682 - val_acc: 0.5044\n",
            "Epoch 739/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0855 - acc: 0.9703 - val_loss: 3.6414 - val_acc: 0.5087\n",
            "Epoch 740/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0756 - acc: 0.9739 - val_loss: 3.7428 - val_acc: 0.5044\n",
            "Epoch 741/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0741 - acc: 0.9708 - val_loss: 3.6945 - val_acc: 0.5131\n",
            "Epoch 742/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0715 - acc: 0.9753 - val_loss: 3.8119 - val_acc: 0.5102\n",
            "Epoch 743/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0921 - acc: 0.9668 - val_loss: 3.5784 - val_acc: 0.5117\n",
            "Epoch 744/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0766 - acc: 0.9733 - val_loss: 3.6033 - val_acc: 0.5087\n",
            "Epoch 745/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0694 - acc: 0.9762 - val_loss: 3.6614 - val_acc: 0.5160\n",
            "Epoch 746/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0831 - acc: 0.9722 - val_loss: 3.6796 - val_acc: 0.5087\n",
            "Epoch 747/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0814 - acc: 0.9733 - val_loss: 3.6964 - val_acc: 0.5175\n",
            "Epoch 748/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0846 - acc: 0.9719 - val_loss: 3.5796 - val_acc: 0.5131\n",
            "Epoch 749/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0683 - acc: 0.9773 - val_loss: 3.7865 - val_acc: 0.5175\n",
            "Epoch 750/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0805 - acc: 0.9703 - val_loss: 3.4639 - val_acc: 0.5219\n",
            "Epoch 751/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0835 - acc: 0.9744 - val_loss: 3.5938 - val_acc: 0.5087\n",
            "Epoch 752/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0775 - acc: 0.9744 - val_loss: 3.7282 - val_acc: 0.5131\n",
            "Epoch 753/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0899 - acc: 0.9699 - val_loss: 3.6252 - val_acc: 0.5044\n",
            "Epoch 754/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0767 - acc: 0.9731 - val_loss: 3.6472 - val_acc: 0.5073\n",
            "Epoch 755/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0783 - acc: 0.9701 - val_loss: 3.5752 - val_acc: 0.5117\n",
            "Epoch 756/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0824 - acc: 0.9690 - val_loss: 3.6504 - val_acc: 0.5000\n",
            "Epoch 757/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0793 - acc: 0.9712 - val_loss: 3.5693 - val_acc: 0.5015\n",
            "Epoch 758/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0862 - acc: 0.9690 - val_loss: 3.5923 - val_acc: 0.5000\n",
            "Epoch 759/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0740 - acc: 0.9733 - val_loss: 3.6078 - val_acc: 0.5058\n",
            "Epoch 760/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0775 - acc: 0.9722 - val_loss: 3.6697 - val_acc: 0.5073\n",
            "Epoch 761/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0795 - acc: 0.9710 - val_loss: 3.5802 - val_acc: 0.5029\n",
            "Epoch 762/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0754 - acc: 0.9737 - val_loss: 3.6148 - val_acc: 0.5044\n",
            "Epoch 763/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0725 - acc: 0.9744 - val_loss: 3.6646 - val_acc: 0.5029\n",
            "Epoch 764/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0727 - acc: 0.9748 - val_loss: 3.6731 - val_acc: 0.5015\n",
            "Epoch 765/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0835 - acc: 0.9679 - val_loss: 3.6223 - val_acc: 0.5073\n",
            "Epoch 766/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0640 - acc: 0.9789 - val_loss: 3.7168 - val_acc: 0.4971\n",
            "Epoch 767/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0779 - acc: 0.9740 - val_loss: 3.6812 - val_acc: 0.5000\n",
            "Epoch 768/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0738 - acc: 0.9764 - val_loss: 3.6147 - val_acc: 0.5073\n",
            "Epoch 769/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0782 - acc: 0.9722 - val_loss: 3.6734 - val_acc: 0.5248\n",
            "Epoch 770/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0737 - acc: 0.9757 - val_loss: 3.6227 - val_acc: 0.4971\n",
            "Epoch 771/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0848 - acc: 0.9708 - val_loss: 3.4909 - val_acc: 0.5190\n",
            "Epoch 772/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0784 - acc: 0.9719 - val_loss: 3.5986 - val_acc: 0.4971\n",
            "Epoch 773/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0681 - acc: 0.9766 - val_loss: 3.7318 - val_acc: 0.5146\n",
            "Epoch 774/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0746 - acc: 0.9766 - val_loss: 3.6178 - val_acc: 0.5204\n",
            "Epoch 775/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0741 - acc: 0.9749 - val_loss: 3.6878 - val_acc: 0.5073\n",
            "Epoch 776/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0649 - acc: 0.9775 - val_loss: 3.7995 - val_acc: 0.4971\n",
            "Epoch 777/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0696 - acc: 0.9746 - val_loss: 3.7604 - val_acc: 0.5087\n",
            "Epoch 778/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0748 - acc: 0.9737 - val_loss: 3.7764 - val_acc: 0.5044\n",
            "Epoch 779/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0798 - acc: 0.9730 - val_loss: 3.4813 - val_acc: 0.5000\n",
            "Epoch 780/1000\n",
            "5548/5548 [==============================] - 2s 318us/step - loss: 0.0784 - acc: 0.9755 - val_loss: 3.5914 - val_acc: 0.5029\n",
            "Epoch 781/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0765 - acc: 0.9748 - val_loss: 3.6794 - val_acc: 0.5015\n",
            "Epoch 782/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0766 - acc: 0.9739 - val_loss: 3.6274 - val_acc: 0.5029\n",
            "Epoch 783/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0789 - acc: 0.9710 - val_loss: 3.6573 - val_acc: 0.5029\n",
            "Epoch 784/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0726 - acc: 0.9746 - val_loss: 3.4835 - val_acc: 0.5015\n",
            "Epoch 785/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0585 - acc: 0.9804 - val_loss: 3.6876 - val_acc: 0.5058\n",
            "Epoch 786/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0720 - acc: 0.9737 - val_loss: 3.6730 - val_acc: 0.5015\n",
            "Epoch 787/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0863 - acc: 0.9728 - val_loss: 3.4907 - val_acc: 0.5058\n",
            "Epoch 788/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0765 - acc: 0.9724 - val_loss: 3.5574 - val_acc: 0.5087\n",
            "Epoch 789/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0690 - acc: 0.9766 - val_loss: 3.6225 - val_acc: 0.5044\n",
            "Epoch 790/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0694 - acc: 0.9742 - val_loss: 3.5747 - val_acc: 0.4985\n",
            "Epoch 791/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0680 - acc: 0.9764 - val_loss: 3.6158 - val_acc: 0.5029\n",
            "Epoch 792/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0745 - acc: 0.9726 - val_loss: 3.6477 - val_acc: 0.5000\n",
            "Epoch 793/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0672 - acc: 0.9762 - val_loss: 3.6603 - val_acc: 0.5000\n",
            "Epoch 794/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0719 - acc: 0.9762 - val_loss: 3.6662 - val_acc: 0.5087\n",
            "Epoch 795/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0776 - acc: 0.9735 - val_loss: 3.6766 - val_acc: 0.5117\n",
            "Epoch 796/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0774 - acc: 0.9703 - val_loss: 3.6098 - val_acc: 0.5073\n",
            "Epoch 797/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0782 - acc: 0.9735 - val_loss: 3.5459 - val_acc: 0.5117\n",
            "Epoch 798/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0712 - acc: 0.9753 - val_loss: 3.5990 - val_acc: 0.5160\n",
            "Epoch 799/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0661 - acc: 0.9764 - val_loss: 3.6866 - val_acc: 0.5102\n",
            "Epoch 800/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0682 - acc: 0.9760 - val_loss: 3.6795 - val_acc: 0.5044\n",
            "Epoch 801/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0692 - acc: 0.9753 - val_loss: 3.7426 - val_acc: 0.5087\n",
            "Epoch 802/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0753 - acc: 0.9757 - val_loss: 3.5638 - val_acc: 0.5015\n",
            "Epoch 803/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0642 - acc: 0.9769 - val_loss: 3.6299 - val_acc: 0.4985\n",
            "Epoch 804/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0706 - acc: 0.9753 - val_loss: 3.5500 - val_acc: 0.5073\n",
            "Epoch 805/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0672 - acc: 0.9760 - val_loss: 3.6219 - val_acc: 0.5073\n",
            "Epoch 806/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0755 - acc: 0.9726 - val_loss: 3.6292 - val_acc: 0.5117\n",
            "Epoch 807/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0676 - acc: 0.9762 - val_loss: 3.6659 - val_acc: 0.5029\n",
            "Epoch 808/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0731 - acc: 0.9753 - val_loss: 3.6591 - val_acc: 0.5160\n",
            "Epoch 809/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0729 - acc: 0.9735 - val_loss: 3.6630 - val_acc: 0.5015\n",
            "Epoch 810/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0690 - acc: 0.9767 - val_loss: 3.5941 - val_acc: 0.5044\n",
            "Epoch 811/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0706 - acc: 0.9751 - val_loss: 3.4867 - val_acc: 0.5058\n",
            "Epoch 812/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0682 - acc: 0.9769 - val_loss: 3.5624 - val_acc: 0.5087\n",
            "Epoch 813/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0691 - acc: 0.9746 - val_loss: 3.6652 - val_acc: 0.5044\n",
            "Epoch 814/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0837 - acc: 0.9710 - val_loss: 3.3428 - val_acc: 0.5219\n",
            "Epoch 815/1000\n",
            "5548/5548 [==============================] - 2s 323us/step - loss: 0.0635 - acc: 0.9791 - val_loss: 3.5461 - val_acc: 0.5087\n",
            "Epoch 816/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0685 - acc: 0.9762 - val_loss: 3.6426 - val_acc: 0.4985\n",
            "Epoch 817/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0726 - acc: 0.9748 - val_loss: 3.5587 - val_acc: 0.5073\n",
            "Epoch 818/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0652 - acc: 0.9771 - val_loss: 3.6616 - val_acc: 0.5102\n",
            "Epoch 819/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0683 - acc: 0.9773 - val_loss: 3.6134 - val_acc: 0.5102\n",
            "Epoch 820/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0674 - acc: 0.9764 - val_loss: 3.5799 - val_acc: 0.5044\n",
            "Epoch 821/1000\n",
            "5548/5548 [==============================] - 2s 320us/step - loss: 0.0695 - acc: 0.9755 - val_loss: 3.7050 - val_acc: 0.5044\n",
            "Epoch 822/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0743 - acc: 0.9751 - val_loss: 3.6625 - val_acc: 0.5131\n",
            "Epoch 823/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0774 - acc: 0.9724 - val_loss: 3.5907 - val_acc: 0.5219\n",
            "Epoch 824/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0631 - acc: 0.9782 - val_loss: 3.6798 - val_acc: 0.5117\n",
            "Epoch 825/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0626 - acc: 0.9791 - val_loss: 3.5983 - val_acc: 0.5190\n",
            "Epoch 826/1000\n",
            "5548/5548 [==============================] - 2s 319us/step - loss: 0.0778 - acc: 0.9721 - val_loss: 3.6258 - val_acc: 0.5117\n",
            "Epoch 827/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0724 - acc: 0.9744 - val_loss: 3.6390 - val_acc: 0.5087\n",
            "Epoch 828/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0689 - acc: 0.9762 - val_loss: 3.6199 - val_acc: 0.5058\n",
            "Epoch 829/1000\n",
            "5548/5548 [==============================] - 2s 317us/step - loss: 0.0625 - acc: 0.9780 - val_loss: 3.5411 - val_acc: 0.5160\n",
            "Epoch 830/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0689 - acc: 0.9776 - val_loss: 3.5641 - val_acc: 0.5175\n",
            "Epoch 831/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0707 - acc: 0.9737 - val_loss: 3.6654 - val_acc: 0.5117\n",
            "Epoch 832/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0777 - acc: 0.9746 - val_loss: 3.5881 - val_acc: 0.5117\n",
            "Epoch 833/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0676 - acc: 0.9766 - val_loss: 3.5976 - val_acc: 0.5175\n",
            "Epoch 834/1000\n",
            "5548/5548 [==============================] - 2s 338us/step - loss: 0.0631 - acc: 0.9773 - val_loss: 3.7602 - val_acc: 0.5087\n",
            "Epoch 835/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0638 - acc: 0.9782 - val_loss: 3.6771 - val_acc: 0.4971\n",
            "Epoch 836/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0799 - acc: 0.9737 - val_loss: 3.5503 - val_acc: 0.5073\n",
            "Epoch 837/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0657 - acc: 0.9776 - val_loss: 3.5940 - val_acc: 0.4985\n",
            "Epoch 838/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0810 - acc: 0.9721 - val_loss: 3.6582 - val_acc: 0.5044\n",
            "Epoch 839/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0567 - acc: 0.9795 - val_loss: 3.7827 - val_acc: 0.5015\n",
            "Epoch 840/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0615 - acc: 0.9784 - val_loss: 3.6862 - val_acc: 0.5073\n",
            "Epoch 841/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0643 - acc: 0.9760 - val_loss: 3.7222 - val_acc: 0.4971\n",
            "Epoch 842/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0721 - acc: 0.9737 - val_loss: 3.6075 - val_acc: 0.5015\n",
            "Epoch 843/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0644 - acc: 0.9798 - val_loss: 3.6872 - val_acc: 0.5131\n",
            "Epoch 844/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0619 - acc: 0.9787 - val_loss: 3.7157 - val_acc: 0.5175\n",
            "Epoch 845/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0610 - acc: 0.9793 - val_loss: 3.6828 - val_acc: 0.5190\n",
            "Epoch 846/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0676 - acc: 0.9760 - val_loss: 3.7410 - val_acc: 0.5102\n",
            "Epoch 847/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0673 - acc: 0.9751 - val_loss: 3.6525 - val_acc: 0.5204\n",
            "Epoch 848/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0688 - acc: 0.9769 - val_loss: 3.7442 - val_acc: 0.5204\n",
            "Epoch 849/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0745 - acc: 0.9753 - val_loss: 3.5567 - val_acc: 0.5146\n",
            "Epoch 850/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0756 - acc: 0.9753 - val_loss: 3.5461 - val_acc: 0.5175\n",
            "Epoch 851/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0591 - acc: 0.9787 - val_loss: 3.6083 - val_acc: 0.5175\n",
            "Epoch 852/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0701 - acc: 0.9742 - val_loss: 3.6784 - val_acc: 0.5146\n",
            "Epoch 853/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0660 - acc: 0.9760 - val_loss: 3.5881 - val_acc: 0.5262\n",
            "Epoch 854/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0725 - acc: 0.9749 - val_loss: 3.5135 - val_acc: 0.5277\n",
            "Epoch 855/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0783 - acc: 0.9721 - val_loss: 3.4686 - val_acc: 0.5117\n",
            "Epoch 856/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0661 - acc: 0.9746 - val_loss: 3.6661 - val_acc: 0.5146\n",
            "Epoch 857/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0730 - acc: 0.9751 - val_loss: 3.5580 - val_acc: 0.5292\n",
            "Epoch 858/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0634 - acc: 0.9771 - val_loss: 3.5769 - val_acc: 0.5233\n",
            "Epoch 859/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0609 - acc: 0.9791 - val_loss: 3.6930 - val_acc: 0.5248\n",
            "Epoch 860/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0677 - acc: 0.9769 - val_loss: 3.6846 - val_acc: 0.5292\n",
            "Epoch 861/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0701 - acc: 0.9764 - val_loss: 3.6920 - val_acc: 0.5204\n",
            "Epoch 862/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0678 - acc: 0.9775 - val_loss: 3.7371 - val_acc: 0.5190\n",
            "Epoch 863/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0561 - acc: 0.9814 - val_loss: 3.8010 - val_acc: 0.5219\n",
            "Epoch 864/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0737 - acc: 0.9740 - val_loss: 3.5998 - val_acc: 0.5233\n",
            "Epoch 865/1000\n",
            "5548/5548 [==============================] - 2s 338us/step - loss: 0.0614 - acc: 0.9793 - val_loss: 3.6555 - val_acc: 0.5117\n",
            "Epoch 866/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0697 - acc: 0.9773 - val_loss: 3.6612 - val_acc: 0.5292\n",
            "Epoch 867/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0610 - acc: 0.9798 - val_loss: 3.7684 - val_acc: 0.5219\n",
            "Epoch 868/1000\n",
            "5548/5548 [==============================] - 2s 321us/step - loss: 0.0683 - acc: 0.9776 - val_loss: 3.7280 - val_acc: 0.5160\n",
            "Epoch 869/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0685 - acc: 0.9767 - val_loss: 3.7202 - val_acc: 0.5131\n",
            "Epoch 870/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0641 - acc: 0.9775 - val_loss: 3.6860 - val_acc: 0.5102\n",
            "Epoch 871/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0685 - acc: 0.9757 - val_loss: 3.7722 - val_acc: 0.5073\n",
            "Epoch 872/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0765 - acc: 0.9740 - val_loss: 3.6536 - val_acc: 0.5146\n",
            "Epoch 873/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0655 - acc: 0.9762 - val_loss: 3.6899 - val_acc: 0.5102\n",
            "Epoch 874/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0735 - acc: 0.9746 - val_loss: 3.6583 - val_acc: 0.5015\n",
            "Epoch 875/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0643 - acc: 0.9769 - val_loss: 3.7340 - val_acc: 0.5073\n",
            "Epoch 876/1000\n",
            "5548/5548 [==============================] - 2s 338us/step - loss: 0.0641 - acc: 0.9795 - val_loss: 3.5271 - val_acc: 0.5044\n",
            "Epoch 877/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0609 - acc: 0.9780 - val_loss: 3.7541 - val_acc: 0.5117\n",
            "Epoch 878/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0686 - acc: 0.9778 - val_loss: 3.8368 - val_acc: 0.5131\n",
            "Epoch 879/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0728 - acc: 0.9744 - val_loss: 3.7719 - val_acc: 0.5102\n",
            "Epoch 880/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0712 - acc: 0.9787 - val_loss: 3.5283 - val_acc: 0.5044\n",
            "Epoch 881/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0687 - acc: 0.9755 - val_loss: 3.6196 - val_acc: 0.5117\n",
            "Epoch 882/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0634 - acc: 0.9775 - val_loss: 3.6498 - val_acc: 0.5073\n",
            "Epoch 883/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0752 - acc: 0.9762 - val_loss: 3.5860 - val_acc: 0.5117\n",
            "Epoch 884/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0576 - acc: 0.9796 - val_loss: 3.6093 - val_acc: 0.5102\n",
            "Epoch 885/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0583 - acc: 0.9818 - val_loss: 3.8212 - val_acc: 0.5044\n",
            "Epoch 886/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0578 - acc: 0.9816 - val_loss: 3.8121 - val_acc: 0.4985\n",
            "Epoch 887/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0553 - acc: 0.9778 - val_loss: 3.9780 - val_acc: 0.5102\n",
            "Epoch 888/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0653 - acc: 0.9769 - val_loss: 3.7991 - val_acc: 0.5102\n",
            "Epoch 889/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0640 - acc: 0.9771 - val_loss: 3.7238 - val_acc: 0.5044\n",
            "Epoch 890/1000\n",
            "5548/5548 [==============================] - 2s 337us/step - loss: 0.0552 - acc: 0.9814 - val_loss: 3.8779 - val_acc: 0.4985\n",
            "Epoch 891/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0647 - acc: 0.9782 - val_loss: 3.8334 - val_acc: 0.5175\n",
            "Epoch 892/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0576 - acc: 0.9800 - val_loss: 3.7672 - val_acc: 0.5117\n",
            "Epoch 893/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0711 - acc: 0.9751 - val_loss: 3.6405 - val_acc: 0.5073\n",
            "Epoch 894/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0662 - acc: 0.9773 - val_loss: 3.8718 - val_acc: 0.5219\n",
            "Epoch 895/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0666 - acc: 0.9760 - val_loss: 3.7794 - val_acc: 0.5073\n",
            "Epoch 896/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0670 - acc: 0.9769 - val_loss: 3.7069 - val_acc: 0.5044\n",
            "Epoch 897/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0637 - acc: 0.9775 - val_loss: 3.7696 - val_acc: 0.5029\n",
            "Epoch 898/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0592 - acc: 0.9798 - val_loss: 3.7242 - val_acc: 0.5073\n",
            "Epoch 899/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0633 - acc: 0.9791 - val_loss: 3.7621 - val_acc: 0.5044\n",
            "Epoch 900/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0605 - acc: 0.9813 - val_loss: 3.9015 - val_acc: 0.5058\n",
            "Epoch 901/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0671 - acc: 0.9760 - val_loss: 3.8436 - val_acc: 0.5175\n",
            "Epoch 902/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0637 - acc: 0.9802 - val_loss: 3.7307 - val_acc: 0.5131\n",
            "Epoch 903/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0574 - acc: 0.9793 - val_loss: 3.7908 - val_acc: 0.5117\n",
            "Epoch 904/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0679 - acc: 0.9787 - val_loss: 3.8348 - val_acc: 0.5087\n",
            "Epoch 905/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0585 - acc: 0.9813 - val_loss: 3.8281 - val_acc: 0.5087\n",
            "Epoch 906/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0619 - acc: 0.9782 - val_loss: 3.8280 - val_acc: 0.5000\n",
            "Epoch 907/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0675 - acc: 0.9778 - val_loss: 3.7952 - val_acc: 0.5058\n",
            "Epoch 908/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0651 - acc: 0.9782 - val_loss: 3.7756 - val_acc: 0.5058\n",
            "Epoch 909/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0649 - acc: 0.9787 - val_loss: 3.7333 - val_acc: 0.5087\n",
            "Epoch 910/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0629 - acc: 0.9769 - val_loss: 3.9277 - val_acc: 0.5058\n",
            "Epoch 911/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0613 - acc: 0.9773 - val_loss: 3.8592 - val_acc: 0.5073\n",
            "Epoch 912/1000\n",
            "5548/5548 [==============================] - 2s 337us/step - loss: 0.0603 - acc: 0.9798 - val_loss: 3.8915 - val_acc: 0.5073\n",
            "Epoch 913/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0614 - acc: 0.9787 - val_loss: 3.8624 - val_acc: 0.5073\n",
            "Epoch 914/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0624 - acc: 0.9778 - val_loss: 3.8994 - val_acc: 0.5044\n",
            "Epoch 915/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0571 - acc: 0.9796 - val_loss: 3.9570 - val_acc: 0.5029\n",
            "Epoch 916/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0665 - acc: 0.9771 - val_loss: 3.8039 - val_acc: 0.5087\n",
            "Epoch 917/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0573 - acc: 0.9793 - val_loss: 3.9879 - val_acc: 0.5029\n",
            "Epoch 918/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0569 - acc: 0.9818 - val_loss: 3.9091 - val_acc: 0.5015\n",
            "Epoch 919/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0711 - acc: 0.9782 - val_loss: 3.6067 - val_acc: 0.5146\n",
            "Epoch 920/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0603 - acc: 0.9800 - val_loss: 3.8330 - val_acc: 0.5058\n",
            "Epoch 921/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0643 - acc: 0.9764 - val_loss: 3.7684 - val_acc: 0.5146\n",
            "Epoch 922/1000\n",
            "5548/5548 [==============================] - 2s 324us/step - loss: 0.0586 - acc: 0.9802 - val_loss: 3.8111 - val_acc: 0.5146\n",
            "Epoch 923/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0665 - acc: 0.9769 - val_loss: 3.7683 - val_acc: 0.5029\n",
            "Epoch 924/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0646 - acc: 0.9771 - val_loss: 3.7732 - val_acc: 0.5073\n",
            "Epoch 925/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0565 - acc: 0.9813 - val_loss: 3.7990 - val_acc: 0.5029\n",
            "Epoch 926/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0562 - acc: 0.9796 - val_loss: 3.7370 - val_acc: 0.5117\n",
            "Epoch 927/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0645 - acc: 0.9775 - val_loss: 3.6834 - val_acc: 0.5073\n",
            "Epoch 928/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0585 - acc: 0.9787 - val_loss: 3.7944 - val_acc: 0.5087\n",
            "Epoch 929/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0556 - acc: 0.9800 - val_loss: 3.8082 - val_acc: 0.5102\n",
            "Epoch 930/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0560 - acc: 0.9818 - val_loss: 3.8075 - val_acc: 0.5044\n",
            "Epoch 931/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0640 - acc: 0.9760 - val_loss: 3.8467 - val_acc: 0.4985\n",
            "Epoch 932/1000\n",
            "5548/5548 [==============================] - 2s 336us/step - loss: 0.0642 - acc: 0.9786 - val_loss: 3.7548 - val_acc: 0.5029\n",
            "Epoch 933/1000\n",
            "5548/5548 [==============================] - 2s 339us/step - loss: 0.0605 - acc: 0.9795 - val_loss: 3.8708 - val_acc: 0.5073\n",
            "Epoch 934/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0645 - acc: 0.9787 - val_loss: 3.8559 - val_acc: 0.5029\n",
            "Epoch 935/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0677 - acc: 0.9784 - val_loss: 3.8006 - val_acc: 0.5087\n",
            "Epoch 936/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0702 - acc: 0.9769 - val_loss: 3.6836 - val_acc: 0.5087\n",
            "Epoch 937/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0594 - acc: 0.9789 - val_loss: 3.7902 - val_acc: 0.5175\n",
            "Epoch 938/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0661 - acc: 0.9773 - val_loss: 3.6800 - val_acc: 0.5044\n",
            "Epoch 939/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0591 - acc: 0.9787 - val_loss: 3.6714 - val_acc: 0.5000\n",
            "Epoch 940/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0569 - acc: 0.9813 - val_loss: 3.8384 - val_acc: 0.5131\n",
            "Epoch 941/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0655 - acc: 0.9787 - val_loss: 3.6363 - val_acc: 0.5131\n",
            "Epoch 942/1000\n",
            "5548/5548 [==============================] - 2s 338us/step - loss: 0.0683 - acc: 0.9762 - val_loss: 3.6163 - val_acc: 0.5087\n",
            "Epoch 943/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0610 - acc: 0.9767 - val_loss: 3.8044 - val_acc: 0.5233\n",
            "Epoch 944/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0549 - acc: 0.9813 - val_loss: 3.7162 - val_acc: 0.5102\n",
            "Epoch 945/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0560 - acc: 0.9786 - val_loss: 3.8909 - val_acc: 0.5073\n",
            "Epoch 946/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0620 - acc: 0.9789 - val_loss: 3.8558 - val_acc: 0.5058\n",
            "Epoch 947/1000\n",
            "5548/5548 [==============================] - 2s 337us/step - loss: 0.0613 - acc: 0.9789 - val_loss: 3.8311 - val_acc: 0.5102\n",
            "Epoch 948/1000\n",
            "5548/5548 [==============================] - 2s 337us/step - loss: 0.0682 - acc: 0.9758 - val_loss: 3.7787 - val_acc: 0.5204\n",
            "Epoch 949/1000\n",
            "5548/5548 [==============================] - 2s 328us/step - loss: 0.0625 - acc: 0.9786 - val_loss: 3.6634 - val_acc: 0.5015\n",
            "Epoch 950/1000\n",
            "5548/5548 [==============================] - 2s 341us/step - loss: 0.0585 - acc: 0.9805 - val_loss: 3.7103 - val_acc: 0.5248\n",
            "Epoch 951/1000\n",
            "5548/5548 [==============================] - 2s 336us/step - loss: 0.0650 - acc: 0.9767 - val_loss: 3.5868 - val_acc: 0.5190\n",
            "Epoch 952/1000\n",
            "5548/5548 [==============================] - 2s 343us/step - loss: 0.0556 - acc: 0.9800 - val_loss: 3.7514 - val_acc: 0.4971\n",
            "Epoch 953/1000\n",
            "5548/5548 [==============================] - 2s 344us/step - loss: 0.0660 - acc: 0.9778 - val_loss: 3.6850 - val_acc: 0.5292\n",
            "Epoch 954/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0570 - acc: 0.9804 - val_loss: 3.7787 - val_acc: 0.5044\n",
            "Epoch 955/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0546 - acc: 0.9820 - val_loss: 3.8659 - val_acc: 0.5073\n",
            "Epoch 956/1000\n",
            "5548/5548 [==============================] - 2s 338us/step - loss: 0.0635 - acc: 0.9804 - val_loss: 3.7582 - val_acc: 0.5131\n",
            "Epoch 957/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0547 - acc: 0.9822 - val_loss: 3.9121 - val_acc: 0.4985\n",
            "Epoch 958/1000\n",
            "5548/5548 [==============================] - 2s 337us/step - loss: 0.0633 - acc: 0.9791 - val_loss: 3.7335 - val_acc: 0.5102\n",
            "Epoch 959/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0629 - acc: 0.9786 - val_loss: 3.7640 - val_acc: 0.5087\n",
            "Epoch 960/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0626 - acc: 0.9800 - val_loss: 3.7607 - val_acc: 0.5102\n",
            "Epoch 961/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0571 - acc: 0.9804 - val_loss: 3.9984 - val_acc: 0.5058\n",
            "Epoch 962/1000\n",
            "5548/5548 [==============================] - 2s 348us/step - loss: 0.0686 - acc: 0.9773 - val_loss: 3.7868 - val_acc: 0.4898\n",
            "Epoch 963/1000\n",
            "5548/5548 [==============================] - 2s 325us/step - loss: 0.0525 - acc: 0.9822 - val_loss: 3.8764 - val_acc: 0.5073\n",
            "Epoch 964/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0607 - acc: 0.9804 - val_loss: 3.8242 - val_acc: 0.5146\n",
            "Epoch 965/1000\n",
            "5548/5548 [==============================] - 2s 342us/step - loss: 0.0633 - acc: 0.9776 - val_loss: 3.8640 - val_acc: 0.5058\n",
            "Epoch 966/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0626 - acc: 0.9789 - val_loss: 3.9836 - val_acc: 0.4971\n",
            "Epoch 967/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0653 - acc: 0.9782 - val_loss: 3.7684 - val_acc: 0.5029\n",
            "Epoch 968/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0544 - acc: 0.9798 - val_loss: 4.0184 - val_acc: 0.4985\n",
            "Epoch 969/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0627 - acc: 0.9776 - val_loss: 3.9244 - val_acc: 0.4854\n",
            "Epoch 970/1000\n",
            "5548/5548 [==============================] - 2s 322us/step - loss: 0.0517 - acc: 0.9825 - val_loss: 3.9577 - val_acc: 0.5000\n",
            "Epoch 971/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0589 - acc: 0.9807 - val_loss: 3.9247 - val_acc: 0.4942\n",
            "Epoch 972/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0562 - acc: 0.9814 - val_loss: 3.8876 - val_acc: 0.4971\n",
            "Epoch 973/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0606 - acc: 0.9789 - val_loss: 3.9805 - val_acc: 0.4942\n",
            "Epoch 974/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0536 - acc: 0.9820 - val_loss: 4.0795 - val_acc: 0.4927\n",
            "Epoch 975/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0546 - acc: 0.9795 - val_loss: 3.8403 - val_acc: 0.4869\n",
            "Epoch 976/1000\n",
            "5548/5548 [==============================] - 2s 340us/step - loss: 0.0592 - acc: 0.9800 - val_loss: 3.8887 - val_acc: 0.4985\n",
            "Epoch 977/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0584 - acc: 0.9814 - val_loss: 3.7803 - val_acc: 0.5015\n",
            "Epoch 978/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0627 - acc: 0.9780 - val_loss: 3.9001 - val_acc: 0.4956\n",
            "Epoch 979/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0569 - acc: 0.9814 - val_loss: 3.9239 - val_acc: 0.5058\n",
            "Epoch 980/1000\n",
            "5548/5548 [==============================] - 2s 326us/step - loss: 0.0557 - acc: 0.9804 - val_loss: 3.9291 - val_acc: 0.4985\n",
            "Epoch 981/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0516 - acc: 0.9795 - val_loss: 4.0427 - val_acc: 0.4985\n",
            "Epoch 982/1000\n",
            "5548/5548 [==============================] - 2s 332us/step - loss: 0.0469 - acc: 0.9850 - val_loss: 3.9187 - val_acc: 0.5015\n",
            "Epoch 983/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0564 - acc: 0.9804 - val_loss: 3.8455 - val_acc: 0.5117\n",
            "Epoch 984/1000\n",
            "5548/5548 [==============================] - 2s 334us/step - loss: 0.0480 - acc: 0.9852 - val_loss: 3.9692 - val_acc: 0.5044\n",
            "Epoch 985/1000\n",
            "5548/5548 [==============================] - 2s 333us/step - loss: 0.0567 - acc: 0.9807 - val_loss: 3.9933 - val_acc: 0.4971\n",
            "Epoch 986/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0601 - acc: 0.9793 - val_loss: 3.9894 - val_acc: 0.5029\n",
            "Epoch 987/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0606 - acc: 0.9789 - val_loss: 3.8254 - val_acc: 0.5029\n",
            "Epoch 988/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0570 - acc: 0.9804 - val_loss: 3.8034 - val_acc: 0.5087\n",
            "Epoch 989/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0593 - acc: 0.9791 - val_loss: 3.7806 - val_acc: 0.5204\n",
            "Epoch 990/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0587 - acc: 0.9793 - val_loss: 3.8603 - val_acc: 0.5102\n",
            "Epoch 991/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0593 - acc: 0.9795 - val_loss: 3.9416 - val_acc: 0.5058\n",
            "Epoch 992/1000\n",
            "5548/5548 [==============================] - 2s 330us/step - loss: 0.0670 - acc: 0.9791 - val_loss: 3.7748 - val_acc: 0.5029\n",
            "Epoch 993/1000\n",
            "5548/5548 [==============================] - 2s 329us/step - loss: 0.0598 - acc: 0.9775 - val_loss: 3.8968 - val_acc: 0.4985\n",
            "Epoch 994/1000\n",
            "5548/5548 [==============================] - 2s 337us/step - loss: 0.0566 - acc: 0.9796 - val_loss: 4.0440 - val_acc: 0.4985\n",
            "Epoch 995/1000\n",
            "5548/5548 [==============================] - 2s 327us/step - loss: 0.0558 - acc: 0.9807 - val_loss: 3.9985 - val_acc: 0.5087\n",
            "Epoch 996/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0527 - acc: 0.9814 - val_loss: 4.1212 - val_acc: 0.5058\n",
            "Epoch 997/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0616 - acc: 0.9805 - val_loss: 3.9472 - val_acc: 0.5073\n",
            "Epoch 998/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0662 - acc: 0.9776 - val_loss: 3.8689 - val_acc: 0.4956\n",
            "Epoch 999/1000\n",
            "5548/5548 [==============================] - 2s 335us/step - loss: 0.0580 - acc: 0.9820 - val_loss: 3.8919 - val_acc: 0.5102\n",
            "Epoch 1000/1000\n",
            "5548/5548 [==============================] - 2s 331us/step - loss: 0.0594 - acc: 0.9780 - val_loss: 3.9531 - val_acc: 0.5015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MmCoU4ksp67"
      },
      "source": [
        "## 2.Predict the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQwJ75p_WdBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bec988e-3a60-4850-a32e-642116e350f0"
      },
      "source": [
        "X_test_encode = np.array(pad_sequences(input_tokenizer.texts_to_sequences(X_test), maxlen=maxLength,padding=\"post\"))\n",
        "test_length = len(X_test_encode)\n",
        "\n",
        "y_predict = []\n",
        "predicted = model.predict(X_test_encode)\n",
        "for predict in predicted:\n",
        "    index2, value = max(enumerate(predict), key=operator.itemgetter(1))\n",
        "    y_predict.append(classes[index2])\n",
        "    \n",
        "print(y_predict[0])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enjoyment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CWnvBNeI0joN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093b260d-ab68-4316-d2e2-1be879488f02"
      },
      "source": [
        "print(y_predict)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Enjoyment', 'Other', 'Fear', 'Fear', 'Disgust', 'Other', 'Disgust', 'Enjoyment', 'Other', 'Sadness', 'Enjoyment', 'Enjoyment', 'Disgust', 'Enjoyment', 'Sadness', 'Disgust', 'Other', 'Enjoyment', 'Other', 'Disgust', 'Fear', 'Other', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Disgust', 'Sadness', 'Other', 'Enjoyment', 'Other', 'Surprise', 'Other', 'Enjoyment', 'Sadness', 'Enjoyment', 'Enjoyment', 'Surprise', 'Disgust', 'Disgust', 'Other', 'Disgust', 'Sadness', 'Disgust', 'Other', 'Disgust', 'Other', 'Other', 'Sadness', 'Sadness', 'Anger', 'Surprise', 'Anger', 'Fear', 'Enjoyment', 'Sadness', 'Other', 'Fear', 'Sadness', 'Disgust', 'Other', 'Disgust', 'Fear', 'Other', 'Sadness', 'Enjoyment', 'Enjoyment', 'Other', 'Other', 'Fear', 'Disgust', 'Disgust', 'Anger', 'Other', 'Fear', 'Sadness', 'Other', 'Enjoyment', 'Sadness', 'Sadness', 'Enjoyment', 'Fear', 'Other', 'Enjoyment', 'Sadness', 'Fear', 'Other', 'Enjoyment', 'Fear', 'Other', 'Anger', 'Enjoyment', 'Sadness', 'Other', 'Disgust', 'Other', 'Enjoyment', 'Other', 'Other', 'Enjoyment', 'Enjoyment', 'Sadness', 'Disgust', 'Disgust', 'Disgust', 'Other', 'Enjoyment', 'Fear', 'Other', 'Other', 'Enjoyment', 'Sadness', 'Enjoyment', 'Other', 'Anger', 'Enjoyment', 'Other', 'Enjoyment', 'Anger', 'Enjoyment', 'Disgust', 'Sadness', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Other', 'Enjoyment', 'Enjoyment', 'Other', 'Disgust', 'Sadness', 'Enjoyment', 'Enjoyment', 'Sadness', 'Disgust', 'Disgust', 'Enjoyment', 'Anger', 'Enjoyment', 'Disgust', 'Surprise', 'Disgust', 'Other', 'Disgust', 'Enjoyment', 'Other', 'Enjoyment', 'Other', 'Disgust', 'Enjoyment', 'Disgust', 'Fear', 'Surprise', 'Sadness', 'Enjoyment', 'Disgust', 'Other', 'Enjoyment', 'Enjoyment', 'Sadness', 'Other', 'Disgust', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Other', 'Sadness', 'Enjoyment', 'Enjoyment', 'Other', 'Enjoyment', 'Other', 'Disgust', 'Enjoyment', 'Other', 'Disgust', 'Other', 'Enjoyment', 'Sadness', 'Disgust', 'Disgust', 'Disgust', 'Enjoyment', 'Fear', 'Enjoyment', 'Surprise', 'Enjoyment', 'Sadness', 'Sadness', 'Anger', 'Other', 'Other', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Disgust', 'Other', 'Other', 'Enjoyment', 'Disgust', 'Anger', 'Sadness', 'Other', 'Sadness', 'Enjoyment', 'Other', 'Disgust', 'Sadness', 'Other', 'Fear', 'Enjoyment', 'Disgust', 'Disgust', 'Other', 'Disgust', 'Other', 'Enjoyment', 'Surprise', 'Disgust', 'Sadness', 'Enjoyment', 'Anger', 'Disgust', 'Enjoyment', 'Other', 'Disgust', 'Fear', 'Fear', 'Other', 'Disgust', 'Anger', 'Enjoyment', 'Other', 'Disgust', 'Fear', 'Fear', 'Sadness', 'Anger', 'Fear', 'Fear', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Sadness', 'Disgust', 'Enjoyment', 'Enjoyment', 'Other', 'Enjoyment', 'Enjoyment', 'Other', 'Sadness', 'Surprise', 'Disgust', 'Other', 'Enjoyment', 'Enjoyment', 'Disgust', 'Fear', 'Enjoyment', 'Sadness', 'Disgust', 'Other', 'Other', 'Enjoyment', 'Sadness', 'Enjoyment', 'Disgust', 'Enjoyment', 'Enjoyment', 'Sadness', 'Enjoyment', 'Fear', 'Enjoyment', 'Other', 'Enjoyment', 'Sadness', 'Other', 'Enjoyment', 'Other', 'Enjoyment', 'Disgust', 'Other', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Sadness', 'Other', 'Disgust', 'Disgust', 'Disgust', 'Sadness', 'Disgust', 'Disgust', 'Disgust', 'Enjoyment', 'Sadness', 'Enjoyment', 'Enjoyment', 'Surprise', 'Surprise', 'Other', 'Disgust', 'Other', 'Sadness', 'Disgust', 'Fear', 'Anger', 'Enjoyment', 'Anger', 'Enjoyment', 'Disgust', 'Enjoyment', 'Other', 'Disgust', 'Other', 'Disgust', 'Sadness', 'Anger', 'Enjoyment', 'Other', 'Other', 'Other', 'Enjoyment', 'Fear', 'Fear', 'Other', 'Other', 'Other', 'Disgust', 'Disgust', 'Sadness', 'Enjoyment', 'Other', 'Disgust', 'Other', 'Disgust', 'Other', 'Disgust', 'Surprise', 'Disgust', 'Sadness', 'Enjoyment', 'Enjoyment', 'Other', 'Disgust', 'Disgust', 'Surprise', 'Disgust', 'Disgust', 'Disgust', 'Enjoyment', 'Other', 'Enjoyment', 'Sadness', 'Sadness', 'Anger', 'Sadness', 'Fear', 'Disgust', 'Other', 'Enjoyment', 'Disgust', 'Fear', 'Other', 'Enjoyment', 'Anger', 'Enjoyment', 'Sadness', 'Fear', 'Sadness', 'Enjoyment', 'Sadness', 'Enjoyment', 'Enjoyment', 'Fear', 'Sadness', 'Fear', 'Enjoyment', 'Enjoyment', 'Sadness', 'Disgust', 'Anger', 'Enjoyment', 'Sadness', 'Sadness', 'Sadness', 'Sadness', 'Enjoyment', 'Enjoyment', 'Anger', 'Sadness', 'Sadness', 'Fear', 'Enjoyment', 'Enjoyment', 'Anger', 'Enjoyment', 'Fear', 'Enjoyment', 'Other', 'Sadness', 'Other', 'Disgust', 'Disgust', 'Other', 'Disgust', 'Fear', 'Disgust', 'Disgust', 'Surprise', 'Enjoyment', 'Surprise', 'Surprise', 'Surprise', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Disgust', 'Other', 'Disgust', 'Disgust', 'Sadness', 'Anger', 'Other', 'Other', 'Sadness', 'Other', 'Disgust', 'Disgust', 'Other', 'Disgust', 'Other', 'Sadness', 'Sadness', 'Fear', 'Surprise', 'Enjoyment', 'Disgust', 'Enjoyment', 'Other', 'Enjoyment', 'Other', 'Sadness', 'Disgust', 'Disgust', 'Surprise', 'Enjoyment', 'Sadness', 'Enjoyment', 'Sadness', 'Sadness', 'Enjoyment', 'Anger', 'Disgust', 'Anger', 'Other', 'Disgust', 'Disgust', 'Other', 'Enjoyment', 'Other', 'Sadness', 'Disgust', 'Sadness', 'Other', 'Fear', 'Disgust', 'Other', 'Enjoyment', 'Disgust', 'Enjoyment', 'Other', 'Anger', 'Enjoyment', 'Disgust', 'Surprise', 'Other', 'Sadness', 'Fear', 'Sadness', 'Disgust', 'Anger', 'Disgust', 'Enjoyment', 'Other', 'Enjoyment', 'Disgust', 'Other', 'Disgust', 'Other', 'Enjoyment', 'Sadness', 'Enjoyment', 'Enjoyment', 'Other', 'Disgust', 'Disgust', 'Enjoyment', 'Sadness', 'Disgust', 'Other', 'Other', 'Sadness', 'Disgust', 'Fear', 'Sadness', 'Fear', 'Sadness', 'Enjoyment', 'Disgust', 'Enjoyment', 'Enjoyment', 'Other', 'Enjoyment', 'Other', 'Enjoyment', 'Sadness', 'Other', 'Enjoyment', 'Anger', 'Sadness', 'Other', 'Anger', 'Enjoyment', 'Disgust', 'Disgust', 'Enjoyment', 'Sadness', 'Sadness', 'Sadness', 'Enjoyment', 'Enjoyment', 'Sadness', 'Disgust', 'Enjoyment', 'Fear', 'Other', 'Surprise', 'Disgust', 'Fear', 'Sadness', 'Other', 'Disgust', 'Other', 'Disgust', 'Surprise', 'Disgust', 'Disgust', 'Sadness', 'Other', 'Surprise', 'Disgust', 'Enjoyment', 'Enjoyment', 'Other', 'Other', 'Other', 'Sadness', 'Other', 'Enjoyment', 'Disgust', 'Enjoyment', 'Sadness', 'Enjoyment', 'Enjoyment', 'Anger', 'Sadness', 'Anger', 'Anger', 'Enjoyment', 'Sadness', 'Disgust', 'Surprise', 'Anger', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Enjoyment', 'Sadness', 'Enjoyment', 'Sadness', 'Fear', 'Anger', 'Enjoyment', 'Sadness', 'Anger', 'Sadness', 'Enjoyment', 'Disgust', 'Sadness', 'Other', 'Sadness', 'Anger', 'Disgust', 'Disgust', 'Sadness', 'Other', 'Disgust', 'Other', 'Anger', 'Sadness', 'Enjoyment', 'Enjoyment', 'Sadness', 'Other', 'Disgust', 'Disgust', 'Enjoyment', 'Sadness', 'Enjoyment', 'Enjoyment', 'Other', 'Sadness', 'Surprise', 'Enjoyment', 'Sadness', 'Enjoyment', 'Sadness', 'Enjoyment', 'Sadness', 'Disgust', 'Disgust', 'Anger', 'Enjoyment', 'Disgust', 'Disgust', 'Fear', 'Disgust', 'Enjoyment', 'Other', 'Disgust', 'Other', 'Disgust', 'Fear', 'Disgust', 'Enjoyment', 'Enjoyment', 'Fear', 'Other', 'Sadness', 'Disgust', 'Disgust', 'Disgust', 'Other', 'Sadness', 'Other', 'Enjoyment', 'Anger', 'Anger', 'Enjoyment', 'Enjoyment', 'Anger', 'Enjoyment', 'Sadness', 'Sadness', 'Fear', 'Surprise', 'Disgust', 'Enjoyment', 'Disgust', 'Other', 'Enjoyment', 'Other', 'Other', 'Anger', 'Fear', 'Enjoyment', 'Fear', 'Sadness', 'Enjoyment', 'Enjoyment', 'Disgust', 'Sadness', 'Sadness', 'Enjoyment', 'Sadness', 'Disgust', 'Anger', 'Other', 'Other', 'Other', 'Other', 'Enjoyment', 'Other', 'Enjoyment', 'Other', 'Other', 'Disgust', 'Enjoyment', 'Disgust', 'Other']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VXZOPGcs9O_"
      },
      "source": [
        "## 3.Report the performance metrics (Accuracy, F1-score...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoEymwgf0joR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd36113-93b0-4a91-be8a-9f5d112bf76a"
      },
      "source": [
        "precision = precision_score(y_test, y_predict, average='weighted')\n",
        "recall = recall_score(y_test, y_predict, average='weighted')\n",
        "f1score = f1_score(y_test, y_predict, average='micro')\n",
        "accuracy = accuracy_score(y_test, y_predict)\n",
        "\n",
        "print(\"Result model LSTM + Attention layer\")\n",
        "print(\"Results of the models\")\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1-Score: \", f1score)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "print(classification_report(y_test,y_predict))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result model LSTM + Attention layer\n",
            "Results of the models\n",
            "Precision:  0.5055043489845584\n",
            "Recall:  0.5007215007215007\n",
            "F1-Score:  0.5007215007215007\n",
            "Accuracy:  0.5007215007215007\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Anger       0.37      0.38      0.37        40\n",
            "     Disgust       0.44      0.47      0.45       132\n",
            "   Enjoyment       0.60      0.58      0.59       193\n",
            "        Fear       0.62      0.65      0.64        46\n",
            "       Other       0.40      0.43      0.42       129\n",
            "     Sadness       0.52      0.49      0.50       116\n",
            "    Surprise       0.60      0.41      0.48        37\n",
            "\n",
            "    accuracy                           0.50       693\n",
            "   macro avg       0.51      0.49      0.49       693\n",
            "weighted avg       0.51      0.50      0.50       693\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2pll3z0tLDW"
      },
      "source": [
        "# VII.Enter the demo program into 1 sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WyndWU_0joU"
      },
      "source": [
        "def demo(str):\n",
        "  demo_pre = clean_doc(str)\n",
        "  X_demo_encode = np.array(pad_sequences(input_tokenizer.texts_to_sequences([demo_pre]), maxlen=maxLength,padding=\"post\"))\n",
        "  predicted = model.predict(X_demo_encode)\n",
        "  index2, value = max(enumerate(predicted[0]), key=operator.itemgetter(1))\n",
        "  print(str)\n",
        "  print(\"Predict the results:\", classes[index2])\n",
        "  # return classes[index2]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVJw8Vi5thbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "150eb23f-591b-471c-9d8c-389e06252f9c"
      },
      "source": [
        "demo('Mình mới chia tay bạn gái, và bạn gái mình rất vui khi chia tay mình.')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mình mới chia tay bạn gái, và bạn gái mình rất vui khi chia tay mình.\n",
            "Predict the results: Sadness\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}